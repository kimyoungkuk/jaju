{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.layers as layers\n",
    "# from text_loader import TextLoader\n",
    "\n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "\n",
    "from sklearn import metrics\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('celeba-dataset/newdataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5064975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=202599*25\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4315799\n",
      "749176\n",
      "5064975\n",
      "0.8520869303402288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>has bags under eyes</th>\n",
       "      <th>is bald</th>\n",
       "      <th>has bangs</th>\n",
       "      <th>has black hair</th>\n",
       "      <th>has blond hair</th>\n",
       "      <th>has brown hair</th>\n",
       "      <th>has bushy eyebrows</th>\n",
       "      <th>is chubby</th>\n",
       "      <th>is wearing eyeglasses</th>\n",
       "      <th>...</th>\n",
       "      <th>has no beard</th>\n",
       "      <th>has oval face</th>\n",
       "      <th>has pale skin</th>\n",
       "      <th>has a pointy nose</th>\n",
       "      <th>has sideburns</th>\n",
       "      <th>is smiling</th>\n",
       "      <th>is wearing a hat</th>\n",
       "      <th>is young</th>\n",
       "      <th>the female</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman with no bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman with high c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A young man with a pointy nose has narrow eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman has a pointy nose and no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000006.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman with brown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000007.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man with bushy eyebrows and black hair has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000008.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A young man with bags under eyes has black hai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000009.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman with high cheekbones and bangs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000010.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman has high cheekbones and no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000011.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman has no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000012.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A opening hmouth slightly man with no beard ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000013.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man is opening his mouth slightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000014.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman has high cheekbones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000015.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man has bags under eyes and narrow eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000016.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man has bags under eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000017.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with oval face is opening her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000018.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman with blond ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000019.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with no beard has oval face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000020.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man with sideburns is opening his mouth slig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000021.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man has gray hair and no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000022.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman with blond hair has no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000023.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A young man with brown hair and narrow eyes is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000024.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with no beard is young and opening her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000025.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A man is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000026.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with no beard is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000027.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman has black hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000028.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with brown hair is opening her mouth s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000029.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman with a pointy nose and no beard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000030.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man has bags under eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202569</th>\n",
       "      <td>202570.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A young man with black hair has a goatee and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202570</th>\n",
       "      <td>202571.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman with bushy eyebrows has pale ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202571</th>\n",
       "      <td>202572.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman has no beard and a pointy nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202572</th>\n",
       "      <td>202573.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with no beard has narrow eyes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202573</th>\n",
       "      <td>202574.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with no beard is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202574</th>\n",
       "      <td>202575.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with high cheekbones has no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202575</th>\n",
       "      <td>202576.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202576</th>\n",
       "      <td>202577.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman has no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202577</th>\n",
       "      <td>202578.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with oval face and brown hair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202578</th>\n",
       "      <td>202579.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with bags under eyes and no beard is y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202579</th>\n",
       "      <td>202580.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman with no beard has brown hair and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202580</th>\n",
       "      <td>202581.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man with oval face and high cheekbones has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202581</th>\n",
       "      <td>202582.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with bags under eyes has high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202582</th>\n",
       "      <td>202583.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A opening her mouth slightly woman with high c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202583</th>\n",
       "      <td>202584.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with no beard has high cheekbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202584</th>\n",
       "      <td>202585.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A man is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202585</th>\n",
       "      <td>202586.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A man with bags under eyes has no beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202586</th>\n",
       "      <td>202587.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with a pointy nose and no bear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202587</th>\n",
       "      <td>202588.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A opening hmouth slightly man with black hair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202588</th>\n",
       "      <td>202589.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A man with oval face is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202589</th>\n",
       "      <td>202590.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A wearing eyeglasses man has gray hair and hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202590</th>\n",
       "      <td>202591.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A young woman with no beard and black hair is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202591</th>\n",
       "      <td>202592.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with blond hair and no beard i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202592</th>\n",
       "      <td>202593.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A smiling woman with bangs has a pointy nose a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202593</th>\n",
       "      <td>202594.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman has a pointy nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202594</th>\n",
       "      <td>202595.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with no beard has blond hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595</th>\n",
       "      <td>202596.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A opening hmouth slightly and smiling man is y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596</th>\n",
       "      <td>202597.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A opening hmouth slightly man with no beard an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597</th>\n",
       "      <td>202598.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman is young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598</th>\n",
       "      <td>202599.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A woman with a pointy nose and pale skin is young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  has bags under eyes  is bald  has bangs  has black hair  \\\n",
       "0       000001.jpg                    0        0          0               0   \n",
       "1       000002.jpg                    1        0          0               0   \n",
       "2       000003.jpg                    0        0          0               0   \n",
       "3       000004.jpg                    0        0          0               0   \n",
       "4       000005.jpg                    0        0          0               0   \n",
       "5       000006.jpg                    0        0          0               0   \n",
       "6       000007.jpg                    1        0          0               1   \n",
       "7       000008.jpg                    1        0          0               1   \n",
       "8       000009.jpg                    0        0          1               0   \n",
       "9       000010.jpg                    0        0          0               0   \n",
       "10      000011.jpg                    0        0          0               0   \n",
       "11      000012.jpg                    0        0          0               1   \n",
       "12      000013.jpg                    0        0          0               0   \n",
       "13      000014.jpg                    0        0          0               0   \n",
       "14      000015.jpg                    1        0          0               0   \n",
       "15      000016.jpg                    1        0          0               0   \n",
       "16      000017.jpg                    0        0          0               0   \n",
       "17      000018.jpg                    0        0          0               0   \n",
       "18      000019.jpg                    0        0          0               0   \n",
       "19      000020.jpg                    0        0          0               0   \n",
       "20      000021.jpg                    0        0          0               0   \n",
       "21      000022.jpg                    0        0          0               0   \n",
       "22      000023.jpg                    0        0          0               0   \n",
       "23      000024.jpg                    0        0          0               0   \n",
       "24      000025.jpg                    0        0          0               0   \n",
       "25      000026.jpg                    0        0          0               0   \n",
       "26      000027.jpg                    0        0          0               1   \n",
       "27      000028.jpg                    0        0          0               0   \n",
       "28      000029.jpg                    0        0          0               0   \n",
       "29      000030.jpg                    1        0          0               0   \n",
       "...            ...                  ...      ...        ...             ...   \n",
       "202569  202570.jpg                    0        0          0               1   \n",
       "202570  202571.jpg                    0        0          0               0   \n",
       "202571  202572.jpg                    0        0          0               0   \n",
       "202572  202573.jpg                    0        0          0               0   \n",
       "202573  202574.jpg                    0        0          0               0   \n",
       "202574  202575.jpg                    0        0          0               0   \n",
       "202575  202576.jpg                    0        0          0               0   \n",
       "202576  202577.jpg                    0        0          0               0   \n",
       "202577  202578.jpg                    0        0          0               0   \n",
       "202578  202579.jpg                    1        0          0               0   \n",
       "202579  202580.jpg                    0        0          1               0   \n",
       "202580  202581.jpg                    0        0          0               0   \n",
       "202581  202582.jpg                    1        0          0               0   \n",
       "202582  202583.jpg                    0        0          0               0   \n",
       "202583  202584.jpg                    0        0          0               0   \n",
       "202584  202585.jpg                    0        0          0               0   \n",
       "202585  202586.jpg                    1        0          0               0   \n",
       "202586  202587.jpg                    0        0          0               0   \n",
       "202587  202588.jpg                    0        0          0               1   \n",
       "202588  202589.jpg                    0        0          0               0   \n",
       "202589  202590.jpg                    0        0          0               0   \n",
       "202590  202591.jpg                    0        0          0               1   \n",
       "202591  202592.jpg                    0        0          0               0   \n",
       "202592  202593.jpg                    0        0          1               0   \n",
       "202593  202594.jpg                    0        0          0               0   \n",
       "202594  202595.jpg                    0        0          0               0   \n",
       "202595  202596.jpg                    0        0          0               0   \n",
       "202596  202597.jpg                    0        0          0               1   \n",
       "202597  202598.jpg                    0        0          0               0   \n",
       "202598  202599.jpg                    0        0          0               0   \n",
       "\n",
       "        has blond hair  has brown hair  has bushy eyebrows  is chubby  \\\n",
       "0                    0               0                   0          0   \n",
       "1                    0               0                   0          0   \n",
       "2                    0               0                   0          0   \n",
       "3                    0               0                   0          0   \n",
       "4                    0               0                   0          0   \n",
       "5                    0               1                   0          0   \n",
       "6                    0               0                   1          0   \n",
       "7                    0               0                   0          0   \n",
       "8                    0               0                   0          0   \n",
       "9                    0               0                   0          0   \n",
       "10                   0               0                   0          0   \n",
       "11                   0               0                   1          0   \n",
       "12                   0               0                   0          0   \n",
       "13                   0               0                   0          0   \n",
       "14                   0               0                   0          0   \n",
       "15                   0               0                   0          0   \n",
       "16                   0               0                   0          0   \n",
       "17                   1               0                   0          0   \n",
       "18                   0               0                   0          0   \n",
       "19                   0               0                   0          1   \n",
       "20                   0               0                   0          0   \n",
       "21                   1               0                   0          0   \n",
       "22                   0               1                   0          0   \n",
       "23                   0               0                   0          0   \n",
       "24                   0               0                   0          0   \n",
       "25                   0               0                   0          0   \n",
       "26                   0               0                   0          0   \n",
       "27                   0               1                   0          0   \n",
       "28                   0               0                   0          0   \n",
       "29                   0               0                   0          0   \n",
       "...                ...             ...                 ...        ...   \n",
       "202569               0               0                   0          0   \n",
       "202570               0               1                   1          0   \n",
       "202571               0               0                   0          0   \n",
       "202572               0               0                   0          0   \n",
       "202573               0               0                   0          0   \n",
       "202574               0               0                   0          0   \n",
       "202575               0               0                   0          0   \n",
       "202576               0               0                   0          0   \n",
       "202577               0               1                   0          0   \n",
       "202578               0               0                   0          0   \n",
       "202579               0               1                   0          0   \n",
       "202580               0               0                   0          0   \n",
       "202581               0               0                   0          0   \n",
       "202582               0               0                   0          0   \n",
       "202583               1               0                   0          0   \n",
       "202584               0               0                   0          0   \n",
       "202585               0               0                   0          0   \n",
       "202586               0               0                   0          0   \n",
       "202587               0               0                   0          0   \n",
       "202588               0               0                   0          0   \n",
       "202589               0               0                   0          0   \n",
       "202590               0               0                   0          0   \n",
       "202591               1               0                   0          0   \n",
       "202592               0               0                   0          0   \n",
       "202593               0               0                   0          0   \n",
       "202594               1               0                   0          0   \n",
       "202595               0               0                   0          0   \n",
       "202596               0               0                   0          0   \n",
       "202597               0               0                   0          0   \n",
       "202598               0               0                   0          0   \n",
       "\n",
       "        is wearing eyeglasses  \\\n",
       "0                           0   \n",
       "1                           0   \n",
       "2                           0   \n",
       "3                           0   \n",
       "4                           0   \n",
       "5                           0   \n",
       "6                           0   \n",
       "7                           0   \n",
       "8                           0   \n",
       "9                           0   \n",
       "10                          0   \n",
       "11                          0   \n",
       "12                          0   \n",
       "13                          0   \n",
       "14                          0   \n",
       "15                          0   \n",
       "16                          0   \n",
       "17                          0   \n",
       "18                          0   \n",
       "19                          0   \n",
       "20                          0   \n",
       "21                          0   \n",
       "22                          0   \n",
       "23                          0   \n",
       "24                          0   \n",
       "25                          0   \n",
       "26                          0   \n",
       "27                          0   \n",
       "28                          0   \n",
       "29                          0   \n",
       "...                       ...   \n",
       "202569                      0   \n",
       "202570                      0   \n",
       "202571                      0   \n",
       "202572                      0   \n",
       "202573                      0   \n",
       "202574                      0   \n",
       "202575                      0   \n",
       "202576                      0   \n",
       "202577                      0   \n",
       "202578                      0   \n",
       "202579                      0   \n",
       "202580                      0   \n",
       "202581                      0   \n",
       "202582                      0   \n",
       "202583                      0   \n",
       "202584                      0   \n",
       "202585                      0   \n",
       "202586                      0   \n",
       "202587                      0   \n",
       "202588                      0   \n",
       "202589                      1   \n",
       "202590                      0   \n",
       "202591                      0   \n",
       "202592                      0   \n",
       "202593                      0   \n",
       "202594                      0   \n",
       "202595                      0   \n",
       "202596                      1   \n",
       "202597                      0   \n",
       "202598                      0   \n",
       "\n",
       "                              ...                          has no beard  \\\n",
       "0                             ...                                     1   \n",
       "1                             ...                                     0   \n",
       "2                             ...                                     1   \n",
       "3                             ...                                     1   \n",
       "4                             ...                                     0   \n",
       "5                             ...                                     1   \n",
       "6                             ...                                     1   \n",
       "7                             ...                                     0   \n",
       "8                             ...                                     0   \n",
       "9                             ...                                     1   \n",
       "10                            ...                                     1   \n",
       "11                            ...                                     1   \n",
       "12                            ...                                     0   \n",
       "13                            ...                                     0   \n",
       "14                            ...                                     0   \n",
       "15                            ...                                     0   \n",
       "16                            ...                                     0   \n",
       "17                            ...                                     0   \n",
       "18                            ...                                     1   \n",
       "19                            ...                                     0   \n",
       "20                            ...                                     1   \n",
       "21                            ...                                     1   \n",
       "22                            ...                                     0   \n",
       "23                            ...                                     1   \n",
       "24                            ...                                     0   \n",
       "25                            ...                                     1   \n",
       "26                            ...                                     0   \n",
       "27                            ...                                     0   \n",
       "28                            ...                                     1   \n",
       "29                            ...                                     0   \n",
       "...                           ...                                   ...   \n",
       "202569                        ...                                     0   \n",
       "202570                        ...                                     0   \n",
       "202571                        ...                                     1   \n",
       "202572                        ...                                     1   \n",
       "202573                        ...                                     1   \n",
       "202574                        ...                                     1   \n",
       "202575                        ...                                     0   \n",
       "202576                        ...                                     1   \n",
       "202577                        ...                                     0   \n",
       "202578                        ...                                     1   \n",
       "202579                        ...                                     1   \n",
       "202580                        ...                                     0   \n",
       "202581                        ...                                     0   \n",
       "202582                        ...                                     0   \n",
       "202583                        ...                                     1   \n",
       "202584                        ...                                     0   \n",
       "202585                        ...                                     1   \n",
       "202586                        ...                                     1   \n",
       "202587                        ...                                     0   \n",
       "202588                        ...                                     0   \n",
       "202589                        ...                                     0   \n",
       "202590                        ...                                     1   \n",
       "202591                        ...                                     1   \n",
       "202592                        ...                                     1   \n",
       "202593                        ...                                     0   \n",
       "202594                        ...                                     1   \n",
       "202595                        ...                                     0   \n",
       "202596                        ...                                     1   \n",
       "202597                        ...                                     0   \n",
       "202598                        ...                                     0   \n",
       "\n",
       "        has oval face  has pale skin  has a pointy nose  has sideburns  \\\n",
       "0                   0              0                  0              0   \n",
       "1                   0              0                  0              0   \n",
       "2                   0              0                  1              0   \n",
       "3                   0              0                  1              0   \n",
       "4                   0              0                  0              0   \n",
       "5                   0              0                  0              0   \n",
       "6                   0              0                  0              0   \n",
       "7                   0              0                  1              0   \n",
       "8                   0              0                  0              0   \n",
       "9                   0              0                  0              0   \n",
       "10                  0              0                  0              0   \n",
       "11                  0              0                  0              0   \n",
       "12                  0              0                  0              0   \n",
       "13                  0              0                  0              0   \n",
       "14                  0              0                  0              0   \n",
       "15                  0              0                  0              0   \n",
       "16                  1              0                  0              0   \n",
       "17                  0              0                  0              0   \n",
       "18                  1              0                  0              0   \n",
       "19                  0              0                  0              1   \n",
       "20                  0              0                  0              0   \n",
       "21                  0              0                  0              0   \n",
       "22                  0              0                  0              0   \n",
       "23                  0              0                  0              0   \n",
       "24                  0              0                  0              0   \n",
       "25                  0              0                  0              0   \n",
       "26                  0              0                  0              0   \n",
       "27                  0              0                  0              0   \n",
       "28                  0              0                  1              0   \n",
       "29                  0              0                  0              0   \n",
       "...               ...            ...                ...            ...   \n",
       "202569              1              0                  0              0   \n",
       "202570              0              1                  0              0   \n",
       "202571              0              0                  1              0   \n",
       "202572              0              0                  1              0   \n",
       "202573              0              0                  0              0   \n",
       "202574              0              0                  0              0   \n",
       "202575              0              0                  0              0   \n",
       "202576              0              0                  0              0   \n",
       "202577              1              0                  0              0   \n",
       "202578              0              0                  0              0   \n",
       "202579              0              0                  0              0   \n",
       "202580              1              0                  0              1   \n",
       "202581              0              0                  0              0   \n",
       "202582              1              0                  0              0   \n",
       "202583              0              0                  0              0   \n",
       "202584              0              0                  0              0   \n",
       "202585              0              0                  0              0   \n",
       "202586              0              0                  1              0   \n",
       "202587              1              0                  0              0   \n",
       "202588              1              0                  0              0   \n",
       "202589              0              0                  0              0   \n",
       "202590              0              0                  0              0   \n",
       "202591              0              0                  0              0   \n",
       "202592              0              0                  1              0   \n",
       "202593              0              0                  1              0   \n",
       "202594              0              0                  0              0   \n",
       "202595              0              0                  0              0   \n",
       "202596              0              0                  0              0   \n",
       "202597              0              0                  0              0   \n",
       "202598              0              1                  1              0   \n",
       "\n",
       "        is smiling  is wearing a hat  is young  the female  \\\n",
       "0                1                 0         1           1   \n",
       "1                1                 0         0           1   \n",
       "2                0                 0         1           0   \n",
       "3                0                 0         0           1   \n",
       "4                0                 0         1           1   \n",
       "5                0                 0         1           1   \n",
       "6                0                 0         0           0   \n",
       "7                0                 0         1           0   \n",
       "8                0                 0         1           1   \n",
       "9                0                 0         1           1   \n",
       "10               0                 0         0           1   \n",
       "11               0                 0         0           0   \n",
       "12               0                 0         0           0   \n",
       "13               1                 0         0           1   \n",
       "14               0                 0         0           0   \n",
       "15               0                 0         0           0   \n",
       "16               1                 0         1           1   \n",
       "17               1                 0         0           1   \n",
       "18               0                 0         0           1   \n",
       "19               0                 0         0           0   \n",
       "20               0                 0         0           0   \n",
       "21               0                 0         1           1   \n",
       "22               1                 0         1           0   \n",
       "23               0                 0         1           1   \n",
       "24               0                 0         1           0   \n",
       "25               0                 0         1           1   \n",
       "26               0                 0         0           1   \n",
       "27               0                 0         0           1   \n",
       "28               0                 0         1           1   \n",
       "29               0                 0         0           0   \n",
       "...            ...               ...       ...         ...   \n",
       "202569           0                 0         1           0   \n",
       "202570           0                 0         1           1   \n",
       "202571           0                 0         0           1   \n",
       "202572           1                 0         0           1   \n",
       "202573           0                 0         1           1   \n",
       "202574           0                 0         0           1   \n",
       "202575           0                 0         1           1   \n",
       "202576           0                 0         0           1   \n",
       "202577           1                 0         1           1   \n",
       "202578           0                 0         1           1   \n",
       "202579           0                 0         1           1   \n",
       "202580           0                 0         0           0   \n",
       "202581           1                 0         0           1   \n",
       "202582           0                 0         1           1   \n",
       "202583           1                 0         0           1   \n",
       "202584           0                 0         1           0   \n",
       "202585           0                 0         0           0   \n",
       "202586           1                 0         0           1   \n",
       "202587           0                 0         0           0   \n",
       "202588           0                 0         1           0   \n",
       "202589           0                 0         0           0   \n",
       "202590           0                 0         1           1   \n",
       "202591           1                 0         1           1   \n",
       "202592           1                 0         0           1   \n",
       "202593           0                 0         0           1   \n",
       "202594           0                 0         0           1   \n",
       "202595           1                 0         1           0   \n",
       "202596           0                 0         0           0   \n",
       "202597           0                 0         1           1   \n",
       "202598           0                 0         1           1   \n",
       "\n",
       "                                                 sentence  \n",
       "0       A opening her mouth slightly woman with no bea...  \n",
       "1       A opening her mouth slightly woman with high c...  \n",
       "2       A young man with a pointy nose has narrow eyes...  \n",
       "3                  A woman has a pointy nose and no beard  \n",
       "4                                        A woman is young  \n",
       "5       A opening her mouth slightly woman with brown ...  \n",
       "6       A man with bushy eyebrows and black hair has b...  \n",
       "7       A young man with bags under eyes has black hai...  \n",
       "8       A young woman with high cheekbones and bangs i...  \n",
       "9          A young woman has high cheekbones and no beard  \n",
       "10        A opening her mouth slightly woman has no beard  \n",
       "11      A opening hmouth slightly man with no beard ha...  \n",
       "12                    A man is opening his mouth slightly  \n",
       "13                    A smiling woman has high cheekbones  \n",
       "14              A man has bags under eyes and narrow eyes  \n",
       "15                              A man has bags under eyes  \n",
       "16      A smiling woman with oval face is opening her ...  \n",
       "17      A opening her mouth slightly woman with blond ...  \n",
       "18                    A woman with no beard has oval face  \n",
       "19      A man with sideburns is opening his mouth slig...  \n",
       "20                       A man has gray hair and no beard  \n",
       "21             A young woman with blond hair has no beard  \n",
       "22      A young man with brown hair and narrow eyes is...  \n",
       "23      A woman with no beard is young and opening her...  \n",
       "24                                         A man is young  \n",
       "25                         A woman with no beard is young  \n",
       "26                                 A woman has black hair  \n",
       "27      A woman with brown hair is opening her mouth s...  \n",
       "28      A young woman with a pointy nose and no beard ...  \n",
       "29                              A man has bags under eyes  \n",
       "...                                                   ...  \n",
       "202569  A young man with black hair has a goatee and o...  \n",
       "202570  A young woman with bushy eyebrows has pale ski...  \n",
       "202571             A woman has no beard and a pointy nose  \n",
       "202572  A smiling woman with no beard has narrow eyes ...  \n",
       "202573                     A woman with no beard is young  \n",
       "202574          A woman with high cheekbones has no beard  \n",
       "202575        A opening her mouth slightly woman is young  \n",
       "202576                               A woman has no beard  \n",
       "202577  A smiling woman with oval face and brown hair ...  \n",
       "202578  A woman with bags under eyes and no beard is y...  \n",
       "202579  A young woman with no beard has brown hair and...  \n",
       "202580  A man with oval face and high cheekbones has a...  \n",
       "202581  A smiling woman with bags under eyes has high ...  \n",
       "202582  A opening her mouth slightly woman with high c...  \n",
       "202583  A smiling woman with no beard has high cheekbo...  \n",
       "202584                                     A man is young  \n",
       "202585            A man with bags under eyes has no beard  \n",
       "202586  A smiling woman with a pointy nose and no bear...  \n",
       "202587  A opening hmouth slightly man with black hair ...  \n",
       "202588                      A man with oval face is young  \n",
       "202589  A wearing eyeglasses man has gray hair and hig...  \n",
       "202590  A young woman with no beard and black hair is ...  \n",
       "202591  A smiling woman with blond hair and no beard i...  \n",
       "202592  A smiling woman with bangs has a pointy nose a...  \n",
       "202593                          A woman has a pointy nose  \n",
       "202594               A woman with no beard has blond hair  \n",
       "202595  A opening hmouth slightly and smiling man is y...  \n",
       "202596  A opening hmouth slightly man with no beard an...  \n",
       "202597                                   A woman is young  \n",
       "202598  A woman with a pointy nose and pale skin is young  \n",
       "\n",
       "[202599 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(data.sum())\n",
    "zero=0\n",
    "one=0\n",
    "for col in data.columns[1:-1]:\n",
    "    zero=zero+data[col].value_counts()[0]\n",
    "    one=one+data[col].value_counts()[1]\n",
    "print(zero)\n",
    "print(one)\n",
    "print(zero+one)\n",
    "print(zero/total)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has bags under eyes 0.89600639687264\n",
      "is bald 0.9882724001599218\n",
      "has bangs 0.9235386156891199\n",
      "has black hair 0.8744761820147188\n",
      "has blond hair 0.9236866914446764\n",
      "has brown hair 0.8914456636014986\n",
      "has bushy eyebrows 0.9278574918928524\n",
      "is chubby 0.9716928513961076\n",
      "is wearing eyeglasses 0.9634302242360525\n",
      "has a goatee 0.9668409024723715\n",
      "has gray hair 0.9768310801139196\n",
      "has high cheekbones 0.7829752367978124\n",
      "the male 0.5832457218446291\n",
      "is opening mouth slightly 0.7628171906080484\n",
      "has a mustache 0.9781489543383729\n",
      "has narrow eyes 0.9431191664322134\n",
      "has no beard 0.5432998188539924\n",
      "has oval face 0.8606113554361078\n",
      "has pale skin 0.9767669139531785\n",
      "has a pointy nose 0.8577683009294221\n",
      "has sideburns 0.9701380559627639\n",
      "is smiling 0.7720916687644065\n",
      "is wearing a hat 0.9725516907783355\n",
      "is young 0.5778064057571853\n",
      "the female 0.41675427815537097\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns[1:-1]:\n",
    "    zero=data[col].value_counts()[0]\n",
    "    one=data[col].value_counts()[1]\n",
    "    print(col,\"{}\".format(zero/(zero+one)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data['sentence']\n",
    "y=np.array(data.iloc[:,1:26]).tolist()\n",
    "# y=list(data.iloc[0:,1:2])\n",
    "# y = [1 if x == '1' else 0 for x in data['is chubby'] ]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "MAX_DOCUMENT_LENGTH = 20 # 한 문장의 단어 갯수\n",
    "\n",
    "EMBEDDING_SIZE = 150 # 임베딩 차원수\n",
    "n_words = 0 # 등장하는 단어 종류(이후에 계산됨)\n",
    "MAX_LABEL = 25 # 특징 갯수\n",
    "WORDS_FEATURE = 'words'\n",
    "learning_rate = 0.0001\n",
    "\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator_spec_for_softmax_classification (logits, labels, mode):\n",
    "\n",
    "    \"\"\"Returns EstimatorSpec instance for softmax classification.\"\"\"\n",
    "\n",
    "#     predicted = tf.argmax(logits, 1)\n",
    "#     predicted = tf.round(tf.nn.softmax(logits))\n",
    "#     predicted = tf.sigmoid(logits)\n",
    "    logits = tf.identity(logits, name='logits')\n",
    "    prob = tf.nn.sigmoid(logits , name='prob')\n",
    "    predicted_classes = tf.round(prob, name='predicted_classes')\n",
    "    \n",
    "    print(\"666\")\n",
    "    print(logits)\n",
    "#     print(type(tf.Session().run(predicted)))\n",
    "\n",
    "    # case 1) inference mode\n",
    "    \n",
    "    # ModeKey가 PREDICT이면 inference mode이다. inference는 학습시킨 모델을 새로운 데이터에 적용시키는 것을 말한다.\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT: \n",
    "        \n",
    "        print(\"ppp\")\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions={\n",
    "            'logits': logits,\n",
    "            'prob': prob,\n",
    "            'predicted_classes': predicted_classes,\n",
    "        })\n",
    "\n",
    "\n",
    "    # case 2) training mode\n",
    "\n",
    "#     onehot_labels = tf.one_hot(labels, MAX_LABEL, 1, 0)\n",
    "\n",
    "\n",
    "    print(\"777\")\n",
    "    print(type(logits))\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(labels, logits=prob)\n",
    "    print(\"loss\")\n",
    "    print(loss)\n",
    "#     print('loss: {0:f}'.format(loss))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(tf.cast(labels,tf.float32),predicted_classes), tf.float32), name='acc')\n",
    "        acc_row = tf.reduce_mean(tf.cast(tf.reduce_all(tf.equal(tf.cast(labels,tf.float32), predicted_classes), axis=1), tf.float32), name='acc_row')\n",
    "    \n",
    "        labels = tf.identity(labels , name='labels')\n",
    "\n",
    "        \n",
    "        print(\"ttt\")\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, predictions=logits)\n",
    "\n",
    "    # case 3) evaluation mode\n",
    "    \n",
    "    print(\"eee!\")\n",
    "    print(labels)\n",
    "    print(predicted_classes)\n",
    "    \n",
    "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes)}\n",
    "    print(\"eee?\")\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(features, labels, mode):\n",
    "\n",
    "    \"\"\"RNN model to predict from sequence of words to a class.\"\"\"\n",
    "    \n",
    "    # 단어들의 index를 embeddings로 바꾼다. \n",
    "    # [n_words(단어 개수), EMBEDDING_SIZE]의 크기를 가지는 matrix를 만들고 순서를 나타내는 단어들의 index를 \n",
    "    # [batch_size, sequence_length, EMBEDDING_SIZE]에 mapping 한다.\n",
    "    # word_vectors와 word_list를 만든다.\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features[WORDS_FEATURE], vocab_size=n_words, embed_dim=EMBEDDING_SIZE)\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "\n",
    "    \n",
    "    # embedding size와 같은 hidden size를 가지는 GUR cell을 만든다.\n",
    "#     cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)\n",
    "    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE / 2)\n",
    "\n",
    "    \n",
    "    # MAX_DOCUMENT_LENGTH의 길이를 가지는 RNN을 만든다. 그리고 각 유닛에 input으로 word_list를 준다.\n",
    "    # (output, state)쌍이 return된다.\n",
    "    print(\"@@@\")\n",
    "#     out1, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "#     resout1 = [w + o for w, o in zip(out1, word_list)]\n",
    "    \n",
    "#     out2, encoding = tf.contrib.rnn.static_rnn(cell, resout1, dtype=tf.float32)\n",
    "    \n",
    "#     resout2 = [w + o for w, o in zip(out2, resout1)]\n",
    "    \n",
    "#     out3, encoding = tf.contrib.rnn.static_rnn(cell, resout2, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    out1, state1, state2 = tf.contrib.rnn.static_bidirectional_rnn(cell, cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "    resout1 = [w + o for w, o in zip(out1, word_list)]\n",
    "    \n",
    "    out2, state1, state2 = tf.contrib.rnn.static_bidirectional_rnn(cell, cell, resout1, dtype=tf.float32)\n",
    "    \n",
    "    resout2 = [w + o for w, o in zip(out2, resout1)]\n",
    "    \n",
    "    out3, state1, state2 = tf.contrib.rnn.static_bidirectional_rnn(cell, cell, resout2, dtype=tf.float32)\n",
    "    \n",
    "    print(\"###\")\n",
    "#     print(out2)\n",
    "#     print(\"###\")\n",
    "#     print(state1)\n",
    "#     print(\"###\")\n",
    "#     print(state2)\n",
    "    print(\"###\")\n",
    "#     print(encoding)\n",
    "    print(tf.concat([state1,state2],1))\n",
    "    print(\"###\")\n",
    "    ##########중요 여기바꿔야\n",
    "    # 마지막 유닛의 state 값을 softmax classification의 feature로 넘겨준다.\n",
    "#     logits = tf.layers.dense(encoding, MAX_LABEL, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(tf.concat([state1,state2],1), MAX_LABEL, activation=tf.nn.relu)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        print(\"trainbatch\")\n",
    "        logits = tf.contrib.layers.batch_norm(logits,is_training=True)\n",
    "    else:\n",
    "        print(\"testbatch\")\n",
    "        logits = tf.contrib.layers.batch_norm(logits,is_training=False)\n",
    "        \n",
    "        \n",
    "          \n",
    "          \n",
    "    return estimator_spec_for_softmax_classification(logits=logits, labels=labels, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    global n_words\n",
    "    global vocab_processor\n",
    "    global classifier\n",
    "    \n",
    "    # train data set, test data set을 나눠준다.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test) # tensorflow input으로 사용될 수 있는 자료형으로 변환시켜줘야 한다.\n",
    "    # 단어들을 우리가 원하는 sequence length로 맞추어 준다.(embedding 해주기 전 단계) 위의 사진 참고\n",
    "    vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "    \n",
    "    x_transform_train = vocab_processor.fit_transform(x_train) # 둘의 차이는?\n",
    "    x_transform_test = vocab_processor.transform(x_test)\n",
    "    x_train = np.array(list(x_transform_train))\n",
    "    x_test = np.array(list(x_transform_test))\n",
    "    \n",
    "    \n",
    "    n_words = len(vocab_processor.vocabulary_)\n",
    "    print('Total words : %d', n_words)\n",
    "    \n",
    "    # 모델을 만들어준다.(여기서는 위에서 정의한 rnn_model을 사용한다.)\n",
    "    model_fn = rnn_model\n",
    "    classifier = tf.estimator.Estimator(model_fn=model_fn)\n",
    "    \n",
    "    \n",
    "    # Train\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {WORDS_FEATURE : x_train},\n",
    "        y = y_train,\n",
    "        batch_size = 256,\n",
    "        num_epochs = 20,\n",
    "        shuffle = True) # shuffle = True : \n",
    "    \n",
    "    \n",
    "    \n",
    "    tensors_to_log = {'prob': 'prob', 'labels': 'labels', 'predicted_classes': 'predicted_classes', 'acc': 'acc', 'acc_row': 'acc_row','logits': 'logits'}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "    \n",
    "    classifier.train(input_fn = train_input_fn, hooks=[logging_hook])\n",
    "\n",
    "    # Predict\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {WORDS_FEATURE : x_test},\n",
    "        y = y_test,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False)\n",
    "    predictions = classifier.predict(input_fn = test_input_fn)\n",
    "    y_predicted = np.array(list(p['prob'] for p in predictions))\n",
    "    \n",
    "    \n",
    "    # Score using tensorflow\n",
    "    score = classifier.evaluate(input_fn = test_input_fn)\n",
    "    print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-5591c0289538>:13: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "Total words : %d 48\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpp_7nmm1l\n",
      "INFO:tensorflow:Using config: {'_is_chief': True, '_master': '', '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpp_7nmm1l', '_save_checkpoints_steps': None, '_device_fn': None, '_save_summary_steps': 100, '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f520c9006a0>, '_session_config': None, '_service': None, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_evaluation_master': '', '_train_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "trainbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "777\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss\n",
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n",
      "ttt\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpp_7nmm1l/model.ckpt.\n",
      "INFO:tensorflow:acc = 0.67109376, acc_row = 0.0, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 1 0]], logits = [[ 0.         -0.0260707   1.293294   ...  0.1096405  -0.00104265\n",
      "   0.89923453]\n",
      " [ 0.         -0.0260707   0.5891685  ...  1.1890211  -0.00104265\n",
      "   1.0795078 ]\n",
      " [ 0.         -0.0260707   0.17554492 ...  1.5899788  -0.00104265\n",
      "  -0.26072353]\n",
      " ...\n",
      " [ 0.         -0.0260707   0.49822772 ...  0.0115871  -0.00104265\n",
      "   0.38370946]\n",
      " [ 0.         -0.0260707   0.72225714 ...  1.3336636  -0.00104265\n",
      "   0.8886773 ]\n",
      " [ 0.         -0.0260707  -0.3805382  ... -0.5268743  -0.00104265\n",
      "  -0.63336766]], predicted_classes = [[0. 0. 1. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.5        0.4934827  0.7847042  ... 0.5273827  0.49973932 0.7107922 ]\n",
      " [0.5        0.4934827  0.64317435 ... 0.766566   0.49973932 0.74640083]\n",
      " [0.5        0.4934827  0.5437739  ... 0.83061314 0.49973932 0.43518588]\n",
      " ...\n",
      " [0.5        0.4934827  0.6220428  ... 0.5028967  0.49973932 0.5947675 ]\n",
      " [0.5        0.4934827  0.67310387 ... 0.791446   0.49973932 0.7086171 ]\n",
      " [0.5        0.4934827  0.4059971  ... 0.37124622 0.49973932 0.3467473 ]]\n",
      "INFO:tensorflow:loss = 0.9003086, step = 0\n",
      "INFO:tensorflow:global_step/sec: 11.4621\n",
      "INFO:tensorflow:acc = 0.79859376, acc_row = 0.00390625, labels = [[1 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.0099829  -0.5168673   0.669065   ... -1.1602695   2.2187777\n",
      "   0.843879  ]\n",
      " [-0.0099829  -0.5168673  -0.0960521  ... -1.0990939  -1.1784525\n",
      "   0.89285874]\n",
      " [-0.0099829   0.34044787  0.03839815 ...  0.9815297   0.65513533\n",
      "   0.9831833 ]\n",
      " ...\n",
      " [-0.0099829  -0.5168673  -0.7662969  ... -1.3548629   0.16573593\n",
      "   0.79100347]\n",
      " [-0.0099829  -0.5168673  -1.5209311  ...  0.02024317 -0.31820613\n",
      "  -0.8636863 ]\n",
      " [-0.0099829  -0.03353862  0.9647246  ... -1.3548629   0.07268341\n",
      "   1.3315802 ]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]], prob = [[0.4975043  0.37358508 0.66129375 ... 0.23861831 0.90192306 0.6992816 ]\n",
      " [0.4975043  0.37358508 0.4760054  ... 0.2499097  0.23533055 0.7094798 ]\n",
      " [0.4975043  0.5842993  0.5095984  ... 0.7274117  0.65816677 0.72773945]\n",
      " ...\n",
      " [0.4975043  0.37358508 0.31728068 ... 0.20507649 0.5413394  0.68804675]\n",
      " [0.4975043  0.37358508 0.17932445 ... 0.5050606  0.42111298 0.29656973]\n",
      " [0.4975043  0.49161616 0.72406673 ... 0.20507649 0.51816285 0.7911019 ]] (8.726 sec)\n",
      "INFO:tensorflow:loss = 0.8732133, step = 100 (8.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5293\n",
      "INFO:tensorflow:acc = 0.8584375, acc_row = 0.04296875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.01996724 -0.3727144  -0.25763395 ... -0.39494374  1.3150139\n",
      "   0.7647738 ]\n",
      " [-0.01996724 -0.3727144   0.02387297 ... -0.39494374  1.0667322\n",
      "   0.9667625 ]\n",
      " [-0.01996724 -0.3727144  -0.38003883 ... -0.39494374 -0.7599563\n",
      "  -1.1661655 ]\n",
      " ...\n",
      " [-0.01996724 -0.3727144  -0.38003883 ...  3.5297768  -0.78640074\n",
      "  -1.1661655 ]\n",
      " [-0.01996724 -0.3727144  -0.38003883 ...  0.723866   -0.87995243\n",
      "  -1.1661655 ]\n",
      " [-0.01996724 -0.3727144   1.9660811  ... -0.39494374  1.3951805\n",
      "   1.1448842 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]], prob = [[0.49500838 0.40788528 0.43594542 ... 0.40252778 0.788351   0.68238926]\n",
      " [0.49500838 0.40788528 0.505968   ... 0.40252778 0.743975   0.7244737 ]\n",
      " [0.49500838 0.40788528 0.40611753 ... 0.40252778 0.31865576 0.2375488 ]\n",
      " ...\n",
      " [0.49500838 0.40788528 0.40611753 ... 0.9715233  0.31294203 0.2375488 ]\n",
      " [0.49500838 0.40788528 0.40611753 ... 0.67345774 0.29318765 0.2375488 ]\n",
      " [0.49500838 0.40788528 0.8771896  ... 0.40252778 0.801418   0.75857526]] (3.633 sec)\n",
      "INFO:tensorflow:loss = 0.8655742, step = 200 (3.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0886\n",
      "INFO:tensorflow:acc = 0.88171875, acc_row = 0.078125, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.02995305 -0.31414893 -0.34114474 ...  1.8278781  -0.8987556\n",
      "  -1.1013278 ]\n",
      " [-0.02995305 -0.31414893 -0.34114474 ...  2.901475    1.2318152\n",
      "  -1.1013278 ]\n",
      " [-0.02995305 -0.31414893 -0.34114474 ...  3.4072874  -0.8987556\n",
      "  -1.1013278 ]\n",
      " ...\n",
      " [-0.02995305 -0.31414893 -0.34114474 ... -0.37673843 -0.8987556\n",
      "   0.5224207 ]\n",
      " [-0.02995305 -0.31414893 -0.03427546 ...  0.70612377  0.8885677\n",
      "  -1.1013278 ]\n",
      " [-0.02995305  3.7659843  -0.34114474 ... -0.37673843 -0.8987556\n",
      "  -1.1013278 ]], predicted_classes = [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]], prob = [[0.49251235 0.42210236 0.41553143 ... 0.8615087  0.28930628 0.24949118]\n",
      " [0.49251235 0.42210236 0.41553143 ... 0.9479193  0.7741361  0.24949118]\n",
      " [0.49251235 0.42210236 0.41553143 ... 0.96793145 0.28930628 0.24949118]\n",
      " ...\n",
      " [0.49251235 0.42210236 0.41553143 ... 0.4069138  0.28930628 0.6277136 ]\n",
      " [0.49251235 0.42210236 0.49143195 ... 0.6695441  0.7085945  0.24949118]\n",
      " [0.49251235 0.9773787  0.41553143 ... 0.4069138  0.28930628 0.24949118]] (3.692 sec)\n",
      "INFO:tensorflow:loss = 0.86083585, step = 300 (3.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0932\n",
      "INFO:tensorflow:acc = 0.90375, acc_row = 0.10546875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.45403197 -0.37442476 -0.32967806 ... -0.35527897 -0.72605324\n",
      "   0.92697793]\n",
      " [-0.45403197 -0.37442476 -0.32967806 ... -0.35527897 -0.96069825\n",
      "   0.6627669 ]\n",
      " [-0.45403197 -0.37442476 -0.32967806 ... -0.35527897  1.1415668\n",
      "  -1.163222  ]\n",
      " ...\n",
      " [-0.45403197 -0.37442476 -0.32967806 ... -0.35527897  1.0570487\n",
      "   0.7307364 ]\n",
      " [-0.45403197 -0.37442476 -0.32967806 ... -0.35527897  0.9623134\n",
      "   0.86065674]\n",
      " [-0.45403197 -0.37442476 -0.32967806 ... -0.35527897 -0.778133\n",
      "   0.7627718 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.38840255 0.40747228 0.41831896 ... 0.41210288 0.32606143 0.7164618 ]\n",
      " [0.38840255 0.40747228 0.41831896 ... 0.41210288 0.27673844 0.65988165]\n",
      " [0.38840255 0.40747228 0.41831896 ... 0.41210288 0.75796723 0.23808233]\n",
      " ...\n",
      " [0.38840255 0.40747228 0.41831896 ... 0.41210288 0.74212617 0.6749668 ]\n",
      " [0.38840255 0.40747228 0.41831896 ... 0.41210288 0.7235848  0.7027979 ]\n",
      " [0.38840255 0.40747228 0.41831896 ... 0.41210288 0.31472242 0.6819552 ]] (3.560 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8520289, step = 400 (3.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8346\n",
      "INFO:tensorflow:acc = 0.9117187, acc_row = 0.11328125, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.38412708 -0.2909021  -0.3486532  ...  0.56700057  0.895839\n",
      "  -1.3030441 ]\n",
      " [-0.38412708 -0.2909021  -0.3486532  ...  0.49389714  1.0574023\n",
      "  -1.2424117 ]\n",
      " [-0.38412708 -0.2909021  -0.3486532  ... -0.31295815  0.7053568\n",
      "   0.79295784]\n",
      " ...\n",
      " [-0.38412708 -0.2909021  -0.3486532  ... -0.31295815  1.1311361\n",
      "   0.6800035 ]\n",
      " [-0.38412708 -0.2909021  -0.3486532  ... -0.31295815  0.8144871\n",
      "   0.65970856]\n",
      " [-0.38412708 -0.2909021  -0.3486532  ... -0.31295815 -1.0101833\n",
      "   0.9182414 ]], predicted_classes = [[0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.40513188 0.42778304 0.41370904 ... 0.63807076 0.7100937  0.21365315]\n",
      " [0.40513188 0.42778304 0.41370904 ... 0.6210241  0.7421938  0.22401646]\n",
      " [0.40513188 0.42778304 0.41370904 ... 0.42239285 0.6693744  0.6884661 ]\n",
      " ...\n",
      " [0.40513188 0.42778304 0.41370904 ... 0.42239285 0.75604844 0.6637395 ]\n",
      " [0.40513188 0.42778304 0.41370904 ... 0.42239285 0.69306487 0.65919495]\n",
      " [0.40513188 0.42778304 0.41370904 ... 0.42239285 0.266944   0.71468365]] (3.592 sec)\n",
      "INFO:tensorflow:loss = 0.84971625, step = 500 (3.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8757\n",
      "INFO:tensorflow:acc = 0.91546875, acc_row = 0.1328125, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.38255322 -0.34956884 -0.38112277 ... -0.31592748  1.3038532\n",
      "   0.8601437 ]\n",
      " [-0.38255322 -0.34956884 -0.38112277 ... -0.31592748 -0.80924666\n",
      "   0.66797435]\n",
      " [ 3.1044247  -0.34956884 -0.38112277 ... -0.31592748 -0.8335228\n",
      "  -1.101361  ]\n",
      " ...\n",
      " [-0.38255322 -0.34956884 -0.38112277 ...  4.116326   -0.8335228\n",
      "  -1.1963214 ]\n",
      " [-0.38255322 -0.34956884 -0.38112277 ...  3.1505775  -0.8335228\n",
      "   0.11004266]\n",
      " [-0.38255322 -0.34956884 -0.38112277 ... -0.31592748 -0.8335228\n",
      "   0.8909698 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.40551123 0.413487   0.40585613 ... 0.4216686  0.78648275 0.7026907 ]\n",
      " [0.40551123 0.413487   0.40585613 ... 0.4216686  0.30805105 0.6610495 ]\n",
      " [0.9570749  0.413487   0.40585613 ... 0.4216686  0.3029007  0.24948494]\n",
      " ...\n",
      " [0.40551123 0.413487   0.40585613 ... 0.9839573  0.3029007  0.23213026]\n",
      " [0.40551123 0.413487   0.40585613 ... 0.9589315  0.3029007  0.5274829 ]\n",
      " [0.40551123 0.413487   0.40585613 ... 0.4216686  0.3029007  0.70909023]] (3.587 sec)\n",
      "INFO:tensorflow:loss = 0.85096985, step = 600 (3.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.286\n",
      "INFO:tensorflow:acc = 0.928125, acc_row = 0.19140625, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-0.40455976 -0.37491506 -0.3654871  ...  0.18353893  0.8261753\n",
      "   0.5276907 ]\n",
      " [-0.40455976 -0.37491506 -0.3654871  ... -0.36486632  1.0413517\n",
      "   0.9325235 ]\n",
      " [-0.40455976 -0.36180663 -0.3654871  ... -0.36486632 -1.0496655\n",
      "  -1.0295881 ]\n",
      " ...\n",
      " [-0.38976747 -0.37491506 -0.3654871  ...  1.7030857  -1.0485871\n",
      "   0.4554769 ]\n",
      " [-0.40455976  2.7382834   0.01869238 ... -0.36486632 -1.0496655\n",
      "  -1.0295881 ]\n",
      " [-0.40455976 -0.37491506 -0.3654871  ... -0.36486632  1.0608517\n",
      "  -1.0295881 ]], predicted_classes = [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.40021732 0.4073539  0.4096319  ... 0.54575634 0.69554555 0.62894434]\n",
      " [0.40021732 0.4073539  0.4096319  ... 0.40978208 0.7391107  0.71758693]\n",
      " [0.40021732 0.4105223  0.4096319  ... 0.40978208 0.25928935 0.26316398]\n",
      " ...\n",
      " [0.40377328 0.4073539  0.4096319  ... 0.8459373  0.2594965  0.6119406 ]\n",
      " [0.40021732 0.9392482  0.50467294 ... 0.40978208 0.25928935 0.26316398]\n",
      " [0.40021732 0.4073539  0.4096319  ... 0.40978208 0.7428533  0.26316398]] (3.665 sec)\n",
      "INFO:tensorflow:loss = 0.84499705, step = 700 (3.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.652\n",
      "INFO:tensorflow:acc = 0.9378125, acc_row = 0.25, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.43365967 -0.36931783  1.6826766  ... -0.3381352   1.1311431\n",
      "   0.66450894]\n",
      " [-0.43365967  3.0792842  -0.3589791  ... -0.3381352  -0.90515107\n",
      "  -1.1658278 ]\n",
      " [-0.43365967 -0.36931783 -0.3589791  ... -0.0440747  -0.90515107\n",
      "  -1.1658278 ]\n",
      " ...\n",
      " [-0.43365967 -0.36931783 -0.3589791  ... -0.3381352  -0.87263113\n",
      "   0.84116507]\n",
      " [-0.43365967 -0.36931783 -0.3589791  ... -0.3381352  -0.90515107\n",
      "   0.6880009 ]\n",
      " [-0.43365967 -0.36931783  0.08028819 ... -0.3381352   0.99542046\n",
      "   0.8150826 ]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]], prob = [[0.3932528  0.4087059  0.8432586  ... 0.4162625  0.75604975 0.66027254]\n",
      " [0.3932528  0.95603013 0.4112067  ... 0.4162625  0.2879931  0.23760994]\n",
      " [0.3932528  0.4087059  0.4112067  ... 0.48898312 0.2879931  0.23760994]\n",
      " ...\n",
      " [0.3932528  0.4087059  0.4112067  ... 0.4162625  0.29470712 0.6987105 ]\n",
      " [0.3932528  0.4087059  0.4112067  ... 0.4162625  0.2879931  0.6655221 ]\n",
      " [0.3932528  0.4087059  0.52006125 ... 0.4162625  0.73015726 0.6931915 ]] (3.616 sec)\n",
      "INFO:tensorflow:loss = 0.84295565, step = 800 (3.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7284\n",
      "INFO:tensorflow:acc = 0.93796873, acc_row = 0.21875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.45293617 -0.36094937 -0.35191077 ... -0.38722154  0.95934314\n",
      "   0.7917232 ]\n",
      " [-0.45293617 -0.36094937 -0.35191077 ... -0.38722154  0.9669106\n",
      "   0.86168385]\n",
      " [-0.45293617 -0.36094937 -0.35191077 ... -0.38722154  0.9844074\n",
      "   0.86481434]\n",
      " ...\n",
      " [-0.04334827 -0.36094937  3.7837067  ... -0.38722154 -0.94806665\n",
      "   0.77300155]\n",
      " [-0.45293617 -0.36094937 -0.35191077 ... -0.38722154  1.1359379\n",
      "   0.7918562 ]\n",
      " [-0.45293617 -0.36094937 -0.35191077 ... -0.38722154 -0.94806665\n",
      "   0.98628503]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.3886629  0.41072974 0.41291916 ... 0.40438634 0.7229903  0.68820125]\n",
      " [0.3886629  0.41072974 0.41291916 ... 0.40438634 0.72450334 0.7030123 ]\n",
      " [0.3886629  0.41072974 0.41291916 ... 0.40438634 0.72798187 0.70366555]\n",
      " ...\n",
      " [0.48916462 0.41072974 0.9777673  ... 0.40438634 0.2792738  0.6841698 ]\n",
      " [0.3886629  0.41072974 0.41291916 ... 0.40438634 0.7569331  0.68822974]\n",
      " [0.3886629  0.41072974 0.41291916 ... 0.40438634 0.2792738  0.72835356]] (3.607 sec)\n",
      "INFO:tensorflow:loss = 0.8398682, step = 900 (3.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6752\n",
      "INFO:tensorflow:acc = 0.95, acc_row = 0.29296875, labels = [[0 0 1 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.468925   -0.35307863  3.617564   ... -0.33416444 -1.0269817\n",
      "   0.81273156]\n",
      " [ 2.9143047  -0.35307863 -0.43024904 ... -0.33416444 -0.9500006\n",
      "  -1.2244056 ]\n",
      " [-0.468925   -0.35307863  2.6859646  ... -0.33416444  0.9005164\n",
      "   0.9048198 ]\n",
      " ...\n",
      " [-0.468925   -0.35307863 -0.43024904 ... -0.33416444 -1.0269817\n",
      "   0.89732456]\n",
      " [-0.468925   -0.35307863 -0.43024904 ...  3.1514866   1.0208082\n",
      "  -1.1822554 ]\n",
      " [-0.468925   -0.35307863 -0.43024904 ... -0.17445305  1.0428749\n",
      "   0.858416  ]], predicted_classes = [[0. 0. 1. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.3848707  0.41263607 0.973854   ... 0.4172277  0.2636697  0.6926913 ]\n",
      " [0.94854903 0.41263607 0.39406684 ... 0.4172277  0.2788847  0.22716206]\n",
      " [0.3848707  0.41263607 0.93619335 ... 0.4172277  0.7110556  0.711939  ]\n",
      " ...\n",
      " [0.3848707  0.41263607 0.39406684 ... 0.4172277  0.2636697  0.7103994 ]\n",
      " [0.3848707  0.41263607 0.39406684 ... 0.9589672  0.73513    0.2346469 ]\n",
      " [0.3848707  0.41263607 0.39406684 ... 0.45649698 0.7394043  0.70232964]] (3.613 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.83620393, step = 1000 (3.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6824\n",
      "INFO:tensorflow:acc = 0.951875, acc_row = 0.26171875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.42256233 -0.38841125 -0.43235934 ... -0.35476148  1.1774629\n",
      "   0.7827637 ]\n",
      " [-0.42256233 -0.38841125 -0.43235934 ... -0.35476148 -0.92022383\n",
      "   0.8206483 ]\n",
      " [-0.42256233 -0.38841125 -0.10381985 ... -0.35476148 -0.7419352\n",
      "   0.81027836]\n",
      " ...\n",
      " [-0.42256233 -0.38841125 -0.43235934 ... -0.35476148 -0.92022383\n",
      "   0.8291425 ]\n",
      " [-0.42256233 -0.38841125 -0.43235934 ... -0.35476148 -0.92022383\n",
      "   0.82725525]\n",
      " [-0.42256233 -0.38841125 -0.43235934 ... -0.35476148 -0.92022383\n",
      "   0.7769453 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.39590374 0.40409982 0.39356306 ... 0.4122283  0.7644913  0.6862754 ]\n",
      " [0.39590374 0.40409982 0.39356306 ... 0.4122283  0.2849123  0.69437397]\n",
      " [0.39590374 0.40409982 0.47406828 ... 0.4122283  0.3225811  0.69216883]\n",
      " ...\n",
      " [0.39590374 0.40409982 0.39356306 ... 0.4122283  0.2849123  0.6961736 ]\n",
      " [0.39590374 0.40409982 0.39356306 ... 0.4122283  0.2849123  0.69577426]\n",
      " [0.39590374 0.40409982 0.39356306 ... 0.4122283  0.2849123  0.6850214 ]] (3.613 sec)\n",
      "INFO:tensorflow:loss = 0.83762467, step = 1100 (3.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8724\n",
      "INFO:tensorflow:acc = 0.9496875, acc_row = 0.25390625, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.46364954 -0.40398636 -0.39737713 ... -0.36104086  1.0143288\n",
      "   0.9817299 ]\n",
      " [ 0.25112268 -0.40398636 -0.39737713 ...  0.0476701  -0.9737445\n",
      "   0.8696214 ]\n",
      " [-0.46364954 -0.40398636  3.2469087  ... -0.36104086  1.1461952\n",
      "   0.8466044 ]\n",
      " ...\n",
      " [-0.46364954 -0.40398636 -0.39737713 ... -0.36104086 -0.9737445\n",
      "   0.8572313 ]\n",
      " [-0.46364954 -0.40398636 -0.39737713 ... -0.36104086  0.9914411\n",
      "   0.81686777]\n",
      " [-0.46364954 -0.40398636 -0.39737713 ... -0.36104086 -0.9737445\n",
      "  -1.1287895 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.3861204  0.40035492 0.40194267 ... 0.41070762 0.73386645 0.7274513 ]\n",
      " [0.5624528  0.40035492 0.40194267 ... 0.51191527 0.27413478 0.7046669 ]\n",
      " [0.3861204  0.40035492 0.96256185 ... 0.41070762 0.7588153  0.6998543 ]\n",
      " ...\n",
      " [0.3861204  0.40035492 0.40194267 ... 0.41070762 0.27413478 0.7020819 ]\n",
      " [0.3861204  0.40035492 0.40194267 ... 0.41070762 0.7293725  0.69357103]\n",
      " [0.3861204  0.40035492 0.40194267 ... 0.41070762 0.27413478 0.24438457]] (3.587 sec)\n",
      "INFO:tensorflow:loss = 0.83263254, step = 1200 (3.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8151\n",
      "INFO:tensorflow:acc = 0.95375, acc_row = 0.27734375, labels = [[1 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[ 1.9667642  -0.3524258  -0.41723824 ... -0.39181942  1.2706021\n",
      "   0.8042877 ]\n",
      " [-0.5073911  -0.3524258  -0.41723824 ... -0.39181942  1.1109983\n",
      "   0.6837939 ]\n",
      " [-0.45783395 -0.3524258   2.4770765  ... -0.39181942  0.9769636\n",
      "  -1.2237751 ]\n",
      " ...\n",
      " [-0.5073911  -0.3524258  -0.41723824 ... -0.39181942  1.1588755\n",
      "   0.90019983]\n",
      " [-0.5073911  -0.3524258  -0.41723824 ... -0.39181942 -0.9285075\n",
      "   0.91469723]\n",
      " [-0.5073911  -0.3524258  -0.41723824 ... -0.39181942  1.1841326\n",
      "   0.90901536]], predicted_classes = [[1. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.8772632  0.41279432 0.3971778  ... 0.4032794  0.7808458  0.6908909 ]\n",
      " [0.37580532 0.41279432 0.3971778  ... 0.4032794  0.75231516 0.66458493]\n",
      " [0.3874998  0.41279432 0.9225191  ... 0.4032794  0.7265053  0.22727278]\n",
      " ...\n",
      " [0.37580532 0.41279432 0.3971778  ... 0.4032794  0.7611283  0.71099055]\n",
      " [0.37580532 0.41279432 0.3971778  ... 0.4032794  0.2832276  0.7139604 ]\n",
      " [0.37580532 0.41279432 0.3971778  ... 0.4032794  0.7656901  0.71279866]] (3.595 sec)\n",
      "INFO:tensorflow:loss = 0.8343256, step = 1300 (3.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7125\n",
      "INFO:tensorflow:acc = 0.9579688, acc_row = 0.30078125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.44637692 -0.30034482 -0.40280855 ... -0.33914542 -1.0818865\n",
      "   0.7755368 ]\n",
      " [-0.29587752  0.640615   -0.40280855 ...  3.10308    -1.0818865\n",
      "  -1.216471  ]\n",
      " [-0.44637692 -0.30034482 -0.40280855 ... -0.33914542 -1.0818865\n",
      "   0.68183935]\n",
      " ...\n",
      " [-0.44637692 -0.30034482 -0.40280855 ...  4.15162    -1.0302023\n",
      "  -1.216471  ]\n",
      " [-0.44637692 -0.30034482 -0.40280855 ... -0.33914542 -1.0818865\n",
      "   0.8263195 ]\n",
      " [-0.44637692 -0.30034482 -0.40280855 ... -0.33914542  0.8377092\n",
      "   0.7916219 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.39022255 0.42547318 0.40063778 ... 0.41601706 0.25314918 0.68471736]\n",
      " [0.42656556 0.65489244 0.40063778 ... 0.9570196  0.25314918 0.22855811]\n",
      " [0.39022255 0.42547318 0.40063778 ... 0.41601706 0.25314918 0.6641491 ]\n",
      " ...\n",
      " [0.39022255 0.42547318 0.40063778 ... 0.98450506 0.2630449  0.22855811]\n",
      " [0.39022255 0.42547318 0.40063778 ... 0.41601706 0.25314918 0.69557613]\n",
      " [0.39022255 0.42547318 0.40063778 ... 0.41601706 0.69798255 0.6881795 ]] (3.608 sec)\n",
      "INFO:tensorflow:loss = 0.8351506, step = 1400 (3.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9889\n",
      "INFO:tensorflow:acc = 0.95984375, acc_row = 0.34765625, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.50917417 -0.3784615  -0.50156474 ... -0.40813857 -1.0232971\n",
      "   0.8956339 ]\n",
      " [-0.50917417 -0.3784615  -0.50156474 ... -0.40813857  1.0111599\n",
      "   0.91196305]\n",
      " [-0.50917417 -0.3784615  -0.50156474 ... -0.40813857 -1.0232971\n",
      "   0.8889503 ]\n",
      " ...\n",
      " [-0.50917417 -0.3784615  -0.50156474 ... -0.40813857 -1.0232971\n",
      "   0.7460916 ]\n",
      " [-0.50917417 -0.3784615  -0.50156474 ... -0.40813857 -1.0232971\n",
      "   0.8222631 ]\n",
      " [-0.50917417 -0.3784615  -0.50156474 ... -0.40813857 -0.9836431\n",
      "  -1.1988552 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.37538713 0.406498   0.37717304 ... 0.39935857 0.26438567 0.7100514 ]\n",
      " [0.37538713 0.406498   0.37717304 ... 0.39935857 0.7332471  0.7134017 ]\n",
      " [0.37538713 0.406498   0.37717304 ... 0.39935857 0.26438567 0.70867354]\n",
      " ...\n",
      " [0.37538713 0.406498   0.37717304 ... 0.39935857 0.26438567 0.6783265 ]\n",
      " [0.37538713 0.406498   0.37717304 ... 0.39935857 0.26438567 0.6947166 ]\n",
      " [0.37538713 0.406498   0.37717304 ... 0.39935857 0.27216953 0.23167895]] (3.573 sec)\n",
      "INFO:tensorflow:loss = 0.82990646, step = 1500 (3.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5093\n",
      "INFO:tensorflow:acc = 0.9639062, acc_row = 0.34375, labels = [[0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.47764575 -0.33043832  3.4284055  ... -0.36064607  0.86350715\n",
      "   0.7795495 ]\n",
      " [-0.47764575 -0.33043832 -0.44268966 ... -0.36064607 -1.0735039\n",
      "   0.85377663]\n",
      " [-0.47764575 -0.33043832 -0.44268966 ... -0.36064607 -1.0735039\n",
      "  -1.2164448 ]\n",
      " ...\n",
      " [-0.47764575 -0.33043832 -0.44268966 ... -0.36064607  0.92959076\n",
      "   0.8351463 ]\n",
      " [-0.47764575 -0.33043832 -0.44268966 ... -0.36064607 -1.0735039\n",
      "   0.8684117 ]\n",
      " [-0.47764575 -0.33043832 -0.44268966 ... -0.36064607  0.9291239\n",
      "   0.82254905]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.3828082  0.418134   0.96858054 ... 0.41080317 0.70339286 0.685583  ]\n",
      " [0.3828082  0.418134   0.39110026 ... 0.41080317 0.25473732 0.7013588 ]\n",
      " [0.3828082  0.418134   0.39110026 ... 0.41080317 0.25473732 0.22856271]\n",
      " ...\n",
      " [0.3828082  0.418134   0.39110026 ... 0.41080317 0.71699226 0.697442  ]\n",
      " [0.3828082  0.418134   0.39110026 ... 0.41080317 0.25473732 0.70441514]\n",
      " [0.3828082  0.418134   0.39110026 ... 0.41080317 0.71689755 0.69477713]] (3.636 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8357204, step = 1600 (3.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5376\n",
      "INFO:tensorflow:acc = 0.96125, acc_row = 0.30859375, labels = [[0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.5242212   3.231011   -0.4631642  ...  2.948254   -1.0386958\n",
      "  -1.2027837 ]\n",
      " [-0.5242212  -0.34337288  3.2719572  ... -0.44051227  0.87774175\n",
      "   0.75025976]\n",
      " [-0.5242212  -0.34337288 -0.4631642  ... -0.44051227  0.9854073\n",
      "  -1.2027837 ]\n",
      " ...\n",
      " [-0.5242212  -0.32494855 -0.4631642  ... -0.44051227 -1.0386958\n",
      "  -1.2027837 ]\n",
      " [-0.5242212  -0.34337288 -0.4631642  ... -0.44051227  0.98637843\n",
      "   0.83249146]\n",
      " [-0.5242212  -0.34337288 -0.4631642  ... -0.44051227 -1.0386958\n",
      "   0.82968163]], predicted_classes = [[0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.37186572 0.96198475 0.38623548 ... 0.95018095 0.2614017  0.23098038]\n",
      " [0.37186572 0.41499043 0.9634541  ... 0.39161888 0.706354   0.67923534]\n",
      " [0.37186572 0.41499043 0.38623548 ... 0.39161888 0.7281798  0.23098038]\n",
      " ...\n",
      " [0.37186572 0.41947022 0.38623548 ... 0.39161888 0.2614017  0.23098038]\n",
      " [0.37186572 0.41499043 0.38623548 ... 0.39161888 0.72837204 0.69688153]\n",
      " [0.37186572 0.41499043 0.38623548 ... 0.39161888 0.2614017  0.69628763]] (3.631 sec)\n",
      "INFO:tensorflow:loss = 0.8296853, step = 1700 (3.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6931\n",
      "INFO:tensorflow:acc = 0.96015626, acc_row = 0.3125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.5398786  -0.42432195 -0.45782602 ... -0.42229724 -0.9954297\n",
      "   0.8225268 ]\n",
      " [-0.5398786  -0.42432195 -0.45782602 ... -0.42229724  1.0100336\n",
      "   0.8226039 ]\n",
      " [ 2.6993084   3.4343133  -0.45782602 ... -0.42229724 -0.9954297\n",
      "  -1.163048  ]\n",
      " ...\n",
      " [-0.5398786  -0.42432195 -0.45782602 ... -0.42229724 -0.9954297\n",
      "   0.9310813 ]\n",
      " [-0.5398786  -0.42432195 -0.45782602 ... -0.42229724 -0.9954297\n",
      "   0.8911127 ]\n",
      " [-0.5398786  -0.42432195 -0.45782602 ... -0.42229724  0.8733156\n",
      "   0.98728454]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.36821586 0.39548305 0.38750166 ... 0.39596716 0.26984096 0.6947724 ]\n",
      " [0.36821586 0.39548305 0.38750166 ... 0.39596716 0.7330267  0.69478875]\n",
      " [0.9369858  0.9687599  0.38750166 ... 0.39596716 0.26984096 0.2381139 ]\n",
      " ...\n",
      " [0.36821586 0.39548305 0.38750166 ... 0.39596716 0.26984096 0.7172946 ]\n",
      " [0.36821586 0.39548305 0.38750166 ... 0.39596716 0.26984096 0.70911974]\n",
      " [0.36821586 0.39548305 0.38750166 ... 0.39596716 0.70543516 0.7285512 ]] (3.611 sec)\n",
      "INFO:tensorflow:loss = 0.8278746, step = 1800 (3.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9944\n",
      "INFO:tensorflow:acc = 0.961875, acc_row = 0.3203125, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-0.4757333  -0.39815354 -0.54710835 ... -0.34289837 -1.1493132\n",
      "  -1.3610206 ]\n",
      " [-0.4757333  -0.39815354 -0.54710835 ... -0.34289837  0.9037514\n",
      "  -1.3610206 ]\n",
      " [-0.4757333  -0.39815354 -0.54710835 ... -0.34289837 -1.1493132\n",
      "   0.8060079 ]\n",
      " ...\n",
      " [-0.4757333  -0.39815354 -0.54710835 ... -0.34289837  0.8648535\n",
      "   0.7616295 ]\n",
      " [-0.4757333  -0.39815354 -0.54710835 ... -0.34289837  0.97670966\n",
      "   0.80165905]\n",
      " [-0.4757333  -0.39815354 -0.54710835 ... -0.34289837  0.85333645\n",
      "  -1.3610206 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.38326016 0.40175602 0.36653554 ... 0.41510558 0.24061453 0.2040745 ]\n",
      " [0.38326016 0.40175602 0.36653554 ... 0.41510558 0.7117198  0.2040745 ]\n",
      " [0.38326016 0.40175602 0.36653554 ... 0.41510558 0.24061453 0.6912582 ]\n",
      " ...\n",
      " [0.38326016 0.40175602 0.36653554 ... 0.41510558 0.70367366 0.6817074 ]\n",
      " [0.38326016 0.40175602 0.36653554 ... 0.41510558 0.72645485 0.69032925]\n",
      " [0.38326016 0.40175602 0.36653554 ... 0.41510558 0.7012665  0.2040745 ]] (3.573 sec)\n",
      "INFO:tensorflow:loss = 0.8233702, step = 1900 (3.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8227\n",
      "INFO:tensorflow:acc = 0.96828127, acc_row = 0.421875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.56236297 -0.38782993 -0.4917124  ... -0.39072374  0.9035434\n",
      "   0.8251342 ]\n",
      " [-0.56236297 -0.38782993 -0.4917124  ... -0.39072374 -1.0954808\n",
      "  -1.1810272 ]\n",
      " [-0.56236297 -0.38782993 -0.4917124  ... -0.39072374 -1.0954808\n",
      "  -1.1810272 ]\n",
      " ...\n",
      " [-0.56236297 -0.38782993 -0.4917124  ... -0.39072374  0.97410953\n",
      "   0.8521701 ]\n",
      " [-0.56236297 -0.38782993 -0.4917124  ... -0.39072374  0.9219133\n",
      "  -1.1810272 ]\n",
      " [-0.56236297 -0.38782993 -0.4917124  ... -0.39072374 -1.0954808\n",
      "   0.8694028 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.3630009  0.4042398  0.37949026 ... 0.40354308 0.71167713 0.69532514]\n",
      " [0.3630009  0.4042398  0.37949026 ... 0.40354308 0.2505876  0.23486757]\n",
      " [0.3630009  0.4042398  0.37949026 ... 0.40354308 0.2505876  0.23486757]\n",
      " ...\n",
      " [0.3630009  0.4042398  0.37949026 ... 0.40354308 0.72593784 0.70102215]\n",
      " [0.3630009  0.4042398  0.37949026 ... 0.40354308 0.7154318  0.23486757]\n",
      " [0.3630009  0.4042398  0.37949026 ... 0.40354308 0.2505876  0.7046214 ]] (3.594 sec)\n",
      "INFO:tensorflow:loss = 0.82642794, step = 2000 (3.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7638\n",
      "INFO:tensorflow:acc = 0.9632813, acc_row = 0.3203125, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.49663338 -0.01601367 -0.5328745  ... -0.45323938 -1.0659496\n",
      "  -1.2133653 ]\n",
      " [-0.49663338 -0.38444996 -0.5328745  ... -0.45323938  0.835613\n",
      "  -1.2133653 ]\n",
      " [-0.49663338 -0.38444996 -0.5328745  ... -0.45323938  0.8024365\n",
      "   0.78892255]\n",
      " ...\n",
      " [-0.49663338 -0.38444996 -0.5328745  ... -0.45323938 -1.153974\n",
      "   0.79805416]\n",
      " [-0.49663338 -0.38444996 -0.5328745  ... -0.45323938 -1.153974\n",
      "   0.9098439 ]\n",
      " [-0.49663338 -0.38444996 -0.5328745  ... -0.45323938  0.8504434\n",
      "   0.82587904]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.37833217 0.4959967  0.3698467  ... 0.3885908  0.25617412 0.22910614]\n",
      " [0.37833217 0.40505406 0.3698467  ... 0.3885908  0.69754046 0.22910614]\n",
      " [0.37833217 0.40505406 0.3698467  ... 0.3885908  0.69049543 0.68759996]\n",
      " ...\n",
      " [0.37833217 0.40505406 0.3698467  ... 0.3885908  0.23976396 0.6895581 ]\n",
      " [0.37833217 0.40505406 0.3698467  ... 0.3885908  0.23976396 0.71296823]\n",
      " [0.37833217 0.40505406 0.3698467  ... 0.3885908  0.7006602  0.69548285]] (3.602 sec)\n",
      "INFO:tensorflow:loss = 0.8270133, step = 2100 (3.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6802\n",
      "INFO:tensorflow:acc = 0.96453124, acc_row = 0.3359375, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.5871098  -0.39811987 -0.5354841  ... -0.46498132  0.9692486\n",
      "   0.82951355]\n",
      " [-0.5871098  -0.39811987 -0.5354841  ... -0.46498132 -1.0780615\n",
      "   0.9298611 ]\n",
      " [-0.5871098  -0.39811987 -0.5354841  ... -0.46498132  0.89359766\n",
      "  -1.1501187 ]\n",
      " ...\n",
      " [-0.5871098  -0.39811987 -0.5354841  ... -0.46498132  0.8364624\n",
      "  -1.1501187 ]\n",
      " [-0.5871098  -0.39811987 -0.5354841  ...  3.88766     1.1642659\n",
      "   0.60116106]\n",
      " [-0.5871098  -0.39811987 -0.5354841  ... -0.46498132  0.90204054\n",
      "   0.8901525 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.35729825 0.40176415 0.36923873 ... 0.3858048  0.72496974 0.6962521 ]\n",
      " [0.35729825 0.40176415 0.36923873 ... 0.3858048  0.25387305 0.7170471 ]\n",
      " [0.35729825 0.40176415 0.36923873 ... 0.3858048  0.70963204 0.2404674 ]\n",
      " ...\n",
      " [0.35729825 0.40176415 0.36923873 ... 0.3858048  0.69771963 0.2404674 ]\n",
      " [0.35729825 0.40176415 0.36923873 ... 0.97991824 0.762107   0.6459219 ]\n",
      " [0.35729825 0.40176415 0.36923873 ... 0.3858048  0.7113687  0.7089216 ]] (3.613 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8242402, step = 2200 (3.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9952\n",
      "INFO:tensorflow:acc = 0.965625, acc_row = 0.3828125, labels = [[1 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[ 2.391882   -0.39658257 -0.566756   ... -0.5188727  -1.2847178\n",
      "   0.94164395]\n",
      " [-0.5772325  -0.39658257  2.4512632  ... -0.5188727   0.652358\n",
      "   0.90179807]\n",
      " [-0.5772325  -0.39658257 -0.566756   ... -0.5188727  -1.2847178\n",
      "  -1.1547701 ]\n",
      " ...\n",
      " [-0.5772325  -0.39658257 -0.566756   ... -0.5188727  -1.2847178\n",
      "  -1.1547701 ]\n",
      " [-0.5772325  -0.39658257  2.7422507  ... -0.5188727   0.6822201\n",
      "   0.83395976]\n",
      " [-0.5772325  -0.39658257 -0.566756   ... -0.5188727   0.6413735\n",
      "   0.93093765]], predicted_classes = [[1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.9162062  0.40213367 0.36198568 ... 0.3731159  0.21674822 0.71943164]\n",
      " [0.35956967 0.40213367 0.9206538  ... 0.3731159  0.65754163 0.71131885]\n",
      " [0.35956967 0.40213367 0.36198568 ... 0.3731159  0.21674822 0.23961887]\n",
      " ...\n",
      " [0.35956967 0.40213367 0.36198568 ... 0.3731159  0.21674822 0.23961887]\n",
      " [0.35956967 0.40213367 0.93947417 ... 0.3731159  0.66423404 0.69719154]\n",
      " [0.35956967 0.40213367 0.36198568 ... 0.3731159  0.65506387 0.7172655 ]] (3.572 sec)\n",
      "INFO:tensorflow:loss = 0.8182545, step = 2300 (3.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.325\n",
      "INFO:tensorflow:acc = 0.96015626, acc_row = 0.33984375, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.5756643  -0.4870528  -0.4924925  ... -0.55261576  0.8824139\n",
      "   0.83801913]\n",
      " [-0.5756643  -0.4870528  -0.4924925  ... -0.55261576  0.8824139\n",
      "   0.83801913]\n",
      " [-0.5756643  -0.4870528  -0.4924925  ... -0.55261576  0.8482172\n",
      "   0.8436676 ]\n",
      " ...\n",
      " [-0.5756643  -0.4870528  -0.4924925  ... -0.55261576  0.9355064\n",
      "  -1.1864794 ]\n",
      " [-0.5756643  -0.4870528  -0.4924925  ...  3.0585225  -0.90025353\n",
      "  -1.1864794 ]\n",
      " [-0.5756643  -0.4870528  -0.4924925  ... -0.55261576  0.902407\n",
      "   0.80449086]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.35993084 0.3805881  0.37930658 ... 0.36525774 0.70732224 0.6980479 ]\n",
      " [0.35993084 0.3805881  0.37930658 ... 0.36525774 0.70732224 0.6980479 ]\n",
      " [0.35993084 0.3805881  0.37930658 ... 0.36525774 0.70019305 0.6992371 ]\n",
      " ...\n",
      " [0.35993084 0.3805881  0.37930658 ... 0.36525774 0.718191   0.23388919]\n",
      " [0.35993084 0.3805881  0.37930658 ... 0.95514905 0.2889984  0.23388919]\n",
      " [0.35993084 0.3805881  0.37930658 ... 0.36525774 0.7114439  0.69093424]] (3.660 sec)\n",
      "INFO:tensorflow:loss = 0.8204715, step = 2400 (3.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7951\n",
      "INFO:tensorflow:acc = 0.9675, acc_row = 0.375, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 1 1 1]], logits = [[-0.5584786  -0.4738906  -0.56895316 ... -0.4556479  -1.095619\n",
      "  -1.266182  ]\n",
      " [-0.5584786  -0.4738906  -0.56895316 ... -0.4556479  -1.095619\n",
      "  -1.266182  ]\n",
      " [-0.5584786  -0.4738906  -0.56895316 ... -0.4556479  -1.095619\n",
      "   0.78114986]\n",
      " ...\n",
      " [ 2.88971     3.9664767  -0.56895316 ... -0.4556479  -1.095619\n",
      "  -1.266182  ]\n",
      " [-0.5584786  -0.4738906  -0.56895316 ... -0.4556479   0.9993956\n",
      "   0.7927479 ]\n",
      " [-0.5584786  -0.4738906  -0.56895316 ...  4.3219995   1.2514621\n",
      "   0.8385907 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]], prob = [[0.36389956 0.3836958  0.36147842 ... 0.38801876 0.25056165 0.21991153]\n",
      " [0.36389956 0.3836958  0.36147842 ... 0.38801876 0.25056165 0.21991153]\n",
      " [0.36389956 0.3836958  0.36147842 ... 0.38801876 0.25056165 0.68592787]\n",
      " ...\n",
      " [0.9473354  0.981412   0.36147842 ... 0.38801876 0.25056165 0.21991153]\n",
      " [0.36389956 0.3836958  0.36147842 ... 0.38801876 0.73093975 0.6884211 ]\n",
      " [0.36389956 0.3836958  0.36147842 ... 0.9869005  0.77755284 0.6981683 ]] (3.597 sec)\n",
      "INFO:tensorflow:loss = 0.819364, step = 2500 (3.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6879\n",
      "INFO:tensorflow:acc = 0.9665625, acc_row = 0.37109375, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.5617853  -0.45395327 -0.55264705 ...  1.8758199  -1.1003073\n",
      "  -1.1883416 ]\n",
      " [-0.5617853  -0.45395327 -0.55264705 ... -0.51299834  0.94789267\n",
      "   0.8481633 ]\n",
      " [-0.5617853  -0.45395327 -0.55264705 ... -0.51299834  0.87784237\n",
      "   0.82690954]\n",
      " ...\n",
      " [-0.5617853  -0.45395327 -0.55264705 ... -0.51299834 -1.1361151\n",
      "  -1.1883416 ]\n",
      " [-0.5617853  -0.45395327 -0.55264705 ... -0.51299834 -1.1361151\n",
      "   0.92044646]\n",
      " [-0.5617853  -0.45395327 -0.55264705 ... -0.51299834 -1.1361151\n",
      "   0.87492657]], predicted_classes = [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.36313447 0.38842127 0.36525047 ... 0.8671303  0.24968229 0.23355567]\n",
      " [0.36313447 0.38842127 0.36525047 ... 0.3744909  0.72069114 0.7001817 ]\n",
      " [0.36313447 0.38842127 0.36525047 ... 0.3744909  0.7063749  0.6957011 ]\n",
      " ...\n",
      " [0.36313447 0.38842127 0.36525047 ... 0.3744909  0.24303433 0.23355567]\n",
      " [0.36313447 0.38842127 0.36525047 ... 0.3744909  0.24303433 0.7151331 ]\n",
      " [0.36313447 0.38842127 0.36525047 ... 0.3744909  0.24303433 0.7057698 ]] (3.611 sec)\n",
      "INFO:tensorflow:loss = 0.8205621, step = 2600 (3.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7732\n",
      "INFO:tensorflow:acc = 0.9653125, acc_row = 0.33203125, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.63561547 -0.5104109  -0.5332377  ... -0.49813074  1.0173575\n",
      "   0.8124598 ]\n",
      " [-0.63561547 -0.5104109  -0.5332377  ... -0.49813074 -1.0464973\n",
      "   0.91678673]\n",
      " [ 2.5305245  -0.5104109  -0.5332377  ... -0.49813074 -1.0464973\n",
      "  -1.1237636 ]\n",
      " ...\n",
      " [-0.63561547 -0.5104109  -0.5332377  ... -0.49813074 -1.0464973\n",
      "  -1.1237636 ]\n",
      " [-0.63561547 -0.5104109  -0.5332377  ... -0.49813074 -1.0464973\n",
      "   0.8559785 ]\n",
      " [-0.63561547 -0.5104109  -0.5332377  ... -0.49813074 -1.0464973\n",
      "  -1.1237636 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.34623832 0.37509722 0.36976203 ... 0.37798005 0.7344575  0.6926334 ]\n",
      " [0.34623832 0.37509722 0.36976203 ... 0.37798005 0.25989828 0.71438694]\n",
      " [0.92625415 0.37509722 0.36976203 ... 0.37798005 0.25989828 0.24531384]\n",
      " ...\n",
      " [0.34623832 0.37509722 0.36976203 ... 0.37798005 0.25989828 0.24531384]\n",
      " [0.34623832 0.37509722 0.36976203 ... 0.37798005 0.25989828 0.7018198 ]\n",
      " [0.34623832 0.37509722 0.36976203 ... 0.37798005 0.25989828 0.24531384]] (3.602 sec)\n",
      "INFO:tensorflow:loss = 0.8178218, step = 2700 (3.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9223\n",
      "INFO:tensorflow:acc = 0.9632813, acc_row = 0.41015625, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.6114352  -0.43894225 -0.63449013 ...  2.5260932  -1.1305616\n",
      "  -1.2588885 ]\n",
      " [-0.6114352  -0.43894225 -0.63449013 ... -0.57769394  0.88677144\n",
      "   0.7846901 ]\n",
      " [-0.6114352  -0.43894225 -0.63449013 ... -0.56401783 -1.1305616\n",
      "  -1.278233  ]\n",
      " ...\n",
      " [-0.6114352  -0.43894225 -0.63449013 ... -0.57769394 -1.1305616\n",
      "   0.70351243]\n",
      " [-0.586921   -0.43894225  2.0698974  ... -0.57769394  0.86523163\n",
      "   0.74440295]\n",
      " [-0.6114352  -0.43894225 -0.63449013 ... -0.57769394  0.7766375\n",
      "   0.7598275 ]], predicted_classes = [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.3517319  0.39199305 0.34649312 ... 0.92595094 0.24405748 0.22116528]\n",
      " [0.3517319  0.39199305 0.34649312 ... 0.3594634  0.70822346 0.68669003]\n",
      " [0.3517319  0.39199305 0.34649312 ... 0.36261833 0.24405748 0.21785116]\n",
      " ...\n",
      " [0.3517319  0.39199305 0.34649312 ... 0.3594634  0.24405748 0.66896605]\n",
      " [0.35734165 0.39199305 0.88794273 ... 0.3594634  0.7037526  0.67795795]\n",
      " [0.3517319  0.39199305 0.34649312 ... 0.3594634  0.684955   0.6813163 ]] (3.582 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8173962, step = 2800 (3.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.496\n",
      "INFO:tensorflow:acc = 0.98265624, acc_row = 0.6796875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.69900393 -0.5170324  -0.6166175  ... -0.47064576  0.8113609\n",
      "   0.82875896]\n",
      " [-0.69900393 -0.5170324  -0.6166175  ... -0.47064576 -1.1367843\n",
      "   0.69600433]\n",
      " [-0.69900393 -0.5170324  -0.49205214 ... -0.47064576 -1.1367843\n",
      "  -1.1810383 ]\n",
      " ...\n",
      " [-0.69900393 -0.5170324  -0.6166175  ... -0.47064576 -1.1367843\n",
      "  -1.274425  ]\n",
      " [ 1.9462285  -0.5170324  -0.6166175  ... -0.47064576  0.9330112\n",
      "   0.83114314]\n",
      " [-0.69900393 -0.5170324  -0.6166175  ... -0.47064576 -1.1367843\n",
      "   0.6890645 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.3320331  0.37354642 0.35055113 ... 0.3844634  0.69239944 0.6960924 ]\n",
      " [0.3320331  0.37354642 0.35055113 ... 0.3844634  0.24291126 0.66730124]\n",
      " [0.3320331  0.37354642 0.37941024 ... 0.3844634  0.24291126 0.23486556]\n",
      " ...\n",
      " [0.3320331  0.37354642 0.35055113 ... 0.3844634  0.24291126 0.2185007 ]\n",
      " [0.8750348  0.37354642 0.35055113 ... 0.3844634  0.7176858  0.69659656]\n",
      " [0.3320331  0.37354642 0.35055113 ... 0.3844634  0.24291126 0.6657588 ]] (3.636 sec)\n",
      "INFO:tensorflow:loss = 0.8111537, step = 2900 (3.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9528\n",
      "INFO:tensorflow:acc = 0.98390627, acc_row = 0.6875, labels = [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[ 2.344146   -0.4254704  -0.5888958  ... -0.49044845 -1.1521822\n",
      "  -1.3447523 ]\n",
      " [-0.66543156 -0.4254704  -0.5888958  ... -0.49044845  0.89097166\n",
      "   0.74185437]\n",
      " [-0.66543156 -0.4254704  -0.5888958  ... -0.49044845  0.9354901\n",
      "   0.774565  ]\n",
      " ...\n",
      " [-0.66543156 -0.4254704  -0.5888958  ... -0.49044845 -1.1521822\n",
      "   0.66469973]\n",
      " [-0.66543156 -0.4254704  -0.5888958  ... -0.49044845 -1.1521822\n",
      "   0.8048293 ]\n",
      " [-0.66543156 -0.4254704  -0.5888958  ... -0.49044845 -1.1521822\n",
      "   0.75987315]], predicted_classes = [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.9124678  0.39520848 0.35688823 ... 0.37978795 0.24009071 0.20672964]\n",
      " [0.33952054 0.39520848 0.35688823 ... 0.37978795 0.7090907  0.67740124]\n",
      " [0.33952054 0.39520848 0.35688823 ... 0.37978795 0.71818775 0.68450755]\n",
      " ...\n",
      " [0.33952054 0.39520848 0.35688823 ... 0.37978795 0.24009071 0.66031533]\n",
      " [0.33952054 0.39520848 0.35688823 ... 0.37978795 0.24009071 0.69100654]\n",
      " [0.33952054 0.39520848 0.35688823 ... 0.37978795 0.24009071 0.6813262 ]] (3.578 sec)\n",
      "INFO:tensorflow:loss = 0.8132808, step = 3000 (3.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9703\n",
      "INFO:tensorflow:acc = 0.98609376, acc_row = 0.69921875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 1 0 0]], logits = [[-0.59390664 -0.5048065  -0.6525655  ... -0.5278996   0.802625\n",
      "   0.7468423 ]\n",
      " [-0.59390664 -0.5048065  -0.6525655  ... -0.5278996   1.0260218\n",
      "   0.7054766 ]\n",
      " [-0.59390664 -0.5048065  -0.6525655  ... -0.5278996  -1.2013767\n",
      "   0.8373349 ]\n",
      " ...\n",
      " [-0.59390664 -0.5048065  -0.6525655  ... -0.5278996   0.8063449\n",
      "  -1.3309265 ]\n",
      " [-0.59390664 -0.5048065  -0.6525655  ... -0.5278996  -1.2013767\n",
      "   0.842987  ]\n",
      " [-0.59390664 -0.5048065  -0.6525655  ...  4.67244    -1.2013767\n",
      "  -1.3309265 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 0. 0.]], prob = [[0.355739   0.3764118  0.3424116  ... 0.37100688 0.6905357  0.6784903 ]\n",
      " [0.355739   0.3764118  0.3424116  ... 0.37100688 0.7361439  0.6694009 ]\n",
      " [0.355739   0.3764118  0.3424116  ... 0.37100688 0.23123041 0.69790363]\n",
      " ...\n",
      " [0.355739   0.3764118  0.3424116  ... 0.37100688 0.69133013 0.20900615]\n",
      " [0.355739   0.3764118  0.3424116  ... 0.37100688 0.23123041 0.69909394]\n",
      " [0.355739   0.3764118  0.3424116  ... 0.99073714 0.23123041 0.20900615]] (3.576 sec)\n",
      "INFO:tensorflow:loss = 0.8114199, step = 3100 (3.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.773\n",
      "INFO:tensorflow:acc = 0.98328125, acc_row = 0.6796875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.643366   -0.5246779  -0.5396759  ... -0.5418311  -1.1195616\n",
      "   0.883585  ]\n",
      " [-0.643366   -0.5246779  -0.5396759  ... -0.5418311   0.9664619\n",
      "   0.9191435 ]\n",
      " [-0.643366   -0.5246779  -0.5396759  ... -0.5418311   0.89640045\n",
      "  -1.1722283 ]\n",
      " ...\n",
      " [-0.643366   -0.5246779  -0.5396759  ... -0.5418311  -1.1195616\n",
      "   0.79757464]\n",
      " [-0.643366   -0.5246779  -0.5396759  ... -0.5418311  -1.1195616\n",
      "  -1.1722283 ]\n",
      " [-0.643366   -0.5246779  -0.5396759  ... -0.5418311  -1.1195616\n",
      "  -1.1722283 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.3444861  0.37175906 0.36826298 ... 0.36776173 0.2460926  0.70756453]\n",
      " [0.3444861  0.37175906 0.36826298 ... 0.36776173 0.7244137  0.7148676 ]\n",
      " [0.3444861  0.37175906 0.36826298 ... 0.36776173 0.71020925 0.23645243]\n",
      " ...\n",
      " [0.3444861  0.37175906 0.36826298 ... 0.36776173 0.2460926  0.68945545]\n",
      " [0.3444861  0.37175906 0.36826298 ... 0.36776173 0.2460926  0.23645243]\n",
      " [0.3444861  0.37175906 0.36826298 ... 0.36776173 0.2460926  0.23645243]] (3.600 sec)\n",
      "INFO:tensorflow:loss = 0.8080625, step = 3200 (3.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8065\n",
      "INFO:tensorflow:acc = 0.986875, acc_row = 0.73828125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-0.62465644 -0.56053126 -0.5912759  ... -0.52507395 -1.1518528\n",
      "   0.87705547]\n",
      " [-0.62465644 -0.56053126 -0.5912759  ... -0.52507395 -1.1518528\n",
      "   0.86408395]\n",
      " [-0.62465644 -0.56053126 -0.5912759  ... -0.52507395 -1.1518528\n",
      "  -1.1453619 ]\n",
      " ...\n",
      " [-0.62465644 -0.56053126 -0.5912759  ... -0.52507395  0.98949\n",
      "  -1.1453619 ]\n",
      " [ 2.999799   -0.56053126 -0.5912759  ... -0.52507395 -1.1518528\n",
      "  -1.1453619 ]\n",
      " [-0.62465644 -0.56053126 -0.5912759  ... -0.52507395  0.9054114\n",
      "  -1.1453619 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.34872314 0.36342454 0.35634217 ... 0.37166655 0.24015081 0.7062116 ]\n",
      " [0.34872314 0.36342454 0.35634217 ... 0.37166655 0.24015081 0.7035132 ]\n",
      " [0.34872314 0.36342454 0.35634217 ... 0.37166655 0.24015081 0.24133728]\n",
      " ...\n",
      " [0.34872314 0.36342454 0.35634217 ... 0.37166655 0.72898716 0.24133728]\n",
      " [0.9525651  0.36342454 0.35634217 ... 0.37166655 0.24015081 0.24133728]\n",
      " [0.34872314 0.36342454 0.35634217 ... 0.37166655 0.71206033 0.24133728]] (3.597 sec)\n",
      "INFO:tensorflow:loss = 0.80694383, step = 3300 (3.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9808\n",
      "INFO:tensorflow:acc = 0.98390627, acc_row = 0.6875, labels = [[0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 1 1 0]], logits = [[-0.61535895 -0.5394825   2.9862914  ... -0.5346784  -1.220472\n",
      "   0.7704736 ]\n",
      " [-0.61535895 -0.5394825  -0.6709317  ... -0.5346784   0.792007\n",
      "   0.8401282 ]\n",
      " [-0.61535895 -0.5394825  -0.6709317  ... -0.5346784  -1.220472\n",
      "   0.78707   ]\n",
      " ...\n",
      " [-0.61535895 -0.5394825  -0.6709317  ... -0.5346784  -1.220472\n",
      "   0.81841016]\n",
      " [-0.61535895 -0.5394825   2.5877686  ... -0.5346784   0.8092641\n",
      "   0.77546185]\n",
      " [-0.61535895 -0.5394825  -0.6709317  ...  4.88731     0.9021741\n",
      "  -1.3205328 ]], predicted_classes = [[0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]], prob = [[0.3508377  0.368308   0.95195097 ... 0.3694264  0.22785343 0.6836233 ]\n",
      " [0.3508377  0.368308   0.33828825 ... 0.3694264  0.6882621  0.6984922 ]\n",
      " [0.3508377  0.368308   0.33828825 ... 0.3694264  0.22785343 0.6872018 ]\n",
      " ...\n",
      " [0.3508377  0.368308   0.33828825 ... 0.3694264  0.22785343 0.69389874]\n",
      " [0.3508377  0.368308   0.93007016 ... 0.3694264  0.69195265 0.6847012 ]\n",
      " [0.3508377  0.368308   0.33828825 ... 0.9925148  0.71139604 0.21072966]] (3.574 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8087824, step = 3400 (3.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7994\n",
      "INFO:tensorflow:acc = 0.985625, acc_row = 0.6796875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.6777937  -0.539512   -0.6479275  ... -0.54243964  0.8888315\n",
      "   0.6526178 ]\n",
      " [-0.6777937  -0.539512    2.688319   ... -0.54243964  0.76594776\n",
      "  -1.2933825 ]\n",
      " [-0.6777937  -0.539512   -0.6479275  ... -0.54243964  1.0369736\n",
      "   0.7497107 ]\n",
      " ...\n",
      " [-0.6777937  -0.539512   -0.6479275  ... -0.54243964  0.8937197\n",
      "  -1.2933825 ]\n",
      " [-0.6777937  -0.539512   -0.6479275  ... -0.54243964 -1.1097974\n",
      "  -1.2933825 ]\n",
      " [-0.6777937  -0.539512   -0.6479275  ... -0.54243964 -1.1097974\n",
      "   0.82731557]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.3367539  0.36830115 0.34345675 ... 0.36762026 0.708649   0.65760016]\n",
      " [0.3367539  0.36830115 0.9363338  ... 0.36762026 0.68264365 0.21528083]\n",
      " [0.3367539  0.36830115 0.34345675 ... 0.36762026 0.73826563 0.67911565]\n",
      " ...\n",
      " [0.3367539  0.36830115 0.34345675 ... 0.36762026 0.7096572  0.21528083]\n",
      " [0.3367539  0.36830115 0.34345675 ... 0.36762026 0.24790865 0.21528083]\n",
      " [0.3367539  0.36830115 0.34345675 ... 0.36762026 0.24790865 0.695787  ]] (3.597 sec)\n",
      "INFO:tensorflow:loss = 0.80671126, step = 3500 (3.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5077\n",
      "INFO:tensorflow:acc = 0.98515624, acc_row = 0.6953125, labels = [[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-0.7583011  -0.5839714  -0.6392746  ... -0.58103657 -1.2427257\n",
      "  -1.1561601 ]\n",
      " [ 2.3032439  -0.5839714  -0.6392746  ... -0.58103657  0.57312584\n",
      "  -1.1561601 ]\n",
      " [-0.7583011  -0.5839714  -0.6392746  ... -0.58103657 -1.2427257\n",
      "   0.8493308 ]\n",
      " ...\n",
      " [-0.7583011  -0.5839714  -0.6392746  ... -0.58103657  0.76814693\n",
      "   0.95960665]\n",
      " [-0.7583011  -0.5839714  -0.6392746  ... -0.58103657  0.79740024\n",
      "  -1.1561601 ]\n",
      " [-0.7583011  -0.5839714  -0.6392746  ... -0.58103657  0.8286832\n",
      "  -1.1561601 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.31901523 0.3580193  0.34541053 ... 0.3586941  0.22396189 0.23936571]\n",
      " [0.90914536 0.3580193  0.34541053 ... 0.3586941  0.6394841  0.23936571]\n",
      " [0.31901523 0.3580193  0.34541053 ... 0.3586941  0.22396189 0.70042676]\n",
      " ...\n",
      " [0.31901523 0.3580193  0.34541053 ... 0.3586941  0.6831199  0.723043  ]\n",
      " [0.31901523 0.3580193  0.34541053 ... 0.3586941  0.68941814 0.23936571]\n",
      " [0.31901523 0.3580193  0.34541053 ... 0.3586941  0.69607645 0.23936571]] (3.635 sec)\n",
      "INFO:tensorflow:loss = 0.8025545, step = 3600 (3.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5647\n",
      "INFO:tensorflow:acc = 0.9875, acc_row = 0.734375, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.6773869  -0.6157748  -0.5812757  ... -0.49645638  0.7958689\n",
      "   0.83636767]\n",
      " [-0.6773869  -0.6157748  -0.5812757  ... -0.49645638 -1.2623798\n",
      "   0.8591333 ]\n",
      " [-0.6773869  -0.6157748  -0.4259375  ... -0.49645638  0.83167124\n",
      "  -1.1516447 ]\n",
      " ...\n",
      " [ 2.7931736  -0.6157748  -0.5812757  ... -0.49645638 -1.2623798\n",
      "  -1.1516447 ]\n",
      " [-0.6773869  -0.6157748  -0.5812757  ... -0.49645638  0.7527579\n",
      "   0.9656782 ]\n",
      " [-0.6773869  -0.6157748  -0.5812757  ... -0.49645638 -1.2623798\n",
      "   0.8498617 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.33684477 0.350743   0.35863912 ... 0.37837377 0.6890901  0.69769967]\n",
      " [0.33684477 0.350743   0.35863912 ... 0.37837377 0.2205645  0.70247954]\n",
      " [0.33684477 0.350743   0.3950968  ... 0.37837377 0.6967082  0.24018879]\n",
      " ...\n",
      " [0.9423058  0.350743   0.35863912 ... 0.37837377 0.2205645  0.24018879]\n",
      " [0.33684477 0.350743   0.35863912 ... 0.37837377 0.67977935 0.72425723]\n",
      " [0.33684477 0.350743   0.35863912 ... 0.37837377 0.2205645  0.70053816]] (3.629 sec)\n",
      "INFO:tensorflow:loss = 0.8041614, step = 3700 (3.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7004\n",
      "INFO:tensorflow:acc = 0.9867188, acc_row = 0.6953125, labels = [[0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-0.74281895 -0.6177186   3.1638288  ... -0.5042477   0.71255785\n",
      "   0.8133588 ]\n",
      " [-0.74281895 -0.6177186  -0.6611556  ... -0.5042477  -1.2306905\n",
      "   0.6439283 ]\n",
      " [-0.74281895 -0.6177186  -0.6611556  ... -0.5042477   0.8320983\n",
      "   0.84527886]\n",
      " ...\n",
      " [-0.74281895 -0.6177186  -0.6611556  ... -0.5042477  -1.2306905\n",
      "   0.76364994]\n",
      " [-0.74281895 -0.6177186  -0.6611556  ... -0.5042477  -1.2306905\n",
      "  -1.2906662 ]\n",
      " [-0.74281895 -0.6177186  -0.6611556  ... -0.5042477   0.7771952\n",
      "  -1.2906662 ]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.32238802 0.3503005  0.9594502  ... 0.37654296 0.6709661  0.6928248 ]\n",
      " [0.32238802 0.3503005  0.3404801  ... 0.37654296 0.2260606  0.6556409 ]\n",
      " [0.32238802 0.3503005  0.3404801  ... 0.37654296 0.69679844 0.69957584]\n",
      " ...\n",
      " [0.32238802 0.3503005  0.3404801  ... 0.37654296 0.2260606  0.6821456 ]\n",
      " [0.32238802 0.3503005  0.3404801  ... 0.37654296 0.2260606  0.21574008]\n",
      " [0.32238802 0.3503005  0.3404801  ... 0.37654296 0.6850753  0.21574008]] (3.610 sec)\n",
      "INFO:tensorflow:loss = 0.80536073, step = 3800 (3.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7238\n",
      "INFO:tensorflow:acc = 0.9875, acc_row = 0.7421875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.80420864 -0.62434626 -0.7260466  ... -0.50279033  0.6711412\n",
      "   1.0013827 ]\n",
      " [-0.80420864 -0.62434626 -0.7260466  ... -0.50279033 -1.207056\n",
      "   1.1197426 ]\n",
      " [-0.80420864 -0.62434626 -0.7260466  ... -0.50279033  0.78804815\n",
      "   0.9399415 ]\n",
      " ...\n",
      " [-0.80420864 -0.62434626 -0.7260466  ... -0.50279033  0.78809446\n",
      "   0.93612254]\n",
      " [-0.80420864 -0.62434626 -0.7260466  ... -0.50279033 -1.207056\n",
      "   0.98988473]\n",
      " [-0.80420864 -0.62434626 -0.7260466  ... -0.50279033 -1.207056\n",
      "  -1.0349703 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.30912596 0.34879363 0.3260629  ... 0.37688515 0.66175866 0.7313304 ]\n",
      " [0.30912596 0.34879363 0.3260629  ... 0.37688515 0.23022237 0.75394094]\n",
      " [0.30912596 0.34879363 0.3260629  ... 0.37688515 0.6874121  0.7190879 ]\n",
      " ...\n",
      " [0.30912596 0.34879363 0.3260629  ... 0.37688515 0.687422   0.7183158 ]\n",
      " [0.30912596 0.34879363 0.3260629  ... 0.37688515 0.23022237 0.7290652 ]\n",
      " [0.30912596 0.34879363 0.3260629  ... 0.37688515 0.23022237 0.26212165]] (3.606 sec)\n",
      "INFO:tensorflow:loss = 0.80074745, step = 3900 (3.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7252\n",
      "INFO:tensorflow:acc = 0.98765624, acc_row = 0.72265625, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [1 0 0 ... 0 1 1]], logits = [[-0.71254647 -0.65293276 -0.68901306 ... -0.61488694 -1.2154796\n",
      "   1.0059384 ]\n",
      " [-0.71254647 -0.65293276  2.962676   ... -0.61488694 -1.2154796\n",
      "  -1.0373371 ]\n",
      " [-0.71254647 -0.65293276 -0.68901306 ... -0.61488694  0.80698895\n",
      "   0.971673  ]\n",
      " ...\n",
      " [-0.71254647 -0.65293276 -0.68901306 ... -0.61488694  0.81465083\n",
      "  -1.0373371 ]\n",
      " [-0.71254647 -0.65293276 -0.68901306 ...  4.5517936   0.8456212\n",
      "  -1.0373371 ]\n",
      " [ 2.594368   -0.65293276 -0.68901306 ... -0.61488694  0.88278913\n",
      "   0.9767638 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 1.]], prob = [[0.3290364  0.34232897 0.33425266 ... 0.35094523 0.22873293 0.7322245 ]\n",
      " [0.3290364  0.34232897 0.9508592  ... 0.35094523 0.22873293 0.26166415]\n",
      " [0.3290364  0.34232897 0.33425266 ... 0.35094523 0.6914675  0.72545284]\n",
      " ...\n",
      " [0.3290364  0.34232897 0.33425266 ... 0.35094523 0.69309974 0.26166415]\n",
      " [0.3290364  0.34232897 0.33425266 ... 0.98956186 0.69964784 0.26166415]\n",
      " [0.93049824 0.34232897 0.33425266 ... 0.35094523 0.70739985 0.7264656 ]] (3.607 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7999121, step = 4000 (3.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5829\n",
      "INFO:tensorflow:acc = 0.9870312, acc_row = 0.734375, labels = [[0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [1 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 1]], logits = [[-0.7001102  -0.5956971  -0.69708735 ... -0.5801045  -1.2507772\n",
      "   0.78543836]\n",
      " [ 3.1633546  -0.5956971  -0.69708735 ... -0.5801045   0.6741525\n",
      "  -1.3211713 ]\n",
      " [ 3.4006286  -0.5956971   2.1895368  ... -0.5801045  -1.2507772\n",
      "   0.7271546 ]\n",
      " ...\n",
      " [-0.7001102  -0.5956971  -0.69708735 ... -0.5801045  -1.2507772\n",
      "  -1.3211713 ]\n",
      " [-0.7001102  -0.5956971  -0.69708735 ... -0.5801045  -1.2507772\n",
      "  -1.3211713 ]\n",
      " [-0.7001102  -0.5956971   2.9869454  ... -0.5801045  -1.2507772\n",
      "   0.76974726]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]], prob = [[0.3317878  0.35532874 0.33245832 ... 0.35890853 0.2225656  0.686851  ]\n",
      " [0.9594317  0.35532874 0.33245832 ... 0.35890853 0.6624324  0.21062349]\n",
      " [0.9677242  0.35532874 0.89930594 ... 0.35890853 0.2225656  0.67418057]\n",
      " ...\n",
      " [0.3317878  0.35532874 0.33245832 ... 0.35890853 0.2225656  0.21062349]\n",
      " [0.3317878  0.35532874 0.33245832 ... 0.35890853 0.2225656  0.21062349]\n",
      " [0.3317878  0.35532874 0.9519809  ... 0.35890853 0.2225656  0.6834662 ]] (3.626 sec)\n",
      "INFO:tensorflow:loss = 0.80005324, step = 4100 (3.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.567\n",
      "INFO:tensorflow:acc = 0.98875, acc_row = 0.765625, labels = [[1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[ 2.223709   -0.62492955 -0.6550485  ... -0.62351257  0.6943725\n",
      "  -1.0512958 ]\n",
      " [-0.798241   -0.62492955 -0.6550485  ... -0.62351257  0.6553585\n",
      "   0.88669   ]\n",
      " [-0.798241   -0.62492955 -0.6550485  ... -0.62351257  0.60358244\n",
      "  -1.1288809 ]\n",
      " ...\n",
      " [-0.798241   -0.62492955 -0.6550485  ... -0.62351257 -1.3818527\n",
      "  -1.1288809 ]\n",
      " [ 2.1514585  -0.62492955 -0.6550485  ... -0.62351257  0.6181772\n",
      "  -1.1288809 ]\n",
      " [-0.798241   -0.62492955 -0.6550485  ... -0.62351257  0.60272944\n",
      "   0.93320626]], predicted_classes = [[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.90235853 0.34866112 0.34185275 ... 0.34898302 0.6669389  0.25897634]\n",
      " [0.3104019  0.34866112 0.34185275 ... 0.34898302 0.65821695 0.70820665]\n",
      " [0.3104019  0.34866112 0.34185275 ... 0.34898302 0.6464755  0.24436772]\n",
      " ...\n",
      " [0.3104019  0.34866112 0.34185275 ... 0.34898302 0.2007116  0.24436772]\n",
      " [0.895805   0.34866112 0.34185275 ... 0.34898302 0.6498039  0.24436772]\n",
      " [0.3104019  0.34866112 0.34185275 ... 0.34898302 0.6462805  0.7177253 ]] (3.627 sec)\n",
      "INFO:tensorflow:loss = 0.7958658, step = 4200 (3.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5951\n",
      "INFO:tensorflow:acc = 0.98640627, acc_row = 0.70703125, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]], logits = [[-0.77470714 -0.63044876 -0.7457072  ... -0.5547186   0.7746105\n",
      "  -1.2500534 ]\n",
      " [-0.77470714 -0.63044876 -0.7457072  ... -0.5547186  -1.209933\n",
      "  -1.2500534 ]\n",
      " [-0.77470714 -0.63044876 -0.7457072  ... -0.5547186  -1.209933\n",
      "   0.7041264 ]\n",
      " ...\n",
      " [-0.77470714 -0.63044876  2.61613    ... -0.5547186   0.792254\n",
      "   0.7561693 ]\n",
      " [-0.77470714 -0.4797579  -0.7457072  ... -0.5547186  -1.209933\n",
      "  -1.2500534 ]\n",
      " [ 2.3268669   4.457714   -0.7457072  ... -0.5547186  -1.209933\n",
      "  -1.2500534 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]], prob = [[0.31546172 0.3474088  0.32175738 ... 0.36477035 0.6845174  0.22269088]\n",
      " [0.31546172 0.3474088  0.32175738 ... 0.36477035 0.2297129  0.22269088]\n",
      " [0.31546172 0.3474088  0.32175738 ... 0.36477035 0.2297129  0.669102  ]\n",
      " ...\n",
      " [0.31546172 0.3474088  0.93189245 ... 0.36477035 0.68831515 0.6805215 ]\n",
      " [0.31546172 0.38230932 0.32175738 ... 0.36477035 0.2297129  0.22269088]\n",
      " [0.91107786 0.9885439  0.32175738 ... 0.36477035 0.2297129  0.22269088]] (3.623 sec)\n",
      "INFO:tensorflow:loss = 0.79804456, step = 4300 (3.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7119\n",
      "INFO:tensorflow:acc = 0.9948437, acc_row = 0.91796875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-0.73673606 -0.6122332  -0.75048655 ... -0.6365509  -1.2750394\n",
      "   0.66276497]\n",
      " [-0.65057635 -0.6122332  -0.75048655 ... -0.6365509   0.54892707\n",
      "   0.9821463 ]\n",
      " [-0.73673606 -0.6122332   2.5518613  ... -0.6365509  -1.2750394\n",
      "   0.74670774]\n",
      " ...\n",
      " [-0.73673606 -0.6122332  -0.75048655 ... -0.6365509   0.7205553\n",
      "   0.8127884 ]\n",
      " [ 3.1222453  -0.6122332  -0.75048655 ... -0.6365509   0.74645185\n",
      "  -1.3429838 ]\n",
      " [-0.73673606 -0.6122332  -0.75048655 ... -0.6365509   0.6076315\n",
      "  -1.3429838 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.32371828 0.35154998 0.32071528 ... 0.34602663 0.2183958  0.65988123]\n",
      " [0.3428597  0.35154998 0.32071528 ... 0.34602663 0.63388664 0.7275339 ]\n",
      " [0.32371828 0.35154998 0.9276985  ... 0.34602663 0.2183958  0.6784609 ]\n",
      " ...\n",
      " [0.32371828 0.35154998 0.32071528 ... 0.34602663 0.6727293  0.69270337]\n",
      " [0.9578011  0.35154998 0.32071528 ... 0.34602663 0.6784051  0.2070198 ]\n",
      " [0.32371828 0.35154998 0.32071528 ... 0.34602663 0.6474003  0.2070198 ]] (3.609 sec)\n",
      "INFO:tensorflow:loss = 0.7942358, step = 4400 (3.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5409\n",
      "INFO:tensorflow:acc = 0.99328125, acc_row = 0.890625, labels = [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]], logits = [[-0.7304752  3.9303439 -0.7185664 ... -0.602786  -1.1580346 -1.0842301]\n",
      " [-0.7304752 -0.7077471 -0.7185664 ... -0.602786   0.8146986  0.9419542]\n",
      " [-0.7304752 -0.7077471 -0.7185664 ... -0.602786  -1.1580346 -1.0842301]\n",
      " ...\n",
      " [ 2.9645052 -0.7077471 -0.7185664 ... -0.602786  -1.1580346 -1.0842301]\n",
      " [-0.7304752 -0.7077471 -0.7185664 ... -0.602786  -1.1580346 -1.0842301]\n",
      " [ 2.6828587 -0.7077471 -0.7185664 ... -0.602786  -1.0951298 -1.0842301]], predicted_classes = [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], prob = [[0.32509044 0.9807413  0.32770875 ... 0.35370657 0.23902458 0.25270635]\n",
      " [0.32509044 0.33009684 0.32770875 ... 0.35370657 0.69310987 0.7194943 ]\n",
      " [0.32509044 0.33009684 0.32770875 ... 0.35370657 0.23902458 0.25270635]\n",
      " ...\n",
      " [0.95094454 0.33009684 0.32770875 ... 0.35370657 0.23902458 0.25270635]\n",
      " [0.32509044 0.33009684 0.32770875 ... 0.35370657 0.23902458 0.25270635]\n",
      " [0.9360075  0.33009684 0.32770875 ... 0.35370657 0.25065354 0.25270635]] (3.631 sec)\n",
      "INFO:tensorflow:loss = 0.79523355, step = 4500 (3.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6005\n",
      "INFO:tensorflow:acc = 0.996875, acc_row = 0.9375, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.73317677 -0.63065064 -0.7441269  ... -0.6261399  -1.2481203\n",
      "   0.7601266 ]\n",
      " [-0.73317677 -0.63065064 -0.6255539  ... -0.6261399  -1.2481203\n",
      "   0.7288499 ]\n",
      " [-0.73317677  4.77612    -0.7441269  ... -0.6261399   0.8047918\n",
      "  -1.2893862 ]\n",
      " ...\n",
      " [-0.73317677 -0.63065064 -0.7441269  ... -0.6261399  -1.2481203\n",
      "  -1.2893862 ]\n",
      " [-0.73317677 -0.63065064 -0.7441269  ... -0.6261399   0.72201884\n",
      "   0.6763039 ]\n",
      " [-0.73317677 -0.63065064 -0.7441269  ... -0.6261399   0.7951973\n",
      "   0.7213897 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.324498   0.347363   0.32210234 ... 0.34838632 0.22302568 0.6813812 ]\n",
      " [0.324498   0.347363   0.34851936 ... 0.34838632 0.22302568 0.6745528 ]\n",
      " [0.324498   0.99164176 0.32210234 ... 0.34838632 0.69099855 0.21595673]\n",
      " ...\n",
      " [0.324498   0.347363   0.32210234 ... 0.34838632 0.22302568 0.21595673]\n",
      " [0.324498   0.347363   0.32210234 ... 0.34838632 0.6730514  0.66291326]\n",
      " [0.324498   0.347363   0.32210234 ... 0.34838632 0.68894625 0.672913  ]] (3.623 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.79341674, step = 4600 (3.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6743\n",
      "INFO:tensorflow:acc = 0.99609375, acc_row = 0.9296875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.8170976  -0.66564256 -0.7379124  ... -0.58140916 -1.30604\n",
      "   0.850835  ]\n",
      " [-0.8170976  -0.66564256 -0.7379124  ... -0.58140916 -1.30604\n",
      "   0.8712486 ]\n",
      " [-0.8170976  -0.66564256 -0.7379124  ... -0.58140916  0.6680456\n",
      "   0.83587015]\n",
      " ...\n",
      " [-0.8170976  -0.66564256 -0.7379124  ... -0.58140916 -1.30604\n",
      "   0.83657414]\n",
      " [-0.8170976  -0.66564256 -0.7379124  ... -0.58140916  0.6922677\n",
      "   0.8049108 ]\n",
      " [-0.8170976  -0.66564256 -0.7379124  ... -0.58140916  0.7172168\n",
      "   0.8721441 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.3063801  0.33947325 0.32346082 ... 0.3586084  0.21315025 0.70074224]\n",
      " [0.3063801  0.33947325 0.32346082 ... 0.3586084  0.21315025 0.7050054 ]\n",
      " [0.3063801  0.33947325 0.32346082 ... 0.3586084  0.6610654  0.6975947 ]\n",
      " ...\n",
      " [0.3063801  0.33947325 0.32346082 ... 0.3586084  0.21315025 0.69774324]\n",
      " [0.3063801  0.33947325 0.32346082 ... 0.3586084  0.66647124 0.69102395]\n",
      " [0.3063801  0.33947325 0.32346082 ... 0.3586084  0.67199385 0.7051917 ]] (3.614 sec)\n",
      "INFO:tensorflow:loss = 0.78986007, step = 4700 (3.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8099\n",
      "INFO:tensorflow:acc = 0.9965625, acc_row = 0.92578125, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.78379995 -0.68479854 -0.77434397 ... -0.6963996  -1.3276472\n",
      "  -1.2040216 ]\n",
      " [-0.78379995 -0.68479854  2.8886492  ... -0.6963996  -1.3276472\n",
      "   0.88470626]\n",
      " [ 2.6009567  -0.68479854 -0.77434397 ... -0.6963996   0.7127676\n",
      "  -1.2040216 ]\n",
      " ...\n",
      " [-0.78379995 -0.68479854 -0.77434397 ... -0.6963996  -1.3276472\n",
      "   0.8481687 ]\n",
      " [-0.78379995 -0.68479854 -0.77434397 ... -0.6963996  -1.3276472\n",
      "  -1.2040216 ]\n",
      " [-0.78379995 -0.68479854 -0.77434397 ... -0.6963996  -1.3276472\n",
      "   0.82511365]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.31350148 0.33519116 0.31554016 ... 0.33261096 0.20954882 0.23076056]\n",
      " [0.31350148 0.33519116 0.9472825  ... 0.33261096 0.20954882 0.7077966 ]\n",
      " [0.93092316 0.33519116 0.31554016 ... 0.33261096 0.6710124  0.23076056]\n",
      " ...\n",
      " [0.31350148 0.33519116 0.31554016 ... 0.33261096 0.20954882 0.70018286]\n",
      " [0.31350148 0.33519116 0.31554016 ... 0.33261096 0.20954882 0.23076056]\n",
      " [0.31350148 0.33519116 0.31554016 ... 0.33261096 0.20954882 0.6953207 ]] (3.596 sec)\n",
      "INFO:tensorflow:loss = 0.7913344, step = 4800 (3.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7908\n",
      "INFO:tensorflow:acc = 0.99625, acc_row = 0.92578125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]], logits = [[-0.7974466  -0.72285813 -0.8053287  ... -0.6699187  -1.2422135\n",
      "   0.822798  ]\n",
      " [-0.7974466  -0.72285813 -0.8053287  ... -0.6699187  -1.2422135\n",
      "   0.7358438 ]\n",
      " [-0.7974466  -0.72285813 -0.8053287  ... -0.6699187  -1.2085\n",
      "   0.7756863 ]\n",
      " ...\n",
      " [-0.7974466  -0.72285813 -0.8053287  ... -0.6699187   0.8300948\n",
      "   0.7217378 ]\n",
      " [-0.7974466  -0.72285813 -0.8053287  ... -0.6699187  -1.2422135\n",
      "   0.7340629 ]\n",
      " [-0.7974466  -0.72285813  2.6136973  ... -0.6699187  -1.2422135\n",
      "   0.8073865 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]], prob = [[0.310572   0.3267639  0.30888683 ... 0.33851504 0.22405092 0.69482994]\n",
      " [0.310572   0.3267639  0.30888683 ... 0.33851504 0.22405092 0.6760863 ]\n",
      " [0.310572   0.3267639  0.30888683 ... 0.33851504 0.22996657 0.68474966]\n",
      " ...\n",
      " [0.310572   0.3267639  0.30888683 ... 0.33851504 0.69637495 0.6729896 ]\n",
      " [0.310572   0.3267639  0.30888683 ... 0.33851504 0.22405092 0.67569625]\n",
      " [0.310572   0.3267639  0.9317379  ... 0.33851504 0.22405092 0.6915523 ]] (3.598 sec)\n",
      "INFO:tensorflow:loss = 0.7864715, step = 4900 (3.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9899\n",
      "INFO:tensorflow:acc = 0.99640626, acc_row = 0.9140625, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 1]], logits = [[-0.87912846 -0.6929808  -0.7670458  ... -0.6771928   0.68708706\n",
      "   0.69227594]\n",
      " [-0.87912846 -0.6929808  -0.7670458  ... -0.6771928   0.73775375\n",
      "   0.8335401 ]\n",
      " [-0.87912846 -0.6929808  -0.7670458  ... -0.6771928   0.74263936\n",
      "   0.78620523]\n",
      " ...\n",
      " [-0.87912846 -0.6929808  -0.7670458  ... -0.6771928   0.73775375\n",
      "   0.8335401 ]\n",
      " [-0.87912846 -0.6929808  -0.7670458  ... -0.6771928  -1.2552176\n",
      "  -1.2101859 ]\n",
      " [-0.87912846 -0.6929808   3.1648626  ... -0.6771928  -1.2552176\n",
      "   0.84820765]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]], prob = [[0.29335842 0.33337033 0.3171185  ... 0.33688813 0.6653186  0.66647303]\n",
      " [0.29335842 0.33337033 0.3171185  ... 0.33688813 0.6765045  0.69710296]\n",
      " [0.29335842 0.33337033 0.3171185  ... 0.33688813 0.6775727  0.68701595]\n",
      " ...\n",
      " [0.29335842 0.33337033 0.3171185  ... 0.33688813 0.6765045  0.69710296]\n",
      " [0.29335842 0.33337033 0.3171185  ... 0.33688813 0.22179829 0.22966817]\n",
      " [0.29335842 0.33337033 0.9594903  ... 0.33688813 0.22179829 0.700191  ]] (3.574 sec)\n",
      "INFO:tensorflow:loss = 0.78657836, step = 5000 (3.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8726\n",
      "INFO:tensorflow:acc = 0.99625, acc_row = 0.92578125, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.83350086 -0.71007025 -0.8597555  ... -0.6552418   0.80391675\n",
      "  -1.1607237 ]\n",
      " [-0.83350086 -0.71007025 -0.8597555  ... -0.6552418   0.8631799\n",
      "   0.8788649 ]\n",
      " [-0.83350086 -0.71007025 -0.8597555  ... -0.6552418   0.83900666\n",
      "   0.8740502 ]\n",
      " ...\n",
      " [-0.83350086 -0.71007025  2.309329   ... -0.6552418   0.7823982\n",
      "   0.8997742 ]\n",
      " [-0.83350086 -0.71007025 -0.8597555  ... -0.6552418   0.8773352\n",
      "  -1.1607237 ]\n",
      " [-0.83350086 -0.71007025 -0.8597555  ... -0.6552418  -1.2477244\n",
      "   0.84045726]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.30290535 0.32958332 0.29739043 ... 0.34180927 0.6908117  0.2385358 ]\n",
      " [0.30290535 0.32958332 0.29739043 ... 0.34180927 0.7033246  0.70658696]\n",
      " [0.30290535 0.32958332 0.29739043 ... 0.34180927 0.698256   0.70558774]\n",
      " ...\n",
      " [0.30290535 0.32958332 0.9096467  ... 0.34180927 0.68619674 0.7109031 ]\n",
      " [0.30290535 0.32958332 0.29739043 ... 0.34180927 0.7062697  0.2385358 ]\n",
      " [0.30290535 0.32958332 0.29739043 ... 0.34180927 0.2230943  0.6985615 ]] (3.587 sec)\n",
      "INFO:tensorflow:loss = 0.7848813, step = 5100 (3.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0529\n",
      "INFO:tensorflow:acc = 0.99671876, acc_row = 0.921875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 1]], logits = [[-0.8335773  -0.7593719  -0.82509744 ... -0.6454913  -1.3381962\n",
      "   0.8397966 ]\n",
      " [-0.8335773  -0.7593719  -0.82509744 ... -0.6454913  -1.3381962\n",
      "   0.9844426 ]\n",
      " [-0.8335773  -0.7593719  -0.82509744 ... -0.6454913  -1.3381962\n",
      "  -1.0922157 ]\n",
      " ...\n",
      " [-0.8335773  -0.7593719  -0.82509744 ... -0.6454913   0.71101695\n",
      "   0.94379634]\n",
      " [-0.8335773  -0.7593719  -0.82509744 ... -0.6454913   0.74814695\n",
      "   0.95275885]\n",
      " [ 2.792376   -0.7593719  -0.82509744 ... -0.6454913  -1.3381962\n",
      "   0.7765353 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]], prob = [[0.3028892  0.31878266 0.3046827  ... 0.34400627 0.20780687 0.6984224 ]\n",
      " [0.3028892  0.31878266 0.3046827  ... 0.34400627 0.20780687 0.72798884]\n",
      " [0.3028892  0.31878266 0.3046827  ... 0.34400627 0.20780687 0.2512013 ]\n",
      " ...\n",
      " [0.3028892  0.31878266 0.3046827  ... 0.34400627 0.67062587 0.7198659 ]\n",
      " [0.3028892  0.31878266 0.3046827  ... 0.34400627 0.67877483 0.7216697 ]\n",
      " [0.9422624  0.31878266 0.3046827  ... 0.34400627 0.20780687 0.68493295]] (3.565 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.78494596, step = 5200 (3.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7889\n",
      "INFO:tensorflow:acc = 0.995625, acc_row = 0.90234375, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 0]], logits = [[-0.83849394 -0.7619143  -0.9165223  ... -0.7482946   0.58416945\n",
      "  -1.1372739 ]\n",
      " [-0.83849394 -0.7619143  -0.9165223  ... -0.7482946   0.5979115\n",
      "   0.838931  ]\n",
      " [-0.83849394 -0.7619143  -0.9165223  ... -0.7482946   0.69943476\n",
      "   0.8639721 ]\n",
      " ...\n",
      " [-0.83849394 -0.7619143  -0.9165223  ... -0.7482946   0.7553001\n",
      "   0.94163543]\n",
      " [ 2.6909924  -0.7619143  -0.9165223  ... -0.7482946   0.60823065\n",
      "   1.0465007 ]\n",
      " [ 2.6596186  -0.7619143  -0.9165223  ... -0.7482946  -1.3664422\n",
      "  -1.1372739 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], prob = [[0.30185205 0.3182308  0.28566703 ... 0.321193   0.64202625 0.2428212 ]\n",
      " [0.30185205 0.3182308  0.28566703 ... 0.321193   0.6451784  0.69824   ]\n",
      " [0.30185205 0.3182308  0.28566703 ... 0.321193   0.66806245 0.7034899 ]\n",
      " ...\n",
      " [0.30185205 0.3182308  0.28566703 ... 0.321193   0.6803325  0.7194299 ]\n",
      " [0.936493   0.3182308  0.28566703 ... 0.321193   0.6475371  0.74010235]\n",
      " [0.93460137 0.3182308  0.28566703 ... 0.321193   0.20319527 0.2428212 ]] (3.598 sec)\n",
      "INFO:tensorflow:loss = 0.78294134, step = 5300 (3.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3702\n",
      "INFO:tensorflow:acc = 0.996875, acc_row = 0.921875, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.8177143 -0.7425816 -0.815801  ... -0.7040589  0.718837  -1.2299097]\n",
      " [-0.8177143 -0.7425816 -0.815801  ... -0.7040589 -1.3472131  0.8260821]\n",
      " [-0.8177143 -0.7425816 -0.815801  ... -0.7040589 -1.3472131  0.7299899]\n",
      " ...\n",
      " [-0.8177143 -0.7425816 -0.815801  ... -0.7040589 -1.3472131  0.7914077]\n",
      " [-0.8177143 -0.7425816 -0.815801  ... -0.7040589  0.6863357 -1.2299097]\n",
      " [-0.8177143 -0.7425816 -0.815801  ... -0.7040589 -1.3472131 -1.2299097]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.30624908 0.32243988 0.30665573 ... 0.33091295 0.6723509  0.22619724]\n",
      " [0.30624908 0.32243988 0.30665573 ... 0.33091295 0.20632637 0.6955259 ]\n",
      " [0.30624908 0.32243988 0.30665573 ... 0.33091295 0.20632637 0.674803  ]\n",
      " ...\n",
      " [0.30624908 0.32243988 0.30665573 ... 0.33091295 0.20632637 0.68813354]\n",
      " [0.30624908 0.32243988 0.30665573 ... 0.33091295 0.6651513  0.22619724]\n",
      " [0.30624908 0.32243988 0.30665573 ... 0.33091295 0.20632637 0.22619724]] (3.653 sec)\n",
      "INFO:tensorflow:loss = 0.782656, step = 5400 (3.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1409\n",
      "INFO:tensorflow:acc = 0.9975, acc_row = 0.9375, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.8491211  -0.69489694 -0.8246963  ... -0.6564043  -1.3084164\n",
      "   0.791801  ]\n",
      " [-0.8491211  -0.69489694 -0.8246963  ... -0.6564043   0.6953936\n",
      "   0.62682444]\n",
      " [-0.8491211  -0.69489694 -0.8246963  ... -0.6564043   0.7725963\n",
      "   0.71482706]\n",
      " ...\n",
      " [-0.8491211  -0.69489694 -0.8246963  ... -0.6564043  -1.2931827\n",
      "  -1.3916987 ]\n",
      " [-0.8491211  -0.69489694 -0.8246963  ... -0.6564043  -1.2415607\n",
      "   0.5345936 ]\n",
      " [-0.8491211  -0.69489694 -0.8246963  ... -0.6564043  -1.3084164\n",
      "   0.68419427]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.2996173  0.3329446  0.30476767 ... 0.3415478  0.21275198 0.6882179 ]\n",
      " [0.2996173  0.3329446  0.30476767 ... 0.3415478  0.6671657  0.65176904]\n",
      " [0.2996173  0.3329446  0.30476767 ... 0.3415478  0.68408227 0.67146695]\n",
      " ...\n",
      " [0.2996173  0.3329446  0.30476767 ... 0.3415478  0.21531458 0.1991367 ]\n",
      " [0.2996173  0.3329446  0.30476767 ... 0.3415478  0.22416444 0.63055384]\n",
      " [0.2996173  0.3329446  0.30476767 ... 0.3415478  0.21275198 0.66467416]] (3.685 sec)\n",
      "INFO:tensorflow:loss = 0.78595906, step = 5500 (3.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6274\n",
      "INFO:tensorflow:acc = 0.996875, acc_row = 0.92578125, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.8270522  -0.75240564 -0.82501554 ... -0.7468667   0.59055066\n",
      "   0.8339899 ]\n",
      " [-0.8270522  -0.75240564 -0.82501554 ... -0.7468667  -1.4247922\n",
      "   0.87796366]\n",
      " [-0.8270522  -0.75240564  3.1973588  ... -0.7468667   0.6738503\n",
      "  -1.1549891 ]\n",
      " ...\n",
      " [-0.8270522  -0.75240564 -0.82501554 ... -0.7468667   0.60116774\n",
      "   0.82686865]\n",
      " [-0.8270522  -0.75240564 -0.82501554 ... -0.7468667  -1.4247922\n",
      "   0.8694304 ]\n",
      " [-0.8270522  -0.75240564 -0.82501554 ... -0.7468667  -1.4247922\n",
      "   0.8609536 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.30426872 0.32029733 0.30470005 ... 0.3215044  0.6434915  0.6971979 ]\n",
      " [0.30426872 0.32029733 0.30470005 ... 0.3215044  0.19391142 0.70640004]\n",
      " [0.30426872 0.32029733 0.96073484 ... 0.3215044  0.6623648  0.23957896]\n",
      " ...\n",
      " [0.30426872 0.32029733 0.30470005 ... 0.3215044  0.64592344 0.6956924 ]\n",
      " [0.30426872 0.32029733 0.30470005 ... 0.3215044  0.19391142 0.7046272 ]\n",
      " [0.30426872 0.32029733 0.30470005 ... 0.3215044  0.19391142 0.7028599 ]] (3.620 sec)\n",
      "INFO:tensorflow:loss = 0.78647923, step = 5600 (3.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4448\n",
      "INFO:tensorflow:acc = 0.9978125, acc_row = 0.94921875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.89902246 -0.7512678  -0.800413   ... -0.72048783  0.60400355\n",
      "   0.8418442 ]\n",
      " [-0.89902246 -0.7512678  -0.800413   ... -0.72048783 -1.4092674\n",
      "   0.8519982 ]\n",
      " [-0.89902246 -0.7512678  -0.800413   ... -0.72048783 -1.4092674\n",
      "   0.9582821 ]\n",
      " ...\n",
      " [-0.89902246 -0.7512678  -0.800413   ... -0.72048783 -1.4092674\n",
      "   0.8843699 ]\n",
      " [-0.89902246 -0.7512678  -0.800413   ... -0.72048783 -1.4092674\n",
      "   0.8270254 ]\n",
      " [-0.89902246 -0.7512678  -0.800413   ... -0.72048783 -1.4092674\n",
      "   0.792794  ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.28925142 0.3205451  0.30993718 ... 0.32728556 0.64657176 0.6988535 ]\n",
      " [0.28925142 0.3205451  0.30993718 ... 0.32728556 0.19634962 0.70098615]\n",
      " [0.28925142 0.3205451  0.30993718 ... 0.32728556 0.19634962 0.7227777 ]\n",
      " ...\n",
      " [0.28925142 0.3205451  0.30993718 ... 0.32728556 0.19634962 0.70772696]\n",
      " [0.28925142 0.3205451  0.30993718 ... 0.32728556 0.19634962 0.69572556]\n",
      " [0.28925142 0.3205451  0.30993718 ... 0.32728556 0.19634962 0.6884309 ]] (3.643 sec)\n",
      "INFO:tensorflow:loss = 0.78417593, step = 5700 (3.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7802\n",
      "INFO:tensorflow:acc = 0.99671876, acc_row = 0.921875, labels = [[1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[ 2.0344613  -0.81039697 -0.8379725  ... -0.71814525  0.6690324\n",
      "  -1.1920859 ]\n",
      " [-0.9605078  -0.81039697 -0.8379725  ... -0.71814525 -1.4065714\n",
      "  -1.1920859 ]\n",
      " [-0.9605078  -0.81039697 -0.8379725  ... -0.71814525 -1.4065714\n",
      "   0.84487885]\n",
      " ...\n",
      " [ 2.1266112  -0.81039697 -0.8379725  ... -0.696631   -1.4065714\n",
      "  -1.1920859 ]\n",
      " [-0.9605078  -0.81039697 -0.8379725  ... -0.71814525 -1.4065714\n",
      "  -1.1920859 ]\n",
      " [-0.9605078  -0.81039697 -0.8379725  ... -0.71814525  0.5654007\n",
      "   0.8080292 ]], predicted_classes = [[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.88436806 0.3078059  0.30196196 ... 0.32780156 0.6612865  0.23288609]\n",
      " [0.27677652 0.3078059  0.30196196 ... 0.32780156 0.1967754  0.23288609]\n",
      " [0.27677652 0.3078059  0.30196196 ... 0.32780156 0.1967754  0.69949174]\n",
      " ...\n",
      " [0.8934629  0.3078059  0.30196196 ... 0.3325596  0.1967754  0.23288609]\n",
      " [0.27677652 0.3078059  0.30196196 ... 0.32780156 0.1967754  0.23288609]\n",
      " [0.27677652 0.3078059  0.30196196 ... 0.32780156 0.6377013  0.6916894 ]] (3.599 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7810167, step = 5800 (3.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5989\n",
      "INFO:tensorflow:acc = 0.998125, acc_row = 0.953125, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]], logits = [[-0.87895346 -0.74541575 -0.7734356  ... -0.72590536 -1.2881074\n",
      "  -1.2036293 ]\n",
      " [-0.87895346 -0.74541575 -0.8111609  ... -0.72590536  0.72812146\n",
      "   0.9347262 ]\n",
      " [-0.87895346 -0.74541575 -0.8111609  ... -0.72590536 -1.2881074\n",
      "  -1.2036293 ]\n",
      " ...\n",
      " [-0.87895346 -0.74541575 -0.8111609  ... -0.72590536 -1.2881074\n",
      "   0.8336904 ]\n",
      " [-0.87895346 -0.74541575 -0.8111609  ... -0.72590536 -1.2881074\n",
      "   0.8336904 ]\n",
      " [-0.87895346 -0.74541575  3.6975372  ... -0.72590536 -1.2881074\n",
      "   0.7569081 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]], prob = [[0.29339468 0.321821   0.31573638 ... 0.3260939  0.21617334 0.23083024]\n",
      " [0.29339468 0.321821   0.30764315 ... 0.3260939  0.6743929  0.71803313]\n",
      " [0.29339468 0.321821   0.30764315 ... 0.3260939  0.21617334 0.23083024]\n",
      " ...\n",
      " [0.29339468 0.321821   0.30764315 ... 0.3260939  0.21617334 0.69713473]\n",
      " [0.29339468 0.321821   0.30764315 ... 0.3260939  0.21617334 0.69713473]\n",
      " [0.29339468 0.321821   0.97581494 ... 0.3260939  0.21617334 0.68068206]] (3.625 sec)\n",
      "INFO:tensorflow:loss = 0.7840044, step = 5900 (3.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8402\n",
      "INFO:tensorflow:acc = 0.9971875, acc_row = 0.9375, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 1 1 0]], logits = [[-0.9129988  -0.7663235  -0.7450039  ... -0.774253    0.8440465\n",
      "  -1.3111758 ]\n",
      " [-0.9129988  -0.7663235  -0.8548591  ... -0.774253   -1.3140256\n",
      "   0.73410076]\n",
      " [-0.9129988  -0.7663235  -0.8548591  ... -0.774253   -1.3140256\n",
      "   0.767995  ]\n",
      " ...\n",
      " [-0.9129988  -0.7663235  -0.8548591  ... -0.774253   -1.3140256\n",
      "   0.73270994]\n",
      " [-0.9129988  -0.7663235  -0.8548591  ... -0.774253   -1.3140256\n",
      "   0.7401459 ]\n",
      " [-0.9129988  -0.7663235  -0.8548591  ...  5.253214    0.5702147\n",
      "  -1.3111758 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]], prob = [[0.28638658 0.31727496 0.32191092 ... 0.3155598  0.69931674 0.21229015]\n",
      " [0.28638658 0.31727496 0.29841456 ... 0.3155598  0.21181399 0.67570454]\n",
      " [0.28638658 0.31727496 0.29841456 ... 0.3155598  0.21181399 0.68308705]\n",
      " ...\n",
      " [0.28638658 0.31727496 0.29841456 ... 0.3155598  0.21181399 0.67539966]\n",
      " [0.28638658 0.31727496 0.29841456 ... 0.3155598  0.21181399 0.67702776]\n",
      " [0.28638658 0.31727496 0.29841456 ... 0.9947966  0.6388128  0.21229015]] (3.592 sec)\n",
      "INFO:tensorflow:loss = 0.77792984, step = 6000 (3.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3617\n",
      "INFO:tensorflow:acc = 0.9970313, acc_row = 0.94140625, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.883723   -0.8100404  -0.84679013 ... -0.7843176  -1.3850592\n",
      "  -1.1282969 ]\n",
      " [-0.84313184 -0.8100404  -0.84679013 ... -0.7843176   0.5656116\n",
      "   0.87444985]\n",
      " [-0.883723    4.3204317  -0.84679013 ... -0.7843176  -1.3850592\n",
      "  -1.1282969 ]\n",
      " ...\n",
      " [-0.883723   -0.8100404  -0.84679013 ... -0.7843176   0.5617612\n",
      "  -1.1282969 ]\n",
      " [-0.883723   -0.8100404  -0.84679013 ... -0.7843176  -1.3850592\n",
      "  -1.1282969 ]\n",
      " [-0.883723   -0.8100404  -0.84679013 ... -0.7843176  -1.3850592\n",
      "   0.8890372 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.29240686 0.3078819  0.3001066  ... 0.3133901  0.20019768 0.24447557]\n",
      " [0.3008756  0.3078819  0.3001066  ... 0.3133901  0.6377499  0.7056708 ]\n",
      " [0.29240686 0.9868803  0.3001066  ... 0.3133901  0.20019768 0.24447557]\n",
      " ...\n",
      " [0.29240686 0.3078819  0.3001066  ... 0.3133901  0.63685995 0.24447557]\n",
      " [0.29240686 0.3078819  0.3001066  ... 0.3133901  0.20019768 0.24447557]\n",
      " [0.29240686 0.3078819  0.3001066  ... 0.3133901  0.20019768 0.7086915 ]] (3.655 sec)\n",
      "INFO:tensorflow:loss = 0.77643615, step = 6100 (3.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6206\n",
      "INFO:tensorflow:acc = 0.9971875, acc_row = 0.9375, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-0.8865117  -0.80544746 -0.8735398  ... -0.7935526   0.46706954\n",
      "   0.7947391 ]\n",
      " [-0.8865117  -0.80544746 -0.8735398  ... -0.7935526   0.5856304\n",
      "   0.7751648 ]\n",
      " [-0.8865117  -0.80544746 -0.8735398  ... -0.7935526   0.61850667\n",
      "  -1.2691219 ]\n",
      " ...\n",
      " [-0.8865117  -0.80544746 -0.8735398  ... -0.7935526   0.6285342\n",
      "   0.74213684]\n",
      " [-0.8865117  -0.80544746 -0.8735398  ... -0.7935526   0.59573615\n",
      "   0.7998511 ]\n",
      " [-0.8865117  -0.80544746 -0.8735398  ... -0.7935526  -1.4243615\n",
      "   0.8469355 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.2918302  0.3088615  0.2945183  ... 0.31140637 0.6146899  0.688848  ]\n",
      " [0.2918302  0.3088615  0.2945183  ... 0.31140637 0.6423619  0.6846371 ]\n",
      " [0.2918302  0.3088615  0.2945183  ... 0.31140637 0.64987886 0.2194076 ]\n",
      " ...\n",
      " [0.2918302  0.3088615  0.2945183  ... 0.31140637 0.652157   0.677463  ]\n",
      " [0.2918302  0.3088615  0.2945183  ... 0.31140637 0.6446802  0.6899426 ]\n",
      " [0.2918302  0.3088615  0.2945183  ... 0.31140637 0.19397876 0.6999239 ]] (3.620 sec)\n",
      "INFO:tensorflow:loss = 0.775295, step = 6200 (3.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8952\n",
      "INFO:tensorflow:acc = 0.9973438, acc_row = 0.9375, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 1 1]], logits = [[-0.8935478  -0.8403046  -0.92292583 ... -0.7784622   0.56446075\n",
      "   0.7455928 ]\n",
      " [-0.8935478  -0.8403046  -0.92292583 ... -0.7784622   0.53939825\n",
      "   0.76051044]\n",
      " [-0.8935478  -0.8403046   2.6488118  ... -0.7784622   0.50211954\n",
      "  -1.41403   ]\n",
      " ...\n",
      " [-0.8935478  -0.8403046  -0.92292583 ... -0.7784622   0.46762824\n",
      "   0.7212417 ]\n",
      " [-0.8935478  -0.8403046  -0.92292583 ... -0.7784622   0.5460831\n",
      "  -1.41403   ]\n",
      " [-0.8935478  -0.8403046  -0.92292583 ...  6.2267613   0.5504272\n",
      "   0.7979874 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]], prob = [[0.29037824 0.3014706  0.2843621  ... 0.31465143 0.6374841  0.67821765]\n",
      " [0.29037824 0.3014706  0.2843621  ... 0.31465143 0.63167244 0.68146455]\n",
      " [0.29037824 0.3014706  0.9339377  ... 0.31465143 0.6229573  0.19559921]\n",
      " ...\n",
      " [0.29037824 0.3014706  0.2843621  ... 0.31465143 0.61482227 0.6728804 ]\n",
      " [0.29037824 0.3014706  0.2843621  ... 0.31465143 0.63322634 0.19559921]\n",
      " [0.29037824 0.3014706  0.2843621  ... 0.998028   0.63423467 0.6895438 ]] (3.586 sec)\n",
      "INFO:tensorflow:loss = 0.778253, step = 6300 (3.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8398\n",
      "INFO:tensorflow:acc = 0.9970313, acc_row = 0.9296875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.9632786  -0.85774124 -0.87808615 ... -0.78804564 -1.4130726\n",
      "   0.78757596]\n",
      " [-0.9632786  -0.85774124 -0.87808615 ... -0.78804564 -1.4064648\n",
      "  -1.2587469 ]\n",
      " [-0.9632786  -0.85774124 -0.87808615 ... -0.78804564  0.7050859\n",
      "   0.7722265 ]\n",
      " ...\n",
      " [-0.9632786  -0.85774124 -0.87808615 ... -0.78804564  0.66058916\n",
      "  -1.2587469 ]\n",
      " [-0.9632786  -0.85774124 -0.87808615 ... -0.78804564  0.51559615\n",
      "   0.7650385 ]\n",
      " [-0.9632786  -0.85774124 -0.87808615 ... -0.78804564  0.6489858\n",
      "   0.8026341 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.27622223 0.29781148 0.29357454 ... 0.31258848 0.19574988 0.6873106 ]\n",
      " [0.27622223 0.29781148 0.29357454 ... 0.31258848 0.19679224 0.22118968]\n",
      " [0.27622223 0.29781148 0.29357454 ... 0.31258848 0.66931444 0.68400234]\n",
      " ...\n",
      " [0.27622223 0.29781148 0.29357454 ... 0.31258848 0.6593927  0.22118968]\n",
      " [0.27622223 0.29781148 0.29357454 ... 0.31258848 0.6261174  0.6824466 ]\n",
      " [0.27622223 0.29781148 0.29357454 ... 0.31258848 0.65678185 0.69053763]] (3.592 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.77546555, step = 6400 (3.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4313\n",
      "INFO:tensorflow:acc = 0.9971875, acc_row = 0.9296875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.9050902 -0.8377407 -0.9426087 ... -0.8235098  0.6286809  0.8126327]\n",
      " [-0.9050902 -0.8377407 -0.9426087 ... -0.8235098  0.6226777  0.6832423]\n",
      " [-0.9050902 -0.8377407 -0.9426087 ... -0.8235098 -1.3905325  0.7339963]\n",
      " ...\n",
      " [-0.9050902 -0.8377407  2.7963755 ... -0.8235098  0.5782363 -1.3227495]\n",
      " [-0.9050902 -0.8377407 -0.9426087 ... -0.8235098 -1.3905325 -1.3227495]\n",
      " [-0.9050902 -0.8377407 -0.9426087 ... -0.8235098 -1.3905325 -1.3227495]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.2880056  0.30201083 0.2803737  ... 0.30501914 0.65219027 0.6926702 ]\n",
      " [0.2880056  0.30201083 0.2803737  ... 0.30501914 0.6508273  0.664462  ]\n",
      " [0.2880056  0.30201083 0.2803737  ... 0.30501914 0.19932275 0.67568165]\n",
      " ...\n",
      " [0.2880056  0.30201083 0.94247967 ... 0.30501914 0.6406615  0.21036121]\n",
      " [0.2880056  0.30201083 0.2803737  ... 0.30501914 0.19932275 0.21036121]\n",
      " [0.2880056  0.30201083 0.2803737  ... 0.30501914 0.19932275 0.21036121]] (3.645 sec)\n",
      "INFO:tensorflow:loss = 0.77585256, step = 6500 (3.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.681\n",
      "INFO:tensorflow:acc = 0.99578124, acc_row = 0.90625, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 1 0]], logits = [[-0.9825059  -0.8860389  -0.9664477  ... -0.8068772   0.61964726\n",
      "   0.77038574]\n",
      " [-0.9825059  -0.8860389  -0.9664477  ... -0.8021634   0.652398\n",
      "   0.8065494 ]\n",
      " [ 2.2771611  -0.8860389  -0.9664477  ... -0.8068772  -1.3805608\n",
      "  -1.2398071 ]\n",
      " ...\n",
      " [ 2.2773678  -0.8860389  -0.9664477  ... -0.8068772   0.65814745\n",
      "   0.81606674]\n",
      " [-0.9825059  -0.8860389  -0.9664477  ... -0.8068772   0.6986262\n",
      "   0.7680777 ]\n",
      " [ 2.4754882  -0.8860389  -0.9664477  ... -0.8068772   0.73280513\n",
      "  -1.2398071 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]], prob = [[0.27239484 0.29192796 0.2755891  ... 0.30855635 0.6501383  0.68360436]\n",
      " [0.27239484 0.29192796 0.2755891  ... 0.30956295 0.6575507  0.6913737 ]\n",
      " [0.9069678  0.29192796 0.2755891  ... 0.30855635 0.20091897 0.22446956]\n",
      " ...\n",
      " [0.90698516 0.29192796 0.2755891  ... 0.30855635 0.6588442  0.6934008 ]\n",
      " [0.27239484 0.29192796 0.2755891  ... 0.30855635 0.6678831  0.68310493]\n",
      " [0.9224055  0.29192796 0.2755891  ... 0.30855635 0.6754205  0.22446956]] (3.612 sec)\n",
      "INFO:tensorflow:loss = 0.7738977, step = 6600 (3.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3049\n",
      "INFO:tensorflow:acc = 0.9971875, acc_row = 0.94140625, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 1 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.9698533  -0.86802477 -0.9893911  ... -0.8129043   0.5030029\n",
      "   0.7384948 ]\n",
      " [-0.9698533  -0.86802477 -0.9893911  ... -0.8129043   0.5525423\n",
      "   0.73762625]\n",
      " [-0.9698533  -0.86802477 -0.9893911  ... -0.8129043   0.5802636\n",
      "   0.8399437 ]\n",
      " ...\n",
      " [-0.9698533  -0.86802477 -0.9893911  ... -0.8129043   0.59596926\n",
      "  -1.3685613 ]\n",
      " [-0.9698533   4.276837   -0.9893911  ... -0.8129043  -1.4558609\n",
      "  -1.3685613 ]\n",
      " [-0.9698533  -0.86802477 -0.9893911  ... -0.8129043  -1.4558609\n",
      "  -1.3685613 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.27490973 0.29566547 0.27103236 ... 0.30727196 0.6231648  0.6766666 ]\n",
      " [0.27490973 0.29566547 0.27103236 ... 0.30727196 0.6347252  0.67647654]\n",
      " [0.27490973 0.29566547 0.27103236 ... 0.30727196 0.64112806 0.69845337]\n",
      " ...\n",
      " [0.27490973 0.29566547 0.27103236 ... 0.30727196 0.6447336  0.2028524 ]\n",
      " [0.27490973 0.9863036  0.27103236 ... 0.30727196 0.18910122 0.2028524 ]\n",
      " [0.27490973 0.29566547 0.27103236 ... 0.30727196 0.18910122 0.2028524 ]] (3.663 sec)\n",
      "INFO:tensorflow:loss = 0.77166456, step = 6700 (3.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8007\n",
      "INFO:tensorflow:acc = 0.9971875, acc_row = 0.93359375, labels = [[0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]], logits = [[-1.0491619  -0.92274415 -1.0384007  ...  4.7091694   0.60627854\n",
      "  -1.1621245 ]\n",
      " [-1.0491619  -0.92274415 -1.0384007  ... -0.86247027  0.772041\n",
      "   0.8261877 ]\n",
      " [-1.0491619  -0.92274415 -1.0384007  ... -0.86247027 -1.3676348\n",
      "  -1.1621245 ]\n",
      " ...\n",
      " [-1.0491619  -0.92274415 -1.0384007  ... -0.86247027 -1.3676348\n",
      "  -1.1621245 ]\n",
      " [-1.0491619  -0.92274415 -1.0384007  ... -0.86247027 -1.1382049\n",
      "  -1.1621245 ]\n",
      " [ 1.8693585   3.2864215  -1.0384007  ... -0.86247027 -1.2495687\n",
      "  -1.1621245 ]], predicted_classes = [[0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]], prob = [[0.25938606 0.2843991  0.26145872 ... 0.99106824 0.6470914  0.23828146]\n",
      " [0.25938606 0.2843991  0.26145872 ... 0.29682347 0.6839622  0.69554824]\n",
      " [0.25938606 0.2843991  0.26145872 ... 0.29682347 0.20300226 0.23828146]\n",
      " ...\n",
      " [0.25938606 0.2843991  0.26145872 ... 0.29682347 0.20300226 0.23828146]\n",
      " [0.25938606 0.2843991  0.26145872 ... 0.29682347 0.24265009 0.23828146]\n",
      " [0.866384   0.96396005 0.26145872 ... 0.29682347 0.22277479 0.23828146]] (3.596 sec)\n",
      "INFO:tensorflow:loss = 0.7707022, step = 6800 (3.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8555\n",
      "INFO:tensorflow:acc = 0.9976562, acc_row = 0.94921875, labels = [[0 0 0 ... 0 0 1]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-0.9994499  -0.87649953 -1.062185   ... -0.8360675  -1.4204462\n",
      "   0.8353666 ]\n",
      " [ 2.8402307  -0.87649953 -1.062185   ... -0.8360675  -1.4204462\n",
      "  -1.200949  ]\n",
      " [-0.9994499  -0.87649953 -1.062185   ... -0.8360675   0.64184755\n",
      "  -1.200949  ]\n",
      " ...\n",
      " [-0.9994499  -0.87649953 -1.062185   ... -0.8360675  -1.4204462\n",
      "  -1.200949  ]\n",
      " [ 2.3794947  -0.87649953 -1.062185   ... -0.8360675  -1.4204462\n",
      "   0.8230705 ]\n",
      " [-0.9994499  -0.87649953 -1.062185   ... -0.8360675  -1.4204462\n",
      "  -1.200949  ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.26904958 0.29390368 0.2568921  ... 0.30236366 0.19459166 0.6974885 ]\n",
      " [0.94481146 0.29390368 0.2568921  ... 0.30236366 0.19459166 0.23130645]\n",
      " [0.26904958 0.29390368 0.2568921  ... 0.30236366 0.655171   0.23130645]\n",
      " ...\n",
      " [0.26904958 0.29390368 0.2568921  ... 0.30236366 0.19459166 0.23130645]\n",
      " [0.91525024 0.29390368 0.2568921  ... 0.30236366 0.19459166 0.6948877 ]\n",
      " [0.26904958 0.29390368 0.2568921  ... 0.30236366 0.19459166 0.23130645]] (3.590 sec)\n",
      "INFO:tensorflow:loss = 0.7693486, step = 6900 (3.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6385\n",
      "INFO:tensorflow:acc = 0.998125, acc_row = 0.953125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.020694   -0.89661187 -0.9337102  ... -0.8466136  -1.4237275\n",
      "   0.83193684]\n",
      " [-1.020694   -0.89661187 -0.9337102  ... -0.8466136   0.64130205\n",
      "  -1.1920506 ]\n",
      " [-1.020694   -0.89661187 -0.9337102  ... -0.8466136  -1.4237275\n",
      "   0.82733977]\n",
      " ...\n",
      " [-1.020694   -0.89661187 -0.9337102  ... -0.8466136   0.64130205\n",
      "  -1.1920506 ]\n",
      " [-1.020694   -0.89661187 -0.9337102  ... -0.8466136  -1.4237275\n",
      "   0.8677792 ]\n",
      " [-1.020694   -0.89661187 -0.9337102  ... -0.8466136   0.71905017\n",
      "   0.80031127]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.26489225 0.28974724 0.28217262 ... 0.30014372 0.1940779  0.6967643 ]\n",
      " [0.26489225 0.28974724 0.28217262 ... 0.30014372 0.6550477  0.2328924 ]\n",
      " [0.26489225 0.28974724 0.28217262 ... 0.30014372 0.1940779  0.69579214]\n",
      " ...\n",
      " [0.26489225 0.28974724 0.28217262 ... 0.30014372 0.6550477  0.2328924 ]\n",
      " [0.26489225 0.28974724 0.28217262 ... 0.30014372 0.1940779  0.70428336]\n",
      " [0.26489225 0.28974724 0.28217262 ... 0.30014372 0.67239785 0.690041  ]] (3.619 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.77009284, step = 7000 (3.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6948\n",
      "INFO:tensorflow:acc = 0.998125, acc_row = 0.953125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 1 0 1]], logits = [[-0.92985237 -0.93285036 -0.91497004 ... -0.8659474  -1.4756639\n",
      "   0.8355296 ]\n",
      " [-0.92985237 -0.93285036 -0.91497004 ... -0.8659474  -1.4756639\n",
      "  -1.2203325 ]\n",
      " [-0.92985237 -0.93285036 -0.91497004 ... -0.8659474  -1.4756639\n",
      "   0.7126454 ]\n",
      " ...\n",
      " [-0.92985237  2.8430045  -0.91497004 ... -0.8659474   0.45677334\n",
      "  -1.2203325 ]\n",
      " [-0.92985237 -0.93285036 -0.91497004 ... -0.8659474   0.56391203\n",
      "   0.78277236]\n",
      " [-0.92985237 -0.93285036 -0.91497004 ...  4.885088   -1.4756639\n",
      "   0.6825032 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 0. 1.]], prob = [[0.28295466 0.28234679 0.2859839  ... 0.29609826 0.18608326 0.6975229 ]\n",
      " [0.28295466 0.28234679 0.2859839  ... 0.29609826 0.18608326 0.22787794]\n",
      " [0.28295466 0.28234679 0.2859839  ... 0.29609826 0.18608326 0.67098546]\n",
      " ...\n",
      " [0.28295466 0.9449559  0.2859839  ... 0.29609826 0.6122484  0.22787794]\n",
      " [0.28295466 0.28234679 0.2859839  ... 0.29609826 0.63735723 0.68627733]\n",
      " [0.28295466 0.28234679 0.2859839  ... 0.9924982  0.18608326 0.66429716]] (3.610 sec)\n",
      "INFO:tensorflow:loss = 0.7704693, step = 7100 (3.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0109\n",
      "INFO:tensorflow:acc = 0.99875, acc_row = 0.96875, labels = [[1 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[ 2.340712   -0.8937433  -1.0458429  ... -0.85144687  0.35238674\n",
      "  -1.301611  ]\n",
      " [ 2.4306524  -0.8937433  -1.0458429  ... -0.85144687  0.5439894\n",
      "   0.7574714 ]\n",
      " [-1.0173658  -0.8937433  -1.0458429  ... -0.85144687  0.5358665\n",
      "   0.6921247 ]\n",
      " ...\n",
      " [-1.0173658  -0.8937433  -1.0458429  ... -0.85144687 -1.4838612\n",
      "  -1.301611  ]\n",
      " [-1.0173658  -0.8937433  -1.0458429  ... -0.85144687  0.5515522\n",
      "   0.74812216]\n",
      " [-1.0173658  -0.8937433  -1.0458429  ... -0.85144687 -1.4838612\n",
      "  -1.301611  ]], predicted_classes = [[1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.9121931  0.29033795 0.26002416 ... 0.29912946 0.58719623 0.21389402]\n",
      " [0.91913503 0.29033795 0.26002416 ... 0.29912946 0.63273996 0.6808045 ]\n",
      " [0.26554084 0.29033795 0.26002416 ... 0.29912946 0.6308504  0.6664395 ]\n",
      " ...\n",
      " [0.26554084 0.29033795 0.26002416 ... 0.29912946 0.18484491 0.21389402]\n",
      " [0.26554084 0.29033795 0.26002416 ... 0.29912946 0.6344956  0.67876935]\n",
      " [0.26554084 0.29033795 0.26002416 ... 0.29912946 0.18484491 0.21389402]] (3.571 sec)\n",
      "INFO:tensorflow:loss = 0.7701463, step = 7200 (3.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.546\n",
      "INFO:tensorflow:acc = 0.9984375, acc_row = 0.9609375, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 0 0 0]], logits = [[-1.0553683  -0.91500497 -0.99627554 ... -0.874203   -1.3990953\n",
      "   0.749179  ]\n",
      " [-1.0553683  -0.91500497 -0.99627554 ... -0.874203    0.5410134\n",
      "   0.7786636 ]\n",
      " [-1.0553683  -0.91500497 -0.99627554 ... -0.874203   -1.3994242\n",
      "   0.7394291 ]\n",
      " ...\n",
      " [-1.0553683  -0.91500497 -0.99627554 ... -0.874203    0.5782069\n",
      "   0.65644413]\n",
      " [-1.0553683  -0.91500497 -0.99627554 ... -0.874203    0.6734454\n",
      "  -1.3479787 ]\n",
      " [ 2.1200576  -0.91500497 -0.99627554 ... -0.874203   -1.3994242\n",
      "  -1.3479787 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], prob = [[0.25819558 0.28597674 0.26967433 ... 0.29438052 0.19795972 0.6789998 ]\n",
      " [0.25819558 0.28597674 0.26967433 ... 0.29438052 0.63204813 0.685392  ]\n",
      " [0.25819558 0.28597674 0.26967433 ... 0.29438052 0.1979075  0.676871  ]\n",
      " ...\n",
      " [0.25819558 0.28597674 0.26967433 ... 0.29438052 0.64065474 0.65846115]\n",
      " [0.25819558 0.28597674 0.26967433 ... 0.29438052 0.66227424 0.20620102]\n",
      " [0.89283746 0.28597674 0.26967433 ... 0.29438052 0.1979075  0.20620102]] (3.629 sec)\n",
      "INFO:tensorflow:loss = 0.7679327, step = 7300 (3.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0246\n",
      "INFO:tensorflow:acc = 0.99890625, acc_row = 0.97265625, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 1 0 0]], logits = [[-1.0990002  -0.8905803  -0.9733497  ... -0.9409972   0.45096588\n",
      "  -1.2007303 ]\n",
      " [-1.0990002  -0.8905803  -0.9733497  ... -0.9409972  -1.5429242\n",
      "  -1.2007303 ]\n",
      " [ 1.877634   -0.8905803  -0.9733497  ... -0.9409972  -1.5429242\n",
      "  -1.2007303 ]\n",
      " ...\n",
      " [-1.0990002  -0.8905803  -0.94715285 ... -0.9409972  -1.5429242\n",
      "  -1.2007303 ]\n",
      " [-1.0990002  -0.8905803  -0.9733497  ... -0.9409972   0.43253776\n",
      "   0.85755956]\n",
      " [ 1.9179525  -0.8905803  -0.9733497  ...  3.8414633  -1.5429242\n",
      "  -1.2007303 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 1. 0. 0.]], prob = [[0.24992724 0.2909901  0.27421334 ... 0.28069896 0.6108689  0.23134531]\n",
      " [0.24992724 0.2909901  0.27421334 ... 0.28069896 0.1761106  0.23134531]\n",
      " [0.8673391  0.2909901  0.27421334 ... 0.28069896 0.1761106  0.23134531]\n",
      " ...\n",
      " [0.24992724 0.2909901  0.27945775 ... 0.28069896 0.1761106  0.23134531]\n",
      " [0.24992724 0.2909901  0.27421334 ... 0.28069896 0.6064795  0.7021505 ]\n",
      " [0.8719099  0.2909901  0.27421334 ... 0.97898877 0.1761106  0.23134531]] (3.569 sec)\n",
      "INFO:tensorflow:loss = 0.76913047, step = 7400 (3.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3445\n",
      "INFO:tensorflow:acc = 0.99796873, acc_row = 0.94921875, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.0963517  -0.9530736  -0.9444542  ... -0.9060159  -1.4459164\n",
      "  -1.1196437 ]\n",
      " [-1.0963517  -0.9530736  -0.9444542  ... -0.9060159  -1.4459164\n",
      "   0.8849546 ]\n",
      " [-1.0963517  -0.9530736   3.7883053  ... -0.9060159  -1.4459164\n",
      "   0.9644481 ]\n",
      " ...\n",
      " [-1.0963517  -0.9530736  -0.9444542  ... -0.9060159  -1.4459164\n",
      "   0.8756931 ]\n",
      " [-1.0963517  -0.9530736  -0.9444542  ...  5.5057735   0.60696256\n",
      "  -1.1196437 ]\n",
      " [-1.0963517  -0.9530736  -0.9444542  ... -0.9060159  -1.4459164\n",
      "   0.8835318 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.2504241  0.27826712 0.2800015  ... 0.2878158  0.19063082 0.24607736]\n",
      " [0.2504241  0.27826712 0.2800015  ... 0.2878158  0.19063082 0.7078479 ]\n",
      " [0.2504241  0.27826712 0.97786707 ... 0.2878158  0.19063082 0.7240115 ]\n",
      " ...\n",
      " [0.2504241  0.27826712 0.2800015  ... 0.2878158  0.19063082 0.7059289 ]\n",
      " [0.2504241  0.27826712 0.2800015  ... 0.9959532  0.6472476  0.24607736]\n",
      " [0.2504241  0.27826712 0.2800015  ... 0.2878158  0.19063082 0.70755357]] (3.657 sec)\n",
      "INFO:tensorflow:loss = 0.7672068, step = 7500 (3.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5678\n",
      "INFO:tensorflow:acc = 0.99796873, acc_row = 0.94921875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.0907391  -0.9732376  -1.0087764  ... -0.8899793   0.49918428\n",
      "   0.9179117 ]\n",
      " [-1.0907391   3.9775963  -1.0087764  ... -0.8899793  -1.572331\n",
      "  -1.1538465 ]\n",
      " [-1.0907391  -0.9732376  -1.0087764  ... -0.8899793   0.34408805\n",
      "   0.8396552 ]\n",
      " ...\n",
      " [ 2.1689498  -0.9732376   2.9559944  ... -0.8899793  -1.572331\n",
      "  -1.1538465 ]\n",
      " [-1.0907391  -0.9732376  -1.0087764  ... -0.8899793  -1.572331\n",
      "   0.8472055 ]\n",
      " [-1.0907391   3.4965334  -1.0087764  ... -0.8899793  -1.572331\n",
      "  -1.1538465 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]], prob = [[0.25147912 0.27423567 0.2672194  ... 0.2911141  0.6222676  0.7146164 ]\n",
      " [0.25147912 0.98161376 0.2672194  ... 0.2911141  0.17188434 0.2397872 ]\n",
      " [0.25147912 0.27423567 0.2672194  ... 0.2911141  0.5851832  0.6983926 ]\n",
      " ...\n",
      " [0.8974263  0.27423567 0.9505461  ... 0.2911141  0.17188434 0.2397872 ]\n",
      " [0.25147912 0.27423567 0.2672194  ... 0.2911141  0.17188434 0.6999806 ]\n",
      " [0.25147912 0.9705889  0.2672194  ... 0.2911141  0.17188434 0.2397872 ]] (3.628 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7626289, step = 7600 (3.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7014\n",
      "INFO:tensorflow:acc = 0.99921876, acc_row = 0.98046875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.1418847  -0.91757715 -1.064941   ... -0.9130439  -1.5005089\n",
      "   0.8116584 ]\n",
      " [-1.1418847  -0.91757715 -1.064941   ... -0.9130439   0.54646343\n",
      "   0.80975676]\n",
      " [-1.1418847  -0.91757715 -1.064941   ... -0.9130439  -1.5005089\n",
      "  -1.2125117 ]\n",
      " ...\n",
      " [-1.1418847  -0.91757715 -1.064941   ... -0.9130439  -1.5005089\n",
      "   0.84280056]\n",
      " [ 1.6709237  -0.91757715 -1.064941   ... -0.9130439  -1.5005089\n",
      "  -1.2125117 ]\n",
      " [-1.1418847  -0.91757715 -1.064941   ... -0.9130439  -1.5005089\n",
      "   0.83413064]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.24197452 0.28545183 0.25636634 ... 0.28637737 0.18234964 0.6924628 ]\n",
      " [0.24197452 0.28545183 0.25636634 ... 0.28637737 0.6333147  0.69205767]\n",
      " [0.24197452 0.28545183 0.25636634 ... 0.28637737 0.18234964 0.22925694]\n",
      " ...\n",
      " [0.24197452 0.28545183 0.25636634 ... 0.28637737 0.18234964 0.6990547 ]\n",
      " [0.84169894 0.28545183 0.25636634 ... 0.28637737 0.18234964 0.22925694]\n",
      " [0.24197452 0.28545183 0.25636634 ... 0.28637737 0.18234964 0.69722766]] (3.610 sec)\n",
      "INFO:tensorflow:loss = 0.7666237, step = 7700 (3.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4958\n",
      "INFO:tensorflow:acc = 0.998125, acc_row = 0.95703125, labels = [[0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-0.88618255 -0.97233367  1.8110527  ... -0.9580172  -1.5977602\n",
      "  -1.1817262 ]\n",
      " [-1.1185141   4.328913   -1.1035345  ... -0.9580172  -1.5977602\n",
      "  -1.1817262 ]\n",
      " [-1.1185141  -0.97233367 -1.1035345  ... -0.9580172   0.37711185\n",
      "   0.83115214]\n",
      " ...\n",
      " [-1.1185141  -0.97233367 -1.1035345  ... -0.9580172  -1.5977602\n",
      "   0.8534185 ]\n",
      " [-1.1185141  -0.97233367 -1.1035345  ... -0.9580172   0.41635942\n",
      "   0.8250383 ]\n",
      " [-1.1185141  -0.97233367 -1.1035345  ... -0.9580172   0.40107855\n",
      "   0.8167698 ]], predicted_classes = [[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.29189825 0.27441558 0.859489   ... 0.27727535 0.16829489 0.23474199]\n",
      " [0.246287   0.98698956 0.24907823 ... 0.27727535 0.16829489 0.23474199]\n",
      " [0.246287   0.27441558 0.24907823 ... 0.27727535 0.59317636 0.69659853]\n",
      " ...\n",
      " [0.246287   0.27441558 0.24907823 ... 0.27727535 0.16829489 0.7012838 ]\n",
      " [0.246287   0.27441558 0.24907823 ... 0.27727535 0.6026118  0.69530475]\n",
      " [0.246287   0.27441558 0.24907823 ... 0.27727535 0.5989468  0.6935502 ]] (3.637 sec)\n",
      "INFO:tensorflow:loss = 0.76305246, step = 7800 (3.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6856\n",
      "INFO:tensorflow:acc = 0.9973438, acc_row = 0.93359375, labels = [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]], logits = [[ 2.2721748   2.979834   -0.94924885 ... -0.98920053 -1.5068398\n",
      "  -1.1546614 ]\n",
      " [-1.0905821  -1.0371398  -0.94924885 ... -0.98920053  0.4422489\n",
      "  -1.1546614 ]\n",
      " [-1.0905821  -1.0371398  -0.94924885 ... -0.98920053 -1.4773647\n",
      "   0.8172306 ]\n",
      " ...\n",
      " [-1.0905821  -1.0371398  -0.94924885 ... -0.98920053 -1.5068398\n",
      "   0.90270203]\n",
      " [-1.0905821  -1.0371398  -0.94924885 ... -0.98920053 -1.5068398\n",
      "  -1.1546614 ]\n",
      " [ 2.1552193  -1.0371398  -0.94924885 ... -0.98920053 -1.5068398\n",
      "  -1.1546614 ]], predicted_classes = [[1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], prob = [[0.9065462  0.95165473 0.2790359  ... 0.27107    0.18140762 0.23963869]\n",
      " [0.25150868 0.26170224 0.2790359  ... 0.27107    0.6087948  0.23963869]\n",
      " [0.25150868 0.26170224 0.2790359  ... 0.27107    0.18582581 0.69364816]\n",
      " ...\n",
      " [0.25150868 0.26170224 0.2790359  ... 0.27107    0.18140762 0.71150446]\n",
      " [0.25150868 0.26170224 0.2790359  ... 0.27107    0.18140762 0.23963869]\n",
      " [0.89615554 0.26170224 0.2790359  ... 0.27107    0.18140762 0.23963869]] (3.612 sec)\n",
      "INFO:tensorflow:loss = 0.76521116, step = 7900 (3.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6236\n",
      "INFO:tensorflow:acc = 0.99875, acc_row = 0.96875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-1.1075673  -0.98047316 -1.0452282  ... -0.9980488  -1.4083133\n",
      "   0.8952049 ]\n",
      " [-1.1075673  -0.98047316  3.2055807  ... -0.9980488   0.6972112\n",
      "   0.87981   ]\n",
      " [-1.1075673  -0.98047316  3.0913558  ... -0.9980488  -1.4083133\n",
      "   0.92575276]\n",
      " ...\n",
      " [ 2.204276   -0.98047316 -1.0452282  ... -0.9980488  -1.4083133\n",
      "  -1.1037245 ]\n",
      " [-1.1075673  -0.98047316 -1.0452282  ... -0.9980488  -1.4083133\n",
      "   0.90965104]\n",
      " [-1.1075673  -0.98047316 -1.0452282  ... -0.9980488   0.6459757\n",
      "  -1.1037245 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.24832469 0.2727979  0.26014248 ... 0.26932523 0.19650023 0.70996314]\n",
      " [0.24832469 0.2727979  0.9610438  ... 0.26932523 0.66756916 0.7067829 ]\n",
      " [0.24832469 0.2727979  0.95653474 ... 0.26932523 0.19650023 0.7162128 ]\n",
      " ...\n",
      " [0.90063286 0.2727979  0.26014248 ... 0.26932523 0.19650023 0.24904267]\n",
      " [0.24832469 0.2727979  0.26014248 ... 0.26932523 0.19650023 0.7129288 ]\n",
      " [0.24832469 0.2727979  0.26014248 ... 0.26932523 0.656103   0.24904267]] (3.620 sec)\n",
      "INFO:tensorflow:loss = 0.76313394, step = 8000 (3.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4271\n",
      "INFO:tensorflow:acc = 0.99859375, acc_row = 0.96484375, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.1394992  -1.0005013  -1.094648   ... -0.9369216  -1.4630959\n",
      "   0.79846096]\n",
      " [-1.1394992  -1.0005013  -1.094648   ... -0.9369216  -1.4630959\n",
      "  -1.2594492 ]\n",
      " [-1.1394992  -1.0005013  -1.094648   ... -0.9369216   0.6305984\n",
      "   0.77916574]\n",
      " ...\n",
      " [-1.1394992  -1.0005013  -1.094648   ... -0.9369216  -1.4630959\n",
      "   0.7815083 ]\n",
      " [ 2.0377712  -1.0005013  -1.094648   ... -0.9369216  -1.4630959\n",
      "  -1.2594492 ]\n",
      " [-1.1394992  -1.0005013  -1.094648   ... -0.9369216  -1.4630959\n",
      "   0.8159983 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.24241233 0.26884288 0.25074404 ... 0.2815226  0.18799427 0.6896452 ]\n",
      " [0.24241233 0.26884288 0.25074404 ... 0.2815226  0.18799427 0.22106871]\n",
      " [0.24241233 0.26884288 0.25074404 ... 0.2815226  0.65262514 0.68550026]\n",
      " ...\n",
      " [0.24241233 0.26884288 0.25074404 ... 0.2815226  0.18799427 0.6860051 ]\n",
      " [0.8847061  0.26884288 0.25074404 ... 0.2815226  0.18799427 0.22106871]\n",
      " [0.24241233 0.26884288 0.25074404 ... 0.2815226  0.18799427 0.6933862 ]] (3.645 sec)\n",
      "INFO:tensorflow:loss = 0.76206315, step = 8100 (3.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8238\n",
      "INFO:tensorflow:acc = 0.99859375, acc_row = 0.96484375, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.1550142   4.695464   -1.0722125  ... -0.97303444  0.20761578\n",
      "  -1.1804892 ]\n",
      " [-1.1550142  -0.9896229  -1.0722125  ... -0.97303444 -1.5557072\n",
      "   0.80677605]\n",
      " [-1.1550142  -0.9896229  -1.0722125  ... -0.97303444 -1.5229956\n",
      "   0.81902486]\n",
      " ...\n",
      " [-1.1550142  -0.9896229  -1.0722125  ... -0.97303444 -1.5557072\n",
      "   0.8244533 ]\n",
      " [ 2.0538418  -0.9896229  -1.0722125  ... -0.97303444 -1.5557072\n",
      "  -1.1804892 ]\n",
      " [-1.1550142  -0.9896229  -1.0722125  ... -0.97303444 -1.5557072\n",
      "   0.802287  ]], predicted_classes = [[0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.23957442 0.99094605 0.25498256 ... 0.27427608 0.55171835 0.23496425]\n",
      " [0.23957442 0.27098656 0.25498256 ... 0.27427608 0.1742635  0.6914221 ]\n",
      " [0.23957442 0.27098656 0.25498256 ... 0.27427608 0.17902082 0.69402933]\n",
      " ...\n",
      " [0.23957442 0.27098656 0.25498256 ... 0.27427608 0.1742635  0.69518083]\n",
      " [0.8863352  0.27098656 0.25498256 ... 0.27427608 0.1742635  0.23496425]\n",
      " [0.23957442 0.27098656 0.25498256 ... 0.27427608 0.1742635  0.6904635 ]] (3.595 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7603488, step = 8200 (3.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6029\n",
      "INFO:tensorflow:acc = 0.99828124, acc_row = 0.95703125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 1 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.0750322  -1.0189663  -1.1509434  ... -0.94142425 -1.518944\n",
      "   0.76821774]\n",
      " [-1.0750322  -1.0189663  -1.1509434  ... -0.94142425 -1.518944\n",
      "   0.75672394]\n",
      " [-1.0750322  -1.0189663  -1.1470407  ... -0.94142425  0.48477548\n",
      "   0.76979643]\n",
      " ...\n",
      " [-1.0750322  -1.0189663   2.1047127  ... -0.94142425  0.5273067\n",
      "  -1.2686245 ]\n",
      " [-1.0750322  -1.0189663  -1.1509434  ... -0.94142425  0.57019675\n",
      "  -1.2686245 ]\n",
      " [-1.0750322  -1.0189663  -1.1509434  ... -0.94142425 -1.518944\n",
      "  -1.2415926 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.25444728 0.2652288  0.24031681 ... 0.28061274 0.17961708 0.6831352 ]\n",
      " [0.25444728 0.2652288  0.24031681 ... 0.28061274 0.17961708 0.680642  ]\n",
      " [0.25444728 0.2652288  0.24103001 ... 0.28061274 0.6188749  0.68347687]\n",
      " ...\n",
      " [0.25444728 0.2652288  0.8913604  ... 0.28061274 0.62885475 0.2194928 ]\n",
      " [0.25444728 0.2652288  0.24031681 ... 0.28061274 0.63880855 0.2194928 ]\n",
      " [0.25444728 0.2652288  0.24031681 ... 0.28061274 0.17961708 0.22415888]] (3.623 sec)\n",
      "INFO:tensorflow:loss = 0.7609648, step = 8300 (3.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6568\n",
      "INFO:tensorflow:acc = 0.99828124, acc_row = 0.95703125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.1737249  -1.0301979  -1.1443269  ... -0.9654033  -1.4658372\n",
      "   0.8909438 ]\n",
      " [-1.1737249  -1.0301979  -1.1443269  ... -0.9654033  -1.4658372\n",
      "  -1.1715364 ]\n",
      " [-1.1737249  -1.0301979  -1.1443269  ... -0.9654033   0.583293\n",
      "   0.8621938 ]\n",
      " ...\n",
      " [-1.1737249  -1.0301979  -1.1443269  ... -0.9654033  -1.4658372\n",
      "   0.80924726]\n",
      " [-1.1737249  -1.0301979  -1.1443269  ... -0.9654033   0.59289473\n",
      "  -1.1715364 ]\n",
      " [-1.1737249  -1.0301979  -1.1443269  ... -0.9654033  -1.4658372\n",
      "   0.8383155 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.23618236 0.26304576 0.24152681 ... 0.27579767 0.18757614 0.7090849 ]\n",
      " [0.23618236 0.26304576 0.24152681 ... 0.27579767 0.18757614 0.23657738]\n",
      " [0.23618236 0.26304576 0.24152681 ... 0.27579767 0.64182484 0.7031188 ]\n",
      " ...\n",
      " [0.23618236 0.26304576 0.24152681 ... 0.27579767 0.18757614 0.69194907]\n",
      " [0.23618236 0.26304576 0.24152681 ... 0.27579767 0.6440291  0.23657738]\n",
      " [0.23618236 0.26304576 0.24152681 ... 0.27579767 0.18757614 0.6981103 ]] (3.614 sec)\n",
      "INFO:tensorflow:loss = 0.76113784, step = 8400 (3.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0182\n",
      "INFO:tensorflow:acc = 0.99890625, acc_row = 0.97265625, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-1.1966865  -0.99561906 -1.1079038  ... -1.00205     0.5314895\n",
      "  -1.1732184 ]\n",
      " [-1.1966865  -0.99561906  2.781213   ... -1.00205    -1.5331547\n",
      "   0.85098004]\n",
      " [-1.1966865  -0.99561906 -1.1079038  ... -1.00205     0.4999485\n",
      "   0.8535522 ]\n",
      " ...\n",
      " [-1.1966865  -0.99561906 -1.1079038  ... -1.00205     0.50549334\n",
      "  -1.1732184 ]\n",
      " [-1.1966865  -0.99561906  2.58071    ... -1.00205    -1.5331547\n",
      "   0.80114067]\n",
      " [-1.1966865  -0.99561906 -1.1079038  ... -1.00205     0.5314895\n",
      "  -1.1732184 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.23206519 0.26980364 0.24826188 ... 0.26853853 0.6298304  0.23627374]\n",
      " [0.23206519 0.26980364 0.9416521  ... 0.26853853 0.17753258 0.7007727 ]\n",
      " [0.23206519 0.26980364 0.24826188 ... 0.26853853 0.62244725 0.7013118 ]\n",
      " ...\n",
      " [0.23206519 0.26980364 0.24826188 ... 0.26853853 0.62374943 0.23627374]\n",
      " [0.23206519 0.26980364 0.9296098  ... 0.26853853 0.17753258 0.6902184 ]\n",
      " [0.23206519 0.26980364 0.24826188 ... 0.26853853 0.6298304  0.23627374]] (3.570 sec)\n",
      "INFO:tensorflow:loss = 0.7595218, step = 8500 (3.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7464\n",
      "INFO:tensorflow:acc = 0.99921876, acc_row = 0.98046875, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.11079    -0.97839105 -1.1341872  ... -1.010545    0.32567304\n",
      "  -1.259953  ]\n",
      " [-1.11079    -0.97839105 -1.1341872  ... -1.010545   -1.6746415\n",
      "  -1.259953  ]\n",
      " [-1.11079    -0.97839105 -1.1341872  ... -1.010545    0.31130055\n",
      "  -1.259953  ]\n",
      " ...\n",
      " [-1.11079    -0.97839105 -1.1341872  ... -1.010545   -1.6746415\n",
      "   0.7911789 ]\n",
      " [-1.11079    -0.97839105 -1.1341872  ... -1.010545    0.29676494\n",
      "  -1.259953  ]\n",
      " [-1.11079    -0.97839105 -1.1341872  ... -1.0010791  -1.6746415\n",
      "   0.83402896]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.24772364 0.27321115 0.24338919 ... 0.2668732  0.58070624 0.22098199]\n",
      " [0.24772364 0.27321115 0.24338919 ... 0.2668732  0.15780632 0.22098199]\n",
      " [0.24772364 0.27321115 0.24338919 ... 0.2668732  0.5772027  0.22098199]\n",
      " ...\n",
      " [0.24772364 0.27321115 0.24338919 ... 0.2668732  0.15780632 0.6880844 ]\n",
      " [0.24772364 0.27321115 0.24338919 ... 0.2668732  0.5736515  0.22098199]\n",
      " [0.24772364 0.27321115 0.24338919 ... 0.2687293  0.15780632 0.69720614]] (3.604 sec)\n",
      "INFO:tensorflow:loss = 0.76012015, step = 8600 (3.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.688\n",
      "INFO:tensorflow:acc = 0.9978125, acc_row = 0.94921875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-1.2155986  -1.0676711  -1.1289554  ... -1.0323828   0.4169751\n",
      "   0.8619136 ]\n",
      " [-1.2155986   3.6967986  -1.1444639  ... -1.0323828  -1.5569878\n",
      "  -1.1629632 ]\n",
      " [-1.2155986  -1.0676711  -1.1444639  ... -1.0323828  -1.5569878\n",
      "   0.9011687 ]\n",
      " ...\n",
      " [-1.2155986  -1.0676711  -1.1444639  ... -1.0323828  -1.5569878\n",
      "   0.79613304]\n",
      " [-1.2155986  -1.0676711  -1.1444639  ... -1.0323828   0.39452714\n",
      "  -1.1629632 ]\n",
      " [-1.2155986  -1.0676711  -1.1444639  ... -1.0323828   0.5504228\n",
      "  -1.1629632 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.22871195 0.25584623 0.24435394 ... 0.26262242 0.6027592  0.7030603 ]\n",
      " [0.22871195 0.9757975  0.24150173 ... 0.26262242 0.1740793  0.23812926]\n",
      " [0.22871195 0.25584623 0.24150173 ... 0.26262242 0.1740793  0.7111896 ]\n",
      " ...\n",
      " [0.22871195 0.25584623 0.24150173 ... 0.26262242 0.1740793  0.6891467 ]\n",
      " [0.22871195 0.25584623 0.24150173 ... 0.26262242 0.597372   0.23812926]\n",
      " [0.22871195 0.25584623 0.24150173 ... 0.26262242 0.63423365 0.23812926]] (3.611 sec)\n",
      "INFO:tensorflow:loss = 0.7556465, step = 8700 (3.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2259\n",
      "INFO:tensorflow:acc = 0.99796873, acc_row = 0.953125, labels = [[0 0 1 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.1130553  -1.0867914   2.0672288  ... -1.0644851   0.37393293\n",
      "   0.8172623 ]\n",
      " [ 2.8975248  -1.0867914  -1.1899627  ... -1.0644851  -1.6059725\n",
      "   0.76276493]\n",
      " [-1.1130553  -1.0867914  -1.1899627  ... -1.0644851   0.38071802\n",
      "   0.79440737]\n",
      " ...\n",
      " [-1.1130553  -1.0867914  -1.1899627  ... -1.0644851   0.40230682\n",
      "  -1.228956  ]\n",
      " [ 2.7817802  -1.0867914   2.0708826  ... -1.0644851  -1.6059725\n",
      "  -1.228956  ]\n",
      " [-1.1130553  -1.0867914  -1.1899627  ... -1.0644851   0.41208163\n",
      "   0.81433535]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.2473017  0.25222296 0.887677   ... 0.25645328 0.59240896 0.6936549 ]\n",
      " [0.947724   0.25222296 0.23326561 ... 0.25645328 0.16714853 0.6819537 ]\n",
      " [0.2473017  0.25222296 0.23326561 ... 0.25645328 0.59404624 0.68877685]\n",
      " ...\n",
      " [0.2473017  0.25222296 0.23326561 ... 0.25645328 0.59924173 0.2263642 ]\n",
      " [0.9416833  0.25222296 0.8880408  ... 0.25645328 0.16714853 0.2263642 ]\n",
      " [0.2473017  0.25222296 0.23326561 ... 0.25645328 0.60158694 0.6930326 ]] (3.674 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.75844955, step = 8800 (3.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5248\n",
      "INFO:tensorflow:acc = 0.99875, acc_row = 0.96875, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.1778134  -1.064795   -1.1925361  ... -0.9978603   0.56069493\n",
      "  -1.227727  ]\n",
      " [-1.1778134  -1.064795   -1.1925361  ... -0.9978603   0.48353663\n",
      "  -1.227727  ]\n",
      " [-1.1778134  -1.064795   -1.1925361  ... -0.9978603  -1.5519519\n",
      "   0.7356337 ]\n",
      " ...\n",
      " [-1.1778134  -1.064795   -1.1925361  ... -0.9978603   0.5050789\n",
      "   0.8048544 ]\n",
      " [-1.1778134  -1.064795   -1.1925361  ... -0.9978603   0.4842935\n",
      "   0.79905355]\n",
      " [-1.1778134  -1.064795   -1.1925361  ... -0.9978603   0.47296464\n",
      "   0.80258656]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.23544559 0.25639418 0.23280565 ... 0.26936233 0.6366133  0.22657952]\n",
      " [0.23544559 0.25639418 0.23280565 ... 0.26936233 0.61858267 0.22657952]\n",
      " [0.23544559 0.25639418 0.23280565 ... 0.26936233 0.17480454 0.67604035]\n",
      " ...\n",
      " [0.23544559 0.25639418 0.23280565 ... 0.26936233 0.62365216 0.6910119 ]\n",
      " [0.23544559 0.25639418 0.23280565 ... 0.26936233 0.61876124 0.68977195]\n",
      " [0.23544559 0.25639418 0.23280565 ... 0.26936233 0.61608523 0.6905275 ]] (3.633 sec)\n",
      "INFO:tensorflow:loss = 0.7564354, step = 8900 (3.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6972\n",
      "INFO:tensorflow:acc = 0.998125, acc_row = 0.953125, labels = [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]], logits = [[ 2.1132274  -1.1053251  -1.1391847  ... -1.0490341  -1.6108198\n",
      "  -1.2009673 ]\n",
      " [-1.1942321  -1.1053251  -1.1391847  ... -1.0490341  -1.6108198\n",
      "   0.80488425]\n",
      " [-1.1942321  -1.1053251  -1.1391847  ... -1.0490341  -1.6108198\n",
      "   0.8218828 ]\n",
      " ...\n",
      " [-1.1942321  -1.1053251  -1.1391847  ... -1.0490341  -1.6108198\n",
      "  -1.2009673 ]\n",
      " [-1.1942321  -1.1053251  -1.1391847  ... -1.0490341  -1.6108198\n",
      "   0.8412635 ]\n",
      " [-1.1942321  -1.1053251  -1.1391847  ... -1.0490341   0.42064765\n",
      "  -1.2009673 ]], predicted_classes = [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.8921822  0.24874344 0.2424701  ... 0.25941062 0.16647483 0.23130319]\n",
      " [0.23250291 0.24874344 0.2424701  ... 0.25941062 0.16647483 0.6910183 ]\n",
      " [0.23250291 0.24874344 0.2424701  ... 0.25941062 0.16647483 0.69463587]\n",
      " ...\n",
      " [0.23250291 0.24874344 0.2424701  ... 0.25941062 0.16647483 0.23130319]\n",
      " [0.23250291 0.24874344 0.2424701  ... 0.25941062 0.16647483 0.69873124]\n",
      " [0.23250291 0.24874344 0.2424701  ... 0.25941062 0.60363823 0.23130319]] (3.611 sec)\n",
      "INFO:tensorflow:loss = 0.7551059, step = 9000 (3.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6984\n",
      "INFO:tensorflow:acc = 0.9971875, acc_row = 0.9296875, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.1431574  -1.1500583  -1.1561205  ... -1.0152194   0.42208418\n",
      "   0.9227966 ]\n",
      " [-1.1431574  -1.1500583  -1.1561205  ... -1.0152194  -1.6520302\n",
      "  -1.085011  ]\n",
      " [-1.1431574  -1.1500583  -1.1561205  ... -1.0152194   0.35797387\n",
      "  -1.085011  ]\n",
      " ...\n",
      " [-1.1431574  -1.1500583  -1.1561205  ... -1.0152194  -1.6520302\n",
      "  -1.085011  ]\n",
      " [-1.1431574  -1.1500583  -1.1561205  ... -1.0152194   0.4267254\n",
      "   0.89209884]\n",
      " [-1.1431574  -1.1500583  -1.1495328  ... -1.0152194   0.3702999\n",
      "   0.939715  ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.24174117 0.24047846 0.23937294 ... 0.26595965 0.6039819  0.7156116 ]\n",
      " [0.24174117 0.24047846 0.23937294 ... 0.26595965 0.16083476 0.25255892]\n",
      " [0.24174117 0.24047846 0.23937294 ... 0.26595965 0.5885499  0.25255892]\n",
      " ...\n",
      " [0.24174117 0.24047846 0.23937294 ... 0.26595965 0.16083476 0.25255892]\n",
      " [0.24174117 0.24047846 0.23937294 ... 0.26595965 0.60509145 0.7093231 ]\n",
      " [0.24174117 0.24047846 0.24057443 ... 0.26595965 0.59153146 0.71904206]] (3.610 sec)\n",
      "INFO:tensorflow:loss = 0.7541504, step = 9100 (3.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3605\n",
      "INFO:tensorflow:acc = 0.99890625, acc_row = 0.97265625, labels = [[0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.1837392  -1.0606303   3.1601088  ... -1.0275027   0.37181845\n",
      "   0.76896954]\n",
      " [-1.1837392  -1.0606303  -1.1414465  ... -0.7240595   0.33301952\n",
      "   0.8100493 ]\n",
      " [-1.1837392  -1.0606303  -1.1414465  ... -1.0275027  -1.65837\n",
      "   0.8189021 ]\n",
      " ...\n",
      " [-1.1837392  -1.0606303  -1.1414465  ... -1.0275027   0.32401446\n",
      "   0.8520314 ]\n",
      " [ 2.456269   -1.0606303  -1.1414465  ... -1.0275027  -1.65837\n",
      "  -1.2309926 ]\n",
      " [-1.1837392  -1.0606303  -1.1414465  ... -1.0275027   0.3546191\n",
      "   0.8137411 ]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.23438054 0.25718904 0.9593052  ... 0.26356858 0.5918983  0.68329793]\n",
      " [0.23438054 0.25718904 0.2420549  ... 0.32649967 0.5824939  0.69212   ]\n",
      " [0.23438054 0.25718904 0.2420549  ... 0.26356858 0.15998094 0.6940032 ]\n",
      " ...\n",
      " [0.23438054 0.25718904 0.2420549  ... 0.26356858 0.5803023  0.7009931 ]\n",
      " [0.9210187  0.25718904 0.2420549  ... 0.26356858 0.15998094 0.22600773]\n",
      " [0.23438054 0.25718904 0.2420549  ... 0.26356858 0.58773726 0.69290614]] (3.655 sec)\n",
      "INFO:tensorflow:loss = 0.754997, step = 9200 (3.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3872\n",
      "INFO:tensorflow:acc = 0.9978125, acc_row = 0.9453125, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.229601   -1.1445236  -1.1757178  ... -1.1412212  -1.574554\n",
      "   0.77477086]\n",
      " [-1.229601   -1.1445236  -1.1757178  ... -1.1412212  -1.574554\n",
      "   0.80614877]\n",
      " [-1.229601    2.6271145  -1.1757178  ... -1.1412212  -1.574554\n",
      "  -1.2503846 ]\n",
      " ...\n",
      " [-1.229601   -1.1445236  -1.1757178  ... -1.1412212   0.47609663\n",
      "   0.800614  ]\n",
      " [-1.229601   -1.1445236  -1.1757178  ... -1.1412212  -1.574554\n",
      "   0.7759188 ]\n",
      " [-1.229601   -1.1445236  -1.1757178  ... -1.1412212  -1.574554\n",
      "   0.7938111 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.22625127 0.2414908  0.23582302 ... 0.24209625 0.17156816 0.684552  ]\n",
      " [0.22625127 0.2414908  0.23582302 ... 0.24209625 0.17156816 0.6912882 ]\n",
      " [0.22625127 0.9325864  0.23582302 ... 0.24209625 0.17156816 0.22263356]\n",
      " ...\n",
      " [0.22625127 0.2414908  0.23582302 ... 0.24209625 0.61682576 0.6901058 ]\n",
      " [0.22625127 0.2414908  0.23582302 ... 0.24209625 0.17156816 0.68479985]\n",
      " [0.22625127 0.2414908  0.23582302 ... 0.24209625 0.17156816 0.68864906]] (3.651 sec)\n",
      "INFO:tensorflow:loss = 0.7541127, step = 9300 (3.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4782\n",
      "INFO:tensorflow:acc = 0.9984375, acc_row = 0.9609375, labels = [[0 0 0 ... 1 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 1 0]], logits = [[-1.2259982  -1.1028395  -1.2685311  ...  4.57647    -1.5732824\n",
      "  -1.1911536 ]\n",
      " [-1.2259982  -1.1028395   1.8023049  ... -1.0990527  -1.5732824\n",
      "  -1.1911536 ]\n",
      " [-1.2259982  -1.1028395  -1.2685311  ... -1.0990527  -1.5732824\n",
      "  -1.1911536 ]\n",
      " ...\n",
      " [-1.2259982  -1.1028395  -1.2685311  ... -1.0990527  -1.5732824\n",
      "  -1.1911536 ]\n",
      " [-1.2259982  -1.1028395  -1.2685311  ... -1.0990527   0.46845832\n",
      "   0.8356208 ]\n",
      " [ 2.1314528  -1.1028395  -1.2685311  ... -1.0990527   0.5051336\n",
      "  -1.1911536 ]], predicted_classes = [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]], prob = [[0.2268826  0.24920823 0.21950881 ... 0.9898136  0.17174897 0.23305267]\n",
      " [0.2268826  0.24920823 0.8584293  ... 0.24991745 0.17174897 0.23305267]\n",
      " [0.2268826  0.24920823 0.21950881 ... 0.24991745 0.17174897 0.23305267]\n",
      " ...\n",
      " [0.2268826  0.24920823 0.21950881 ... 0.24991745 0.17174897 0.23305267]\n",
      " [0.2268826  0.24920823 0.21950881 ... 0.24991745 0.6150188  0.69754213]\n",
      " [0.89392287 0.24920823 0.21950881 ... 0.24991745 0.623665   0.23305267]] (3.640 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7543927, step = 9400 (3.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5188\n",
      "INFO:tensorflow:acc = 0.9990625, acc_row = 0.9765625, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.2430526  -1.1210175  -1.1776876  ... -1.0838118  -1.6068337\n",
      "  -1.2905713 ]\n",
      " [-1.2430526  -1.1210175  -1.1776876  ... -1.0838118   0.40953127\n",
      "   0.73717976]\n",
      " [-1.2430526  -1.1210175  -1.1776876  ... -1.0838118  -1.6068337\n",
      "   0.7942407 ]\n",
      " ...\n",
      " [-1.2430526  -1.1210175  -1.1776876  ... -1.0838118   0.6226564\n",
      "  -1.2905713 ]\n",
      " [-1.2430526  -1.1210175  -1.1776876  ... -1.0838118  -1.6068337\n",
      "  -1.2905713 ]\n",
      " [-1.2430526  -1.1210175  -1.1776876  ... -1.0838118  -1.6068337\n",
      "  -1.2905713 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.22390507 0.24582261 0.23546822 ... 0.25278535 0.16702868 0.21575612]\n",
      " [0.22390507 0.24582261 0.23546822 ... 0.25278535 0.60097545 0.67637885]\n",
      " [0.22390507 0.24582261 0.23546822 ... 0.25278535 0.16702868 0.6887412 ]\n",
      " ...\n",
      " [0.22390507 0.24582261 0.23546822 ... 0.25278535 0.65082246 0.21575612]\n",
      " [0.22390507 0.24582261 0.23546822 ... 0.25278535 0.16702868 0.21575612]\n",
      " [0.22390507 0.24582261 0.23546822 ... 0.25278535 0.16702868 0.21575612]] (3.634 sec)\n",
      "INFO:tensorflow:loss = 0.75069517, step = 9500 (3.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4273\n",
      "INFO:tensorflow:acc = 0.99921876, acc_row = 0.98046875, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.3139563 -1.1019434 -1.1966174 ... -1.1502855 -1.553055  -1.0952693]\n",
      " [-1.3139563 -1.1019434 -1.1966174 ... -1.1502855 -1.553055   0.9302459]\n",
      " [-1.3139563 -1.1019434 -1.1966174 ... -1.1502855 -1.553055  -1.0952693]\n",
      " ...\n",
      " [ 1.5560223 -1.1019434 -1.1966174 ... -1.1502855 -1.553055  -1.0952693]\n",
      " [-1.3139563 -1.1019434 -1.1966174 ... -1.1502855 -1.553055   0.9333195]\n",
      " [-1.3139563 -1.1019434 -1.1966174 ... -1.1502855 -1.553055   0.9379588]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.21182558 0.24937595 0.23207751 ... 0.24043693 0.17464547 0.25062734]\n",
      " [0.21182558 0.24937595 0.23207751 ... 0.24043693 0.17464547 0.7171252 ]\n",
      " [0.21182558 0.24937595 0.23207751 ... 0.24043693 0.17464547 0.25062734]\n",
      " ...\n",
      " [0.8257818  0.24937595 0.23207751 ... 0.24043693 0.17464547 0.25062734]\n",
      " [0.21182558 0.24937595 0.23207751 ... 0.24043693 0.17464547 0.7177482 ]\n",
      " [0.21182558 0.24937595 0.23207751 ... 0.24043693 0.17464547 0.7186872 ]] (3.646 sec)\n",
      "INFO:tensorflow:loss = 0.7505738, step = 9600 (3.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7073\n",
      "INFO:tensorflow:acc = 0.99859375, acc_row = 0.96484375, labels = [[0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.267192   -1.137402    1.9254088  ... -1.0891116  -1.5766463\n",
      "   0.86848414]\n",
      " [-1.267192   -1.137402   -1.2958145  ... -1.0891116  -1.5766463\n",
      "   0.84991026]\n",
      " [-1.267192   -1.137402   -1.2958145  ... -1.0891116  -1.5766463\n",
      "   0.872111  ]\n",
      " ...\n",
      " [-1.267192   -1.137402   -1.2958145  ... -1.0891116  -1.5766463\n",
      "   0.9251078 ]\n",
      " [ 2.0414329  -1.137402   -1.2958145  ... -1.0891116   0.47513402\n",
      "  -1.155311  ]\n",
      " [-1.267192   -1.137402   -1.2958145  ... -1.0891116  -1.5766463\n",
      "  -1.155311  ]], predicted_classes = [[0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.2197383  0.24279767 0.8727404  ... 0.2517856  0.17127097 0.70443016]\n",
      " [0.2197383  0.24279767 0.21487029 ... 0.2517856  0.17127097 0.70054835]\n",
      " [0.2197383  0.24279767 0.21487029 ... 0.2517856  0.17127097 0.70518476]\n",
      " ...\n",
      " [0.2197383  0.24279767 0.21487029 ... 0.2517856  0.17127097 0.71608174]\n",
      " [0.8850791  0.24279767 0.21487029 ... 0.2517856  0.61659825 0.23952034]\n",
      " [0.2197383  0.24279767 0.21487029 ... 0.2517856  0.17127097 0.23952034]] (3.609 sec)\n",
      "INFO:tensorflow:loss = 0.7497216, step = 9700 (3.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2621\n",
      "INFO:tensorflow:acc = 0.9996875, acc_row = 0.9921875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.2764719  -1.0386969  -1.2308686  ... -1.0983388  -1.5809078\n",
      "   0.91589546]\n",
      " [-1.2764719  -1.0386969  -1.2308686  ... -1.0983388   0.55081475\n",
      "   0.86583984]\n",
      " [-1.2764719  -1.0386969  -1.2308686  ... -1.0983388  -1.5809078\n",
      "  -1.2208285 ]\n",
      " ...\n",
      " [-1.2764719  -1.0386969  -1.2308686  ... -1.0983388  -1.5809078\n",
      "   0.757581  ]\n",
      " [-1.2764719  -1.0386969  -1.2308686  ... -1.0983388  -1.5809078\n",
      "   0.8089051 ]\n",
      " [-1.2764719  -1.0386969  -1.2308686  ... -1.0983388   0.48585454\n",
      "   0.81201214]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.2181514  0.26140153 0.22602944 ... 0.2500513  0.17066696 0.714205  ]\n",
      " [0.2181514  0.26140153 0.22602944 ... 0.2500513  0.6343246  0.70387936]\n",
      " [0.2181514  0.26140153 0.22602944 ... 0.2500513  0.17066696 0.22779067]\n",
      " ...\n",
      " [0.2181514  0.26140153 0.22602944 ... 0.2500513  0.17066696 0.6808283 ]\n",
      " [0.2181514  0.26140153 0.22602944 ... 0.2500513  0.17066696 0.6918761 ]\n",
      " [0.2181514  0.26140153 0.22602944 ... 0.2500513  0.6191294  0.6925381 ]] (3.538 sec)\n",
      "INFO:tensorflow:loss = 0.75109804, step = 9800 (3.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1533\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 1]], logits = [[-1.2638345  -1.0518235  -1.2718616  ... -1.1784106  -1.5639162\n",
      "  -1.239159  ]\n",
      " [-1.2638345  -1.0518235  -1.2718616  ... -1.1784106   0.53402364\n",
      "   0.81114024]\n",
      " [-1.2638345  -1.0518235  -1.2718616  ... -1.1784106  -1.5639162\n",
      "   0.77201957]\n",
      " ...\n",
      " [-1.2638345  -1.0518235   2.3561347  ... -1.1784106   0.5677859\n",
      "   0.85725445]\n",
      " [-1.2638345  -1.0518235  -1.2718616  ... -1.1784106  -1.5639162\n",
      "   0.80224204]\n",
      " [ 2.3120518  -1.0518235  -1.2718616  ... -1.1784106  -1.5639162\n",
      "   0.7802488 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]], prob = [[0.22031453 0.2588751  0.21893874 ... 0.23533808 0.17308542 0.22458242]\n",
      " [0.22031453 0.2588751  0.21893874 ... 0.23533808 0.6304211  0.6923524 ]\n",
      " [0.22031453 0.2588751  0.21893874 ... 0.23533808 0.17308542 0.6839576 ]\n",
      " ...\n",
      " [0.22031453 0.2588751  0.91342056 ... 0.23533808 0.63825214 0.70208675]\n",
      " [0.22031453 0.2588751  0.21893874 ... 0.23533808 0.17308542 0.6904539 ]\n",
      " [0.90987027 0.2588751  0.21893874 ... 0.23533808 0.17308542 0.68573374]] (3.682 sec)\n",
      "INFO:tensorflow:loss = 0.74939895, step = 9900 (3.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5408\n",
      "INFO:tensorflow:acc = 0.9998438, acc_row = 0.99609375, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.3096794  -1.1446975  -1.2496302  ... -1.0872273   0.46625367\n",
      "   0.78462386]\n",
      " [-1.3103297  -1.1446975  -1.2496302  ... -1.0872273  -1.5796866\n",
      "  -1.2684852 ]\n",
      " [-1.3103297  -1.1446975  -1.2496302  ... -1.0872273   0.46168232\n",
      "  -1.2684852 ]\n",
      " ...\n",
      " [ 1.8924636  -1.1446975  -1.2496302  ... -1.0872273  -1.5796866\n",
      "  -1.2684852 ]\n",
      " [-1.3103297  -1.1446975  -1.2496302  ... -1.0872273   0.48749253\n",
      "   0.7817761 ]\n",
      " [-1.3103297  -1.1446975  -1.2496302  ... -1.0872273  -1.5796866\n",
      "  -1.2684852 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.2125405  0.24145894 0.22276415 ... 0.25214073 0.61449665 0.6866758 ]\n",
      " [0.21243168 0.24145894 0.22276415 ... 0.25214073 0.17083988 0.21951666]\n",
      " [0.21243168 0.24145894 0.22276415 ... 0.25214073 0.61341316 0.21951666]\n",
      " ...\n",
      " [0.8690362  0.24145894 0.22276415 ... 0.25214073 0.17083988 0.21951666]\n",
      " [0.21243168 0.24145894 0.22276415 ... 0.25214073 0.61951554 0.68606275]\n",
      " [0.21243168 0.24145894 0.22276415 ... 0.25214073 0.17083988 0.21951666]] (3.631 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7466513, step = 10000 (3.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6684\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 0]], logits = [[-1.3189704  -1.0688541  -1.3264993  ... -1.1535077   0.36143646\n",
      "  -1.2790968 ]\n",
      " [-1.3189704  -1.0688541  -1.3264993  ... -1.1535077  -1.652657\n",
      "  -1.2790968 ]\n",
      " [-1.3189704  -1.0688541   1.8568753  ... -1.1535077   0.33144113\n",
      "   0.7656529 ]\n",
      " ...\n",
      " [-1.3189704  -1.0688541  -1.3264993  ... -1.1535077  -1.652657\n",
      "   0.781606  ]\n",
      " [-1.3189704  -1.0688541  -1.3264993  ... -1.1535077   0.34774044\n",
      "   0.7756151 ]\n",
      " [ 1.9091107  -1.0688541  -1.3264993  ... -1.1535077  -1.652657\n",
      "  -1.2790968 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], prob = [[0.21098964 0.25562108 0.209739   ... 0.23984896 0.58938813 0.21770403]\n",
      " [0.21098964 0.25562108 0.209739   ... 0.23984896 0.16075017 0.21770403]\n",
      " [0.21098964 0.25562108 0.8649323  ... 0.23984896 0.58211    0.6825798 ]\n",
      " ...\n",
      " [0.21098964 0.25562108 0.209739   ... 0.23984896 0.16075017 0.6860261 ]\n",
      " [0.21098964 0.25562108 0.209739   ... 0.23984896 0.5860695  0.6847343 ]\n",
      " [0.87091917 0.25562108 0.209739   ... 0.23984896 0.16075017 0.21770403]] (3.614 sec)\n",
      "INFO:tensorflow:loss = 0.7470513, step = 10100 (3.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7075\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.2850268  -1.0537544  -1.2764595  ... -1.1209304  -1.5904244\n",
      "   0.82333493]\n",
      " [-1.2850268  -1.0537544  -1.2764595  ... -1.1209304  -1.5904244\n",
      "   0.80945724]\n",
      " [-1.2850268  -1.0537544  -1.2764595  ... -1.1209304  -1.5904244\n",
      "   0.82333493]\n",
      " ...\n",
      " [-1.2850268  -1.0537544  -1.2764595  ... -1.1209304   0.4829624\n",
      "   0.80525833]\n",
      " [-1.2850268  -1.0537544  -1.2764595  ... -1.1209304  -1.5904244\n",
      "   0.78305906]\n",
      " [-1.2850268  -1.0537544  -1.2764595  ... -1.1209304  -1.5904244\n",
      "   0.84471184]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.21669576 0.25850478 0.2181535  ... 0.24583875 0.16932419 0.6949438 ]\n",
      " [0.21669576 0.25850478 0.2181535  ... 0.24583875 0.16932419 0.69199383]\n",
      " [0.21669576 0.25850478 0.2181535  ... 0.24583875 0.16932419 0.6949438 ]\n",
      " ...\n",
      " [0.21669576 0.25850478 0.2181535  ... 0.24583875 0.6184472  0.69109815]\n",
      " [0.21669576 0.25850478 0.2181535  ... 0.24583875 0.16932419 0.686339  ]\n",
      " [0.21669576 0.25850478 0.2181535  ... 0.24583875 0.16932419 0.69945663]] (3.609 sec)\n",
      "INFO:tensorflow:loss = 0.7478064, step = 10200 (3.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8976\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[ 1.6452025  -1.11023    -1.3380337  ... -1.1458101   0.33802322\n",
      "  -1.1715846 ]\n",
      " [-1.3719206  -1.11023    -1.3380337  ... -1.1458101   0.30436113\n",
      "   0.8629569 ]\n",
      " [-1.3719206  -1.11023    -1.3380337  ... -1.1458101  -1.6763046\n",
      "   0.850919  ]\n",
      " ...\n",
      " [-1.3719206  -1.11023    -1.3380337  ... -1.1458101  -1.6763046\n",
      "  -1.1715846 ]\n",
      " [-1.3719206  -1.11023    -1.3380337  ... -1.1458101   0.34905633\n",
      "  -1.1715846 ]\n",
      " [-1.3719206  -1.11023    -1.3380337  ... -1.1458101  -1.6763046\n",
      "  -1.1715846 ]], predicted_classes = [[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.8382416  0.24782802 0.2078336  ... 0.24125522 0.58371025 0.23656867]\n",
      " [0.20230973 0.24782802 0.2078336  ... 0.24125522 0.5755083  0.70327806]\n",
      " [0.20230973 0.24782802 0.2078336  ... 0.24125522 0.15758543 0.7007599 ]\n",
      " ...\n",
      " [0.20230973 0.24782802 0.2078336  ... 0.24125522 0.15758543 0.23656867]\n",
      " [0.20230973 0.24782802 0.2078336  ... 0.24125522 0.5863887  0.23656867]\n",
      " [0.20230973 0.24782802 0.2078336  ... 0.24125522 0.15758543 0.23656867]] (3.585 sec)\n",
      "INFO:tensorflow:loss = 0.746827, step = 10300 (3.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8904\n",
      "INFO:tensorflow:acc = 0.9998438, acc_row = 0.99609375, labels = [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]], logits = [[ 1.8639059 -1.1524732 -1.326273  ... -1.2164446 -1.6351137 -1.291704 ]\n",
      " [-1.3541818 -1.1524732 -1.326273  ... -1.2164446 -1.6351137  0.7040087]\n",
      " [-1.3541818 -1.1524732 -1.326273  ... -1.2164446 -1.6351137  0.7596941]\n",
      " ...\n",
      " [-1.3541818 -1.1524732 -1.326273  ... -1.2164446 -1.6351137 -1.291704 ]\n",
      " [ 1.6850104 -1.1524732 -1.326273  ... -1.2164446 -1.6351137  0.8362026]\n",
      " [-1.3541818 -1.1524732 -1.326273  ... -1.2164446 -1.6351137 -1.291704 ]], predicted_classes = [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.86575156 0.24003762 0.20977654 ... 0.22856276 0.16313103 0.2155645 ]\n",
      " [0.20518756 0.24003762 0.20977654 ... 0.22856276 0.16313103 0.66907597]\n",
      " [0.20518756 0.24003762 0.20977654 ... 0.22856276 0.16313103 0.68128735]\n",
      " ...\n",
      " [0.20518756 0.24003762 0.20977654 ... 0.22856276 0.16313103 0.2155645 ]\n",
      " [0.8435669  0.24003762 0.20977654 ... 0.22856276 0.16313103 0.69766486]\n",
      " [0.20518756 0.24003762 0.20977654 ... 0.22856276 0.16313103 0.2155645 ]] (3.586 sec)\n",
      "INFO:tensorflow:loss = 0.7444984, step = 10400 (3.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4474\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.3053883  -1.1122272  -1.3278234  ... -1.2896607  -1.6932216\n",
      "   0.8858397 ]\n",
      " [-1.3053883  -1.1122272  -1.3278234  ... -1.2896607   0.33022636\n",
      "   0.93124   ]\n",
      " [-1.3053883  -1.1122272  -1.3278234  ... -1.2896607  -1.6932216\n",
      "   0.8519294 ]\n",
      " ...\n",
      " [-1.3053883  -1.1122272  -1.3278234  ... -1.2896607   0.3590682\n",
      "  -1.1194395 ]\n",
      " [-1.3053883  -1.1122272  -1.3278234  ... -1.2896607  -1.6932216\n",
      "   0.8915943 ]\n",
      " [-1.3053883  -1.1122272  -1.3278234  ... -1.2896607   0.3332116\n",
      "   0.9053776 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.21325958 0.24745588 0.20951964 ... 0.21591024 0.15535265 0.70803094]\n",
      " [0.21325958 0.24745588 0.20951964 ... 0.21591024 0.58181447 0.71732676]\n",
      " [0.21325958 0.24745588 0.20951964 ... 0.21591024 0.15535265 0.7009717 ]\n",
      " ...\n",
      " [0.21325958 0.24745588 0.20951964 ... 0.21591024 0.58881485 0.24611525]\n",
      " [0.21325958 0.24745588 0.20951964 ... 0.21591024 0.15535265 0.7092191 ]\n",
      " [0.21325958 0.24745588 0.20951964 ... 0.21591024 0.58254063 0.71205336]] (3.643 sec)\n",
      "INFO:tensorflow:loss = 0.74609816, step = 10500 (3.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3861\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.2981374  -1.1394262  -1.3735263  ... -1.1879338   0.46517548\n",
      "   0.7896883 ]\n",
      " [-1.2981374  -1.1394262  -1.3735263  ... -1.1879338  -1.5964712\n",
      "   0.8413134 ]\n",
      " [-1.2981374  -1.1394262  -1.3735263  ... -1.1879338   0.41493255\n",
      "  -1.1919259 ]\n",
      " ...\n",
      " [-1.2981374  -1.1394262  -1.3735263  ... -1.1879338  -1.5964712\n",
      "   0.84370434]\n",
      " [-1.2981374  -1.1394262  -1.3735263  ... -1.1291234  -1.5964712\n",
      "   0.775067  ]\n",
      " [-1.2981374  -1.1394262  -1.3735263  ... -1.1879338  -1.5964712\n",
      "   0.8506881 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.21447866 0.24242572 0.20205073 ... 0.23362869 0.61424124 0.6877644 ]\n",
      " [0.21447866 0.24242572 0.20205073 ... 0.23362869 0.1684754  0.6987418 ]\n",
      " [0.21447866 0.24242572 0.20205073 ... 0.23362869 0.60227    0.23291467]\n",
      " ...\n",
      " [0.21447866 0.24242572 0.20205073 ... 0.23362869 0.1684754  0.6992448 ]\n",
      " [0.21447866 0.24242572 0.20205073 ... 0.24432291 0.1684754  0.68461597]\n",
      " [0.21447866 0.24242572 0.20205073 ... 0.23362869 0.1684754  0.7007115 ]] (3.651 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74864334, step = 10600 (3.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3889\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.274976   -1.1492844  -1.3487417  ... -1.1833842  -1.6635981\n",
      "   0.75881034]\n",
      " [-1.274976   -1.1492844  -1.3487417  ... -1.1833842  -1.6635981\n",
      "   0.7763603 ]\n",
      " [-1.274976   -1.1492844  -1.3487417  ... -1.1833842  -1.3930254\n",
      "   0.7525002 ]\n",
      " ...\n",
      " [-1.274976   -1.1492844   2.148442   ... -1.1833842  -1.6635981\n",
      "   0.7497587 ]\n",
      " [-1.274976   -1.1492844  -1.3487417  ... -1.1833842  -1.6635981\n",
      "   0.76888216]\n",
      " [-1.274976   -1.1492844  -1.3487417  ... -1.1833842   0.37279198\n",
      "   0.7483808 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.21840665 0.24061981 0.20607619 ... 0.23444426 0.15927958 0.6810954 ]\n",
      " [0.21840665 0.24061981 0.20607619 ... 0.23444426 0.15927958 0.68489516]\n",
      " [0.21840665 0.24061981 0.20607619 ... 0.23444426 0.1989252  0.67972326]\n",
      " ...\n",
      " [0.21840665 0.24061981 0.8955231  ... 0.23444426 0.15927958 0.67912614]\n",
      " [0.21840665 0.24061981 0.20607619 ... 0.23444426 0.15927958 0.68327904]\n",
      " [0.21840665 0.24061981 0.20607619 ... 0.23444426 0.59213346 0.6788258 ]] (3.651 sec)\n",
      "INFO:tensorflow:loss = 0.7449889, step = 10700 (3.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.345\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.3698561  -1.1591182  -1.3167458  ... -1.1777451  -1.6198744\n",
      "  -1.3100736 ]\n",
      " [-1.3698561  -1.1591182  -1.3167458  ... -1.1777451  -1.6198744\n",
      "  -1.3100736 ]\n",
      " [-1.3698561  -1.1591182  -1.3167458  ... -1.1777451  -1.6198744\n",
      "  -1.3100736 ]\n",
      " ...\n",
      " [-1.3698561  -1.1591182  -1.3167458  ... -1.1777451  -1.6198744\n",
      "   0.7610385 ]\n",
      " [-1.3698561  -1.1591182  -1.3167458  ... -1.1777451   0.42882144\n",
      "   0.755989  ]\n",
      " [-1.3698561  -1.1591182  -1.3167458  ... -1.1777451  -1.6198744\n",
      "   0.7610385 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.2026431  0.23882756 0.21136022 ... 0.23545785 0.1652222  0.21247452]\n",
      " [0.2026431  0.23882756 0.21136022 ... 0.23545785 0.1652222  0.21247452]\n",
      " [0.2026431  0.23882756 0.21136022 ... 0.23545785 0.1652222  0.21247452]\n",
      " ...\n",
      " [0.2026431  0.23882756 0.21136022 ... 0.23545785 0.1652222  0.6815792 ]\n",
      " [0.2026431  0.23882756 0.21136022 ... 0.23545785 0.60559225 0.68048227]\n",
      " [0.2026431  0.23882756 0.21136022 ... 0.23545785 0.1652222  0.6815792 ]] (3.659 sec)\n",
      "INFO:tensorflow:loss = 0.74318236, step = 10800 (3.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6557\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[ 2.8360991  14.647221   -1.3653471  ... -1.2628133  -1.6699233\n",
      "  -1.3671607 ]\n",
      " [-1.3016069  -1.125035   -1.3653471  ... -1.2628133  -1.6699233\n",
      "   0.72592795]\n",
      " [-1.3016069  -1.125035    2.1311843  ... -1.2628133   0.39197075\n",
      "   0.7345172 ]\n",
      " ...\n",
      " [ 2.911689   -1.125035   -1.3653471  ... -1.2628133  -1.6699233\n",
      "   0.6980812 ]\n",
      " [-1.3016069  -1.125035   -1.3653471  ... -1.2628133   0.33141404\n",
      "  -1.3671607 ]\n",
      " [-1.3016069  -1.125035   -1.3653471  ... -1.2628133  -1.6699233\n",
      "   0.7159253 ]], predicted_classes = [[1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.94459563 0.9999995  0.20337261 ... 0.22048998 0.1584344  0.20307899]\n",
      " [0.2138947  0.24507853 0.20337261 ... 0.22048998 0.1584344  0.6739111 ]\n",
      " [0.2138947  0.24507853 0.89389735 ... 0.22048998 0.596757   0.67579573]\n",
      " ...\n",
      " [0.9484213  0.24507853 0.20337261 ... 0.22048998 0.1584344  0.6677622 ]\n",
      " [0.2138947  0.24507853 0.20337261 ... 0.22048998 0.5821034  0.20307899]\n",
      " [0.2138947  0.24507853 0.20337261 ... 0.22048998 0.1584344  0.67170906]] (3.614 sec)\n",
      "INFO:tensorflow:loss = 0.7426452, step = 10900 (3.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5659\n",
      "INFO:tensorflow:acc = 0.9998438, acc_row = 0.99609375, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.3748955  -1.1469682  -1.4034392  ... -1.2726147   0.34478742\n",
      "  -1.1278669 ]\n",
      " [-1.3748955  -1.1469682  -1.4034392  ... -1.2726147  -1.6751528\n",
      "  -1.1278669 ]\n",
      " [-1.3748955  -1.1469682  -1.4034392  ... -1.2726147   0.36521846\n",
      "   0.8749196 ]\n",
      " ...\n",
      " [-1.3748955  -1.1469682  -1.4034392  ... -1.2726147  -1.6751528\n",
      "  -1.1278669 ]\n",
      " [-1.3748955  -1.1469682  -1.4034392  ... -1.2726147  -1.6751528\n",
      "   0.95057786]\n",
      " [-1.3748955  -1.1469682  -1.4034392  ... -1.2726147  -1.6751528\n",
      "   0.8743431 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.20183006 0.24104328 0.19727093 ... 0.21880999 0.58535296 0.244555  ]\n",
      " [0.20183006 0.24104328 0.19727093 ... 0.21880999 0.15773839 0.244555  ]\n",
      " [0.20183006 0.24104328 0.19727093 ... 0.21880999 0.5903031  0.70576835]\n",
      " ...\n",
      " [0.20183006 0.24104328 0.19727093 ... 0.21880999 0.15773839 0.244555  ]\n",
      " [0.20183006 0.24104328 0.19727093 ... 0.21880999 0.15773839 0.7212314 ]\n",
      " [0.20183006 0.24104328 0.19727093 ... 0.21880999 0.15773839 0.7056486 ]] (3.628 sec)\n",
      "INFO:tensorflow:loss = 0.74196076, step = 11000 (3.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7633\n",
      "INFO:tensorflow:acc = 0.9998438, acc_row = 0.99609375, labels = [[1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[ 1.8034936  -1.1911085  -1.3766118  ... -1.2707617   0.4007199\n",
      "  -1.2607783 ]\n",
      " [-1.411892   -1.1911085  -1.3766118  ... -1.2707617  -1.6938717\n",
      "   0.7802191 ]\n",
      " [-1.411892   -1.1911085  -1.3766118  ... -1.2707617  -1.6938717\n",
      "   0.7743021 ]\n",
      " ...\n",
      " [-1.411892   -1.1911085  -1.3766118  ... -1.2707617   0.34560406\n",
      "   0.7721614 ]\n",
      " [-1.411892   -1.1911085  -1.3766118  ... -1.2707617  -1.6938717\n",
      "   0.7727441 ]\n",
      " [-1.411892   -1.1911085  -1.3766118  ... -1.2707617  -1.6938717\n",
      "   0.89832956]], predicted_classes = [[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.8585737  0.23306076 0.2015537  ... 0.21912688 0.59886056 0.22083995]\n",
      " [0.1959358  0.23306076 0.2015537  ... 0.21912688 0.15526734 0.6857273 ]\n",
      " [0.1959358  0.23306076 0.2015537  ... 0.21912688 0.15526734 0.6844508 ]\n",
      " ...\n",
      " [0.1959358  0.23306076 0.2015537  ... 0.21912688 0.5855512  0.6839883 ]\n",
      " [0.1959358  0.23306076 0.2015537  ... 0.21912688 0.15526734 0.6841142 ]\n",
      " [0.1959358  0.23306076 0.2015537  ... 0.21912688 0.15526734 0.7106061 ]] (3.603 sec)\n",
      "INFO:tensorflow:loss = 0.74064875, step = 11100 (3.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6343\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.4077798  -1.1986492  -1.353893   ... -1.2572085   0.24216884\n",
      "  -1.2690394 ]\n",
      " [-1.4077798  -1.1986492  -1.353893   ... -1.2572085   0.26589474\n",
      "   0.7691219 ]\n",
      " [-1.4077798  -1.1986492   2.5849435  ... -1.2572085  -1.7321281\n",
      "   0.7685745 ]\n",
      " ...\n",
      " [-1.4077798  -1.1986492  -1.353893   ... -1.2572085  -1.7321281\n",
      "  -1.2690394 ]\n",
      " [-1.4077798  -1.1986492  -1.353893   ... -1.2572085  -1.7321281\n",
      "  -1.2690394 ]\n",
      " [-1.4077798  -1.1986492  -1.353893   ... -1.2572085  -1.7321281\n",
      "   0.786697  ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.19658448 0.23171562 0.20523465 ... 0.22145481 0.5602481  0.21942174]\n",
      " [0.19658448 0.23171562 0.20523465 ... 0.22145481 0.5660848  0.68333095]\n",
      " [0.19658448 0.23171562 0.9298862  ... 0.22145481 0.15031557 0.68321246]\n",
      " ...\n",
      " [0.19658448 0.23171562 0.20523465 ... 0.22145481 0.15031557 0.21942174]\n",
      " [0.19658448 0.23171562 0.20523465 ... 0.22145481 0.15031557 0.21942174]\n",
      " [0.19658448 0.23171562 0.20523465 ... 0.22145481 0.15031557 0.6871217 ]] (3.618 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74223787, step = 11200 (3.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2425\n",
      "INFO:tensorflow:acc = 0.99953127, acc_row = 0.98828125, labels = [[0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.4385403  -1.2202876   1.7357161  ... -1.2546858  -1.7492261\n",
      "   0.8078143 ]\n",
      " [-1.4385403  -1.2202876  -1.4023019  ... -1.2546858  -1.7492261\n",
      "   0.8492143 ]\n",
      " [-1.4385403  -1.2202876  -1.4023019  ... -1.2546858  -1.7492261\n",
      "   0.81752497]\n",
      " ...\n",
      " [-1.4385403  -1.2202876  -1.4023019  ... -1.2546858  -1.7492261\n",
      "   0.80528694]\n",
      " [-1.4385403  -1.2202876  -1.4023019  ... -1.2546858  -1.7492261\n",
      "   0.85487205]\n",
      " [-1.4385403  -1.2202876  -1.4023019  ... -1.2546858   0.2128869\n",
      "   0.8174926 ]], predicted_classes = [[0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.19177149 0.22788584 0.8501421  ... 0.22189006 0.14814483 0.69164354]\n",
      " [0.19177149 0.22788584 0.1974511  ... 0.22189006 0.14814483 0.7004023 ]\n",
      " [0.19177149 0.22788584 0.1974511  ... 0.22189006 0.14814483 0.6937107 ]\n",
      " ...\n",
      " [0.19177149 0.22788584 0.1974511  ... 0.22189006 0.14814483 0.6911043 ]\n",
      " [0.19177149 0.22788584 0.1974511  ... 0.22189006 0.14814483 0.7015882 ]\n",
      " [0.19177149 0.22788584 0.1974511  ... 0.22189006 0.5530216  0.69370383]] (3.670 sec)\n",
      "INFO:tensorflow:loss = 0.73827624, step = 11300 (3.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3192\n",
      "INFO:tensorflow:acc = 0.9998438, acc_row = 0.99609375, labels = [[1 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 1]], logits = [[ 1.6272435  -1.2169887  -1.3811928  ... -1.2758934  -1.7189486\n",
      "   0.8508777 ]\n",
      " [-1.4469098  -1.2169887  -1.3811928  ... -1.2758934   0.28544685\n",
      "  -1.2096752 ]\n",
      " [-1.4469098  -1.2169887  -1.3811928  ... -1.2758934   0.3079152\n",
      "  -1.2096752 ]\n",
      " ...\n",
      " [-1.4469098  -1.2169887   2.4653077  ... -1.2758934   0.35276023\n",
      "   0.8507477 ]\n",
      " [-1.4469098  -1.2169887  -1.3811928  ... -1.2758934  -1.7189486\n",
      "   0.82460797]\n",
      " [ 1.5657763  -1.2169887  -1.3811928  ... -1.2758934  -1.7189486\n",
      "   0.8425424 ]], predicted_classes = [[1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]], prob = [[0.8357917  0.22846682 0.2008175  ... 0.21825007 0.15200664 0.7007512 ]\n",
      " [0.1904776  0.22846682 0.2008175  ... 0.21825007 0.5708811  0.2297585 ]\n",
      " [0.1904776  0.22846682 0.2008175  ... 0.21825007 0.57637626 0.2297585 ]\n",
      " ...\n",
      " [0.1904776  0.22846682 0.9216737  ... 0.21825007 0.5872868  0.700724  ]\n",
      " [0.1904776  0.22846682 0.2008175  ... 0.21825007 0.15200664 0.6952136 ]\n",
      " [0.8271807  0.22846682 0.2008175  ... 0.21825007 0.15200664 0.6990004 ]] (3.661 sec)\n",
      "INFO:tensorflow:loss = 0.7393006, step = 11400 (3.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7046\n",
      "INFO:tensorflow:acc = 0.9998438, acc_row = 0.99609375, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-1.476742   -1.2529205  -1.4362111  ... -1.2974094  -1.7093601\n",
      "   1.0224894 ]\n",
      " [-1.476742   -1.2529205  -1.4362111  ... -1.2974094  -1.7093601\n",
      "   1.0328581 ]\n",
      " [-1.476742   -1.2529205  -1.4362111  ... -1.2974094  -1.7093601\n",
      "  -1.0362728 ]\n",
      " ...\n",
      " [-1.476742   -1.2529205  -1.4362111  ... -1.2974094  -1.7093601\n",
      "   1.0185715 ]\n",
      " [-1.476742   -1.2529205  -1.4362111  ... -1.2974094  -1.7093601\n",
      "  -1.0362728 ]\n",
      " [-1.476742   -1.2529205  -1.4362111  ... -1.2974094   0.27721545\n",
      "  -1.0362728 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.18592001 0.222195   0.19213277 ... 0.21460132 0.15324673 0.7354572 ]\n",
      " [0.18592001 0.222195   0.19213277 ... 0.21460132 0.15324673 0.7374696 ]\n",
      " [0.18592001 0.222195   0.19213277 ... 0.21460132 0.15324673 0.26186982]\n",
      " ...\n",
      " [0.18592001 0.222195   0.19213277 ... 0.21460132 0.15324673 0.73469424]\n",
      " [0.18592001 0.222195   0.19213277 ... 0.21460132 0.15324673 0.26186982]\n",
      " [0.18592001 0.222195   0.19213277 ... 0.21460132 0.56886345 0.26186982]] (3.610 sec)\n",
      "INFO:tensorflow:loss = 0.741567, step = 11500 (3.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2701\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 1 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.399099   -1.2160218   1.7153057  ... -1.2819955  -1.6908158\n",
      "   0.9194749 ]\n",
      " [-1.399099   -1.2160218  -1.4604423  ... -1.2819955   0.42504898\n",
      "  -1.1267303 ]\n",
      " [-1.399099   -1.2160218  -1.4604423  ... -1.2819955   0.3414775\n",
      "   0.838322  ]\n",
      " ...\n",
      " [-1.399099   -1.2160218  -1.4604423  ... -1.2819955   0.32066092\n",
      "   0.907508  ]\n",
      " [-1.399099   -1.2160218  -1.4604423  ... -1.2819955   0.34463522\n",
      "   0.8719983 ]\n",
      " [-1.399099   -1.2160218  -1.4604423  ... -1.2819955   0.34775224\n",
      "   0.8965972 ]], predicted_classes = [[0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.19795913 0.22863732 0.84752315 ... 0.21721072 0.15566859 0.7149351 ]\n",
      " [0.19795913 0.22863732 0.18839967 ... 0.21721072 0.6046908  0.24476501]\n",
      " [0.19795913 0.22863732 0.18839967 ... 0.21721072 0.5845494  0.6981117 ]\n",
      " ...\n",
      " [0.19795913 0.22863732 0.18839967 ... 0.21721072 0.5794853  0.71248996]\n",
      " [0.19795913 0.22863732 0.18839967 ... 0.21721072 0.58531606 0.70516133]\n",
      " [0.19795913 0.22863732 0.18839967 ... 0.21721072 0.5860724  0.7102498 ]] (3.667 sec)\n",
      "INFO:tensorflow:loss = 0.7363748, step = 11600 (3.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7031\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.4817566 -1.1990105  2.0645955 ... -1.2453761 -1.7021425 -1.1069865]\n",
      " [-1.4817566 -1.1990105 -1.4170122 ... -1.2453761  0.3543952  0.9186824]\n",
      " [-1.4817566 -1.1990105 -1.4170122 ... -1.2453761 -1.7021425  0.9587777]\n",
      " ...\n",
      " [-1.4817566 -1.1990105 -1.4170122 ...  7.814197  -1.6738669 -1.1114799]\n",
      " [-1.4817566 -1.1990105 -1.4170122 ... -1.2453761 -1.7021425 -1.1114799]\n",
      " [-1.4817566 -1.1990105 -1.4170122 ... -1.2453761 -1.7021425 -1.1114799]], predicted_classes = [[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.18516225 0.23165128 0.88741416 ... 0.22350158 0.15418565 0.24843313]\n",
      " [0.18516225 0.23165128 0.1951304  ... 0.22350158 0.587683   0.71477354]\n",
      " [0.18516225 0.23165128 0.1951304  ... 0.22350158 0.15418565 0.72287697]\n",
      " ...\n",
      " [0.18516225 0.23165128 0.1951304  ... 0.9995962  0.1579093  0.2475951 ]\n",
      " [0.18516225 0.23165128 0.1951304  ... 0.22350158 0.15418565 0.2475951 ]\n",
      " [0.18516225 0.23165128 0.1951304  ... 0.22350158 0.15418565 0.2475951 ]] (3.609 sec)\n",
      "INFO:tensorflow:loss = 0.7380628, step = 11700 (3.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3787\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 0]], logits = [[-1.4408643  -1.2873833   1.798102   ... -1.2719085   0.30587754\n",
      "   0.78328127]\n",
      " [-1.4408643  -1.2873833  -1.4790484  ... -1.2719085  -1.7265887\n",
      "   0.7845007 ]\n",
      " [-1.4408643  -1.2873833  -1.4790484  ... -1.2719085  -1.7265887\n",
      "   0.7802692 ]\n",
      " ...\n",
      " [-1.4408643  -1.2873833  -1.4790484  ... -1.2719085  -1.7265887\n",
      "   0.7888405 ]\n",
      " [-1.4408643  -1.2873833  -1.4790484  ... -1.2719085   0.2576808\n",
      "   0.82583815]\n",
      " [-1.4408643  -1.2873833  -1.4790484  ... -1.2719085   0.2802196\n",
      "  -1.2599255 ]], predicted_classes = [[0. 0. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], prob = [[0.19141154 0.21629605 0.8579177  ... 0.21893072 0.5758787  0.6863869 ]\n",
      " [0.19141154 0.21629605 0.18557121 ... 0.21893072 0.15102445 0.6866493 ]\n",
      " [0.19141154 0.21629605 0.18557121 ... 0.21893072 0.15102445 0.68573815]\n",
      " ...\n",
      " [0.19141154 0.21629605 0.18557121 ... 0.21893072 0.15102445 0.6875823 ]\n",
      " [0.19141154 0.21629605 0.18557121 ... 0.21893072 0.56406605 0.6954742 ]\n",
      " [0.19141154 0.21629605 0.18557121 ... 0.21893072 0.56960005 0.22098671]] (3.652 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.73825455, step = 11800 (3.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3163\n",
      "INFO:tensorflow:acc = 0.9996875, acc_row = 0.9921875, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], logits = [[-1.5404031  -1.2658178  -1.466759   ... -1.3111304  -1.6748245\n",
      "   0.8043805 ]\n",
      " [-1.5404031  -1.2658178  -1.466759   ... -1.3111304  -1.6748245\n",
      "   0.7794773 ]\n",
      " [-1.5404031  -1.2658178  -1.466759   ... -1.3111304  -1.6748245\n",
      "  -1.2686273 ]\n",
      " ...\n",
      " [-1.5404031  -1.2658178  -1.466759   ... -1.3111304   0.40020952\n",
      "   0.77353346]\n",
      " [ 1.3390831  -1.2658178  -1.466759   ... -1.3111304  -1.6748245\n",
      "  -1.2686273 ]\n",
      " [-1.5404031  -1.2658178  -1.466759   ... -1.3111304  -1.6748245\n",
      "  -1.2686273 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], prob = [[0.17647669 0.21997404 0.18743573 ... 0.21229775 0.157782   0.6909107 ]\n",
      " [0.17647669 0.21997404 0.18743573 ... 0.21229775 0.157782   0.68556744]\n",
      " [0.17647669 0.21997404 0.18743573 ... 0.21229775 0.157782   0.21949232]\n",
      " ...\n",
      " [0.17647669 0.21997404 0.18743573 ... 0.21229775 0.598738   0.68428475]\n",
      " [0.7923391  0.21997404 0.18743573 ... 0.21229775 0.157782   0.21949232]\n",
      " [0.17647669 0.21997404 0.18743573 ... 0.21229775 0.157782   0.21949232]] (3.661 sec)\n",
      "INFO:tensorflow:loss = 0.7359264, step = 11900 (3.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5969\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 0]], logits = [[-1.4033623  -1.2914689  -1.4451032  ... -1.3196087  -1.698467\n",
      "   0.774577  ]\n",
      " [-1.4033623  -1.2914689  -1.4451032  ... -1.3196087  -1.698467\n",
      "   0.7788414 ]\n",
      " [-1.4033623  -1.2914689  -1.4451032  ... -1.3196087  -1.698467\n",
      "  -1.2482622 ]\n",
      " ...\n",
      " [-1.4033623  -1.2914689  -1.4451032  ... -1.3196087  -1.698467\n",
      "   0.8030927 ]\n",
      " [-1.4033623  -1.2914689  -1.4451032  ... -1.3196087   0.32932374\n",
      "   0.7993092 ]\n",
      " [-1.4033623  -1.2914689   2.4649444  ... -1.3196087  -1.698467\n",
      "  -1.2482622 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]], prob = [[0.1972831  0.2156043  0.19075634 ... 0.21088341 0.15466559 0.6845102 ]\n",
      " [0.1972831  0.2156043  0.19075634 ... 0.21088341 0.15466559 0.68543035]\n",
      " [0.1972831  0.2156043  0.19075634 ... 0.21088341 0.15466559 0.22300112]\n",
      " ...\n",
      " [0.1972831  0.2156043  0.19075634 ... 0.21088341 0.15466559 0.6906357 ]\n",
      " [0.1972831  0.2156043  0.19075634 ... 0.21088341 0.58159477 0.6898267 ]\n",
      " [0.1972831  0.2156043  0.9216474  ... 0.21088341 0.15466559 0.22300112]] (3.623 sec)\n",
      "INFO:tensorflow:loss = 0.7373905, step = 12000 (3.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9729\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 1]], logits = [[-1.5391393  -1.2635365  -1.4627532  ... -1.2829769   0.377815\n",
      "  -1.1094631 ]\n",
      " [-1.5391393  -1.2635365  -1.4627532  ... -1.2829769   0.38937494\n",
      "   0.88828635]\n",
      " [-1.5391393  -1.2635365  -1.4627532  ... -1.2829769  -1.6829698\n",
      "  -1.1094631 ]\n",
      " ...\n",
      " [-1.5391393  -1.2635365  -1.4627532  ...  7.6524496  -1.6829698\n",
      "  -1.1094631 ]\n",
      " [-1.5391393  -1.2635365  -1.4627532  ... -1.2829769   0.3126591\n",
      "   0.883873  ]\n",
      " [-1.5391393  -1.2635365  -1.4627532  ... -1.2829769  -1.6829698\n",
      "   0.9086684 ]], predicted_classes = [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]], prob = [[0.17666043 0.22036572 0.18804659 ... 0.21704392 0.593346   0.247971  ]\n",
      " [0.17666043 0.22036572 0.18804659 ... 0.21704392 0.5961322  0.70853645]\n",
      " [0.17666043 0.22036572 0.18804659 ... 0.21704392 0.15670261 0.247971  ]\n",
      " ...\n",
      " [0.17666043 0.22036572 0.18804659 ... 0.9995253  0.15670261 0.247971  ]\n",
      " [0.17666043 0.22036572 0.18804659 ... 0.21704392 0.5775342  0.70762414]\n",
      " [0.17666043 0.22036572 0.18804659 ... 0.21704392 0.15670261 0.7127276 ]] (3.575 sec)\n",
      "INFO:tensorflow:loss = 0.73455155, step = 12100 (3.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5807\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.4855605  -1.3104324  -1.5019991  ... -1.338418   -1.7106481\n",
      "  -1.1356064 ]\n",
      " [-1.4855605  -1.3104324  -1.5019991  ... -1.338418   -1.7106481\n",
      "   0.86527   ]\n",
      " [-1.4855605  -1.3104324   1.7916512  ... -1.338418   -1.7106481\n",
      "   0.87515205]\n",
      " ...\n",
      " [-1.4855605  -1.3104324  -1.5019991  ... -1.338418   -1.7106481\n",
      "  -1.1356064 ]\n",
      " [-1.4855605  -1.3104324  -1.5019991  ... -1.338418   -1.7106481\n",
      "  -1.1356064 ]\n",
      " [-1.4855605  -1.3104324  -1.5019991  ... -1.338418    0.29904768\n",
      "   0.91883594]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.184589   0.21241447 0.18212755 ... 0.20777035 0.15307969 0.24312793]\n",
      " [0.184589   0.21241447 0.18212755 ... 0.20777035 0.15307969 0.7037605 ]\n",
      " [0.184589   0.21241447 0.8571296  ... 0.20777035 0.15307969 0.7058166 ]\n",
      " ...\n",
      " [0.184589   0.21241447 0.18212755 ... 0.20777035 0.15307969 0.24312793]\n",
      " [0.184589   0.21241447 0.18212755 ... 0.20777035 0.15307969 0.24312793]\n",
      " [0.184589   0.21241447 0.18212755 ... 0.20777035 0.57420975 0.7148048 ]] (3.626 sec)\n",
      "INFO:tensorflow:loss = 0.7365554, step = 12200 (3.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6238\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]], logits = [[-1.571013   -1.3350508  -1.4660456  ... -1.3197118  -1.6943362\n",
      "   0.89241624]\n",
      " [ 1.283464   -1.3350508  -1.4660456  ... -1.3197118  -1.6943362\n",
      "  -1.1286002 ]\n",
      " [ 1.3497645  -1.3350508  -1.4660456  ... -1.3197118  -1.6943362\n",
      "  -1.1286002 ]\n",
      " ...\n",
      " [-1.571013   -1.3350508  -1.4660456  ... -1.3197118  -1.6943362\n",
      "   0.8991334 ]\n",
      " [-1.571013   -1.3350508  -1.4660456  ... -1.3197118   0.32950175\n",
      "  -1.1286002 ]\n",
      " [-1.571013   -1.3350508   2.364037   ... -1.3197118  -1.6943362\n",
      "  -1.1286002 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]], prob = [[0.17207204 0.20832513 0.1875444  ... 0.21086623 0.15520644 0.7093886 ]\n",
      " [0.7830388  0.20832513 0.1875444  ... 0.21086623 0.15520644 0.24441952]\n",
      " [0.7940911  0.20832513 0.1875444  ... 0.21086623 0.15520644 0.24441952]\n",
      " ...\n",
      " [0.17207204 0.20832513 0.1875444  ... 0.21086623 0.15520644 0.7107714 ]\n",
      " [0.17207204 0.20832513 0.1875444  ... 0.21086623 0.58163816 0.24441952]\n",
      " [0.17207204 0.20832513 0.91404355 ... 0.21086623 0.15520644 0.24441952]] (3.620 sec)\n",
      "INFO:tensorflow:loss = 0.73507684, step = 12300 (3.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8481\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]], logits = [[-1.4819645  -1.2650193  -1.5060892  ... -1.38248    -1.738463\n",
      "  -1.2445444 ]\n",
      " [-1.4819645  -1.2650193  -1.5060892  ... -1.38248     0.27332717\n",
      "  -1.2445444 ]\n",
      " [-1.4819645  -1.2650193  -1.5060892  ... -1.38248    -1.7284459\n",
      "  -1.2085114 ]\n",
      " ...\n",
      " [ 2.2005038  -1.2650193  -1.5060892  ... -1.38248    -1.738463\n",
      "  -1.2445444 ]\n",
      " [-1.4819645  -1.2650193  -1.5060892  ... -1.38248    -1.738463\n",
      "  -1.2445444 ]\n",
      " [-1.4819645  -1.2650193   1.9566061  ... -1.38248    -1.5484372\n",
      "  -1.2445444 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]], prob = [[0.18513088 0.22011107 0.18151909 ... 0.200611   0.14950825 0.22364596]\n",
      " [0.18513088 0.22011107 0.18151909 ... 0.200611   0.56790954 0.22364596]\n",
      " [0.18513088 0.22011107 0.18151909 ... 0.200611   0.15078647 0.22996454]\n",
      " ...\n",
      " [0.9002948  0.22011107 0.18151909 ... 0.200611   0.14950825 0.22364596]\n",
      " [0.18513088 0.22011107 0.18151909 ... 0.200611   0.14950825 0.22364596]\n",
      " [0.18513088 0.22011107 0.8761652  ... 0.200611   0.1753121  0.22364596]] (3.591 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7345221, step = 12400 (3.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3607\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.5131693  -1.2751153  -1.5145876  ... -1.3528631  -1.7532978\n",
      "   0.75099474]\n",
      " [-1.5131693  -1.2751153  -1.5145876  ... -1.3528631   0.2998929\n",
      "   0.7559771 ]\n",
      " [-1.5131693  -1.2751153  -1.5145876  ... -1.3528631  -1.7532978\n",
      "  -1.3107774 ]\n",
      " ...\n",
      " [ 1.9797212  -1.2751153  -1.5145876  ... -1.3528631   0.22561061\n",
      "  -1.3107774 ]\n",
      " [-1.5131693  -1.2751153  -1.5145876  ... -1.3528631  -1.7532978\n",
      "  -1.3107774 ]\n",
      " [-1.5131693  -1.2751153  -1.5145876  ... -1.3528631   0.21018738\n",
      "   0.7281045 ]], predicted_classes = [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.18046959 0.21838287 0.1802599  ... 0.20540269 0.14763173 0.67939544]\n",
      " [0.18046959 0.21838287 0.1802599  ... 0.20540269 0.5744163  0.6804797 ]\n",
      " [0.18046959 0.21838287 0.1802599  ... 0.20540269 0.14763173 0.21235679]\n",
      " ...\n",
      " [0.8786514  0.21838287 0.1802599  ... 0.20540269 0.5561646  0.21235679]\n",
      " [0.18046959 0.21838287 0.1802599  ... 0.20540269 0.14763173 0.21235679]\n",
      " [0.18046959 0.21838287 0.1802599  ... 0.20540269 0.5523542  0.6743892 ]] (3.654 sec)\n",
      "INFO:tensorflow:loss = 0.73444575, step = 12500 (3.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8181\n",
      "INFO:tensorflow:acc = 1.0, acc_row = 1.0, labels = [[0 0 1 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]], logits = [[-1.4760845  -1.3310549   2.179735   ... -1.3887293   0.29490477\n",
      "  -1.2585951 ]\n",
      " [-1.4760845  -1.3310549  -1.516537   ... -1.3887293  -1.6900802\n",
      "   0.7876    ]\n",
      " [-1.4760845  -1.3310549  -1.516537   ... -1.3887293  -1.6788062\n",
      "   0.801909  ]\n",
      " ...\n",
      " [-1.4760845  -1.3310549  -1.516537   ... -1.3887293   0.37077025\n",
      "   0.782253  ]\n",
      " [-1.4760845  -1.3310549  -1.516537   ... -1.3887293   0.37077025\n",
      "   0.782253  ]\n",
      " [-1.4760845  -1.3310549  -1.516537   ... -1.3887293   0.34754115\n",
      "   0.7778171 ]], predicted_classes = [[0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], prob = [[0.18601957 0.20898493 0.8984149  ... 0.19961068 0.5731965  0.22121583]\n",
      " [0.18601957 0.20898493 0.17997204 ... 0.19961068 0.1557653  0.68731576]\n",
      " [0.18601957 0.20898493 0.17997204 ... 0.19961068 0.15725362 0.69038266]\n",
      " ...\n",
      " [0.18601957 0.20898493 0.17997204 ... 0.19961068 0.5916451  0.6861655 ]\n",
      " [0.18601957 0.20898493 0.17997204 ... 0.19961068 0.5916451  0.6861655 ]\n",
      " [0.18601957 0.20898493 0.17997204 ... 0.19961068 0.5860212  0.68520945]] (3.595 sec)\n",
      "INFO:tensorflow:loss = 0.7346778, step = 12600 (3.596 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12663 into /tmp/tmpp_7nmm1l/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.72925067.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "testbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "ppp\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "testbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "777\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss\n",
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n",
      "eee!\n",
      "Tensor(\"fifo_queue_DequeueUpTo:2\", shape=(?, 25), dtype=int64, device=/device:CPU:0)\n",
      "Tensor(\"predicted_classes:0\", shape=(?, 25), dtype=float32)\n",
      "eee?\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-27-01:58:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-27-01:59:00\n",
      "INFO:tensorflow:Saving dict for global step 12663: accuracy = 0.9998717, global_step = 12663, loss = 0.75148875\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12663: /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "Accuracy (tensorflow): 0.999872\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--test_with_fake_data',\n",
    "        default = False,\n",
    "        help = 'Test the example code with fake data',\n",
    "        action = 'store_true')\n",
    "    parser.add_argument(\n",
    "        '--bow model',\n",
    "        default = False,\n",
    "        help = 'Run with BOW model instead of RNN',\n",
    "        action = 'store_true')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run(main=main, argv = [sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "testbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "ppp\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[-1.2069418  -1.2286294  -1.2161264  ... -1.2273476   1.3720585\n",
      "   3.2946615 ]\n",
      " [ 1.7686007  -1.2286294  -1.2161264  ... -1.2273476  -0.86196303\n",
      "   3.266552  ]\n",
      " [-1.2069418  -1.2286294  -1.2161264  ... -1.2273476   1.3704385\n",
      "  -0.01974662]\n",
      " ...\n",
      " [-1.2069418  -1.2286294  -1.2161264  ... -1.2273476  -0.8910116\n",
      "  -0.01974662]\n",
      " [-1.2069418  -1.2286294  -1.2161264  ... -1.2273476   1.3385092\n",
      "   3.3211372 ]\n",
      " [-1.2069418  -1.2286294  -1.2161264  ... -1.2273476   1.383912\n",
      "   3.3858972 ]]\n",
      "(202599, 25)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "testbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "ppp\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[0.23024262 0.22642142 0.22861885 ... 0.22664599 0.79771256 0.96424514]\n",
      " [0.85428363 0.22642142 0.22861885 ... 0.22664599 0.2969294  0.9632634 ]\n",
      " [0.23024262 0.22642142 0.22861885 ... 0.22664599 0.797451   0.49506354]\n",
      " ...\n",
      " [0.23024262 0.22642142 0.22861885 ... 0.22664599 0.29090112 0.49506354]\n",
      " [0.23024262 0.22642142 0.22861885 ... 0.22664599 0.7922447  0.9651469 ]\n",
      " [0.23024262 0.22642142 0.22861885 ... 0.22664599 0.79961854 0.9672609 ]]\n",
      "(202599, 25)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "testbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "ppp\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[0. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]]\n",
      "(202599, 25)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "@@@\n",
      "###\n",
      "###\n",
      "Tensor(\"concat_60:0\", shape=(?, 150), dtype=float32)\n",
      "###\n",
      "testbatch\n",
      "666\n",
      "Tensor(\"logits:0\", shape=(?, 25), dtype=float32)\n",
      "777\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss\n",
      "Tensor(\"sigmoid_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n",
      "eee!\n",
      "Tensor(\"fifo_queue_DequeueUpTo:2\", shape=(?, 25), dtype=int64, device=/device:CPU:0)\n",
      "Tensor(\"predicted_classes:0\", shape=(?, 25), dtype=float32)\n",
      "eee?\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-27-03:16:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-27-03:17:05\n",
      "INFO:tensorflow:Saving dict for global step 12663: accuracy = 0.9998792, global_step = 12663, loss = 0.75148857\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12663: /tmp/tmpp_7nmm1l/model.ckpt-12663\n",
      "Accuracy (tensorflow): 0.999879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_transform_result = vocab_processor.transform(x)\n",
    "x_result = np.array(list(x_transform_result))\n",
    "y_result = np.array(y)\n",
    "    \n",
    "\n",
    "    # Predict\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {WORDS_FEATURE : x_result},\n",
    "    y = y_result,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "predictions = classifier.predict(input_fn = test_input_fn)\n",
    "y_logits = np.array(list(p['logits'] for p in predictions))\n",
    "print(y_logits)\n",
    "print(y_logits.shape)\n",
    "\n",
    "predictions = classifier.predict(input_fn = test_input_fn)\n",
    "y_prob = np.array(list(p['prob'] for p in predictions))\n",
    "print(y_prob)\n",
    "print(y_prob.shape)\n",
    "\n",
    "predictions = classifier.predict(input_fn = test_input_fn)\n",
    "y_predicted_classes = np.array(list(p['predicted_classes'] for p in predictions))\n",
    "print(y_predicted_classes)\n",
    "print(y_predicted_classes.shape)\n",
    "    \n",
    "# Score using tensorflow\n",
    "score = classifier.evaluate(input_fn = test_input_fn)\n",
    "print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.847598</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818762</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797713</td>\n",
       "      <td>0.964245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854284</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.296929</td>\n",
       "      <td>0.963263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893830</td>\n",
       "      <td>0.857029</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797451</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848516</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.828885</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.962808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792245</td>\n",
       "      <td>0.965147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.880379</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.844832</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.789205</td>\n",
       "      <td>0.964984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.843310</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.876754</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.838772</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.853705</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.851993</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.231799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.827412</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.796232</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.793946</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.794794</td>\n",
       "      <td>0.964835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797354</td>\n",
       "      <td>0.963577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848233</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.851965</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.880994</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.852404</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818295</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890676</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.854084</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.841212</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.795435</td>\n",
       "      <td>0.965144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.877505</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875282</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.821901</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849638</td>\n",
       "      <td>0.843485</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.238068</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.847361</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.875345</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.841702</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.883911</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849182</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.799684</td>\n",
       "      <td>0.964311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.878591</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873638</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.819269</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848564</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797825</td>\n",
       "      <td>0.966432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792789</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848584</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790335</td>\n",
       "      <td>0.964672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.855844</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.865686</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848988</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.823475</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>0.965273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.854084</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202569</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.868697</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.919503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.846318</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.787956</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202570</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.873830</td>\n",
       "      <td>0.886399</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.330819</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.864441</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.762974</td>\n",
       "      <td>0.966189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202571</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.845949</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.830474</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202572</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904575</td>\n",
       "      <td>0.854878</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.825827</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.819722</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.962915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202573</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848584</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790335</td>\n",
       "      <td>0.964672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202574</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849005</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202575</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.793271</td>\n",
       "      <td>0.964494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202576</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848959</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202577</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.868594</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.844060</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.793806</td>\n",
       "      <td>0.965360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202578</th>\n",
       "      <td>0.859691</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.850327</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.806960</td>\n",
       "      <td>0.964611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202579</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.794916</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.870359</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.842945</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.788476</td>\n",
       "      <td>0.964522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202580</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.247887</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.901441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.814552</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.859558</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202581</th>\n",
       "      <td>0.855618</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887981</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.810389</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202582</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.838017</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790484</td>\n",
       "      <td>0.965396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202583</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.874206</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202584</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792789</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202585</th>\n",
       "      <td>0.857652</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848269</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202586</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848493</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.819524</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202587</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.857552</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.842099</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202588</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.840531</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.789156</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202589</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.895807</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202590</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.852762</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849177</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797561</td>\n",
       "      <td>0.965888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202591</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.882705</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.846669</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.823509</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790358</td>\n",
       "      <td>0.965263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202592</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.800968</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.828619</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818340</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202593</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.830843</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202594</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.879823</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.815174</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.799841</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.847356</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.874454</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792245</td>\n",
       "      <td>0.965147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598</th>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.875538</td>\n",
       "      <td>0.830110</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.799619</td>\n",
       "      <td>0.967261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "1       0.854284  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "2       0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "3       0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "4       0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "5       0.230243  0.226421  0.228619  0.230902  0.229227  0.880379  0.228527   \n",
       "6       0.843310  0.226421  0.228619  0.856332  0.229227  0.230029  0.876754   \n",
       "7       0.853705  0.226421  0.228619  0.851993  0.229227  0.230029  0.228527   \n",
       "8       0.230243  0.226421  0.793946  0.230902  0.229227  0.230029  0.228527   \n",
       "9       0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "10      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "11      0.230243  0.226421  0.228619  0.851965  0.229227  0.230029  0.880994   \n",
       "12      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "13      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "14      0.853583  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "15      0.854084  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "16      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "17      0.230243  0.226421  0.228619  0.230902  0.877505  0.230029  0.228527   \n",
       "18      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "19      0.230243  0.226421  0.238068  0.230902  0.229227  0.230029  0.228527   \n",
       "20      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "21      0.230243  0.226421  0.228619  0.230902  0.883911  0.230029  0.228527   \n",
       "22      0.230243  0.226421  0.228619  0.230902  0.229227  0.878591  0.228527   \n",
       "23      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "24      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "25      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "26      0.230243  0.226421  0.228619  0.855844  0.229227  0.230029  0.228527   \n",
       "27      0.230243  0.226421  0.228619  0.230902  0.229227  0.865686  0.228527   \n",
       "28      0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "29      0.854084  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "202569  0.230243  0.226421  0.228619  0.868697  0.229227  0.230029  0.228527   \n",
       "202570  0.230243  0.226421  0.228619  0.230902  0.229227  0.873830  0.886399   \n",
       "202571  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202572  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202573  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202574  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202575  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202576  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202577  0.230243  0.226421  0.228619  0.230902  0.229227  0.868594  0.228527   \n",
       "202578  0.859691  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202579  0.230243  0.226421  0.794916  0.230902  0.229227  0.870359  0.228527   \n",
       "202580  0.230243  0.226421  0.228619  0.230902  0.247887  0.230029  0.228527   \n",
       "202581  0.855618  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202582  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202583  0.230243  0.226421  0.228619  0.230902  0.874206  0.230029  0.228527   \n",
       "202584  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202585  0.857652  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202586  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202587  0.230243  0.226421  0.228619  0.857552  0.229227  0.230029  0.228527   \n",
       "202588  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202589  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202590  0.230243  0.226421  0.228619  0.852762  0.229227  0.230029  0.228527   \n",
       "202591  0.230243  0.226421  0.228619  0.230902  0.882705  0.230029  0.228527   \n",
       "202592  0.230243  0.226421  0.800968  0.230902  0.229227  0.230029  0.228527   \n",
       "202593  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202594  0.230243  0.226421  0.228619  0.230902  0.879823  0.230029  0.228527   \n",
       "202595  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202596  0.230243  0.226421  0.228619  0.847356  0.229227  0.230029  0.228527   \n",
       "202597  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "202598  0.230243  0.226421  0.228619  0.230902  0.229227  0.230029  0.228527   \n",
       "\n",
       "              7         8         9     ...           15        16        17  \\\n",
       "0       0.227724  0.227509  0.227404    ...     0.228122  0.847598  0.231347   \n",
       "1       0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "2       0.227724  0.227509  0.227404    ...     0.893830  0.857029  0.231347   \n",
       "3       0.227724  0.227509  0.227404    ...     0.228122  0.848516  0.231347   \n",
       "4       0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "5       0.227724  0.227509  0.227404    ...     0.228122  0.844832  0.231347   \n",
       "6       0.227724  0.227509  0.227404    ...     0.228122  0.838772  0.231347   \n",
       "7       0.227724  0.227509  0.231799    ...     0.228122  0.326709  0.231347   \n",
       "8       0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "9       0.227724  0.227509  0.227404    ...     0.228122  0.845152  0.231347   \n",
       "10      0.227724  0.227509  0.227404    ...     0.228122  0.848233  0.231347   \n",
       "11      0.227724  0.227509  0.227404    ...     0.228122  0.852404  0.231347   \n",
       "12      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "13      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "14      0.227724  0.227509  0.227404    ...     0.890676  0.326709  0.231347   \n",
       "15      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "16      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.841212   \n",
       "17      0.227724  0.227509  0.227404    ...     0.875282  0.326709  0.231347   \n",
       "18      0.227724  0.227509  0.227404    ...     0.228122  0.849638  0.843485   \n",
       "19      0.847361  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "20      0.227724  0.227509  0.227404    ...     0.228122  0.841702  0.231347   \n",
       "21      0.227724  0.227509  0.227404    ...     0.228122  0.849182  0.231347   \n",
       "22      0.227724  0.227509  0.227404    ...     0.873638  0.326709  0.231347   \n",
       "23      0.227724  0.227509  0.227404    ...     0.228122  0.848564  0.231347   \n",
       "24      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "25      0.227724  0.227509  0.227404    ...     0.228122  0.848584  0.231347   \n",
       "26      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "27      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "28      0.227724  0.227509  0.227404    ...     0.228122  0.848988  0.231347   \n",
       "29      0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "...          ...       ...       ...    ...          ...       ...       ...   \n",
       "202569  0.227724  0.227509  0.919503    ...     0.228122  0.326709  0.846318   \n",
       "202570  0.227724  0.227509  0.227404    ...     0.228122  0.330819  0.231347   \n",
       "202571  0.227724  0.227509  0.227404    ...     0.228122  0.845949  0.231347   \n",
       "202572  0.227724  0.227509  0.227404    ...     0.904575  0.854878  0.231347   \n",
       "202573  0.227724  0.227509  0.227404    ...     0.228122  0.848584  0.231347   \n",
       "202574  0.227724  0.227509  0.227404    ...     0.228122  0.849005  0.231347   \n",
       "202575  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "202576  0.227724  0.227509  0.227404    ...     0.228122  0.848959  0.231347   \n",
       "202577  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.844060   \n",
       "202578  0.227724  0.227509  0.227404    ...     0.228122  0.850327  0.231347   \n",
       "202579  0.227724  0.227509  0.227404    ...     0.228122  0.842945  0.231347   \n",
       "202580  0.227724  0.227509  0.901441    ...     0.228122  0.326709  0.814552   \n",
       "202581  0.227724  0.227509  0.227404    ...     0.887981  0.326709  0.231347   \n",
       "202582  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.838017   \n",
       "202583  0.227724  0.227509  0.227404    ...     0.228122  0.847879  0.231347   \n",
       "202584  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "202585  0.227724  0.227509  0.227404    ...     0.228122  0.848269  0.231347   \n",
       "202586  0.227724  0.227509  0.227404    ...     0.228122  0.848493  0.231347   \n",
       "202587  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.842099   \n",
       "202588  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.840531   \n",
       "202589  0.227724  0.895807  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "202590  0.227724  0.227509  0.227404    ...     0.228122  0.849177  0.231347   \n",
       "202591  0.227724  0.227509  0.227404    ...     0.228122  0.846669  0.231347   \n",
       "202592  0.227724  0.227509  0.227404    ...     0.228122  0.849057  0.231347   \n",
       "202593  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "202594  0.227724  0.227509  0.227404    ...     0.228122  0.850510  0.231347   \n",
       "202595  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "202596  0.227724  0.874454  0.227404    ...     0.228122  0.850123  0.231347   \n",
       "202597  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "202598  0.227724  0.227509  0.227404    ...     0.228122  0.326709  0.231347   \n",
       "\n",
       "              18        19        20        21        22        23        24  \n",
       "0       0.226592  0.231567  0.227144  0.818762  0.226646  0.797713  0.964245  \n",
       "1       0.226592  0.231567  0.227144  0.813673  0.226646  0.296929  0.963263  \n",
       "2       0.226592  0.827042  0.227144  0.236010  0.226646  0.797451  0.495064  \n",
       "3       0.226592  0.828885  0.227144  0.236010  0.226646  0.290901  0.962808  \n",
       "4       0.226592  0.231567  0.227144  0.236010  0.226646  0.792245  0.965147  \n",
       "5       0.226592  0.231567  0.227144  0.236010  0.226646  0.789205  0.964984  \n",
       "6       0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "7       0.226592  0.827412  0.227144  0.236010  0.226646  0.796232  0.495064  \n",
       "8       0.226592  0.231567  0.227144  0.236010  0.226646  0.794794  0.964835  \n",
       "9       0.226592  0.231567  0.227144  0.236010  0.226646  0.797354  0.963577  \n",
       "10      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.964488  \n",
       "11      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "12      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "13      0.226592  0.231567  0.227144  0.818295  0.226646  0.290901  0.964319  \n",
       "14      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "15      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "16      0.226592  0.231567  0.227144  0.810045  0.226646  0.795435  0.965144  \n",
       "17      0.226592  0.231567  0.227144  0.821901  0.226646  0.290901  0.963936  \n",
       "18      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.965751  \n",
       "19      0.226592  0.231567  0.875345  0.236010  0.226646  0.290901  0.495064  \n",
       "20      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "21      0.226592  0.231567  0.227144  0.236010  0.226646  0.799684  0.964311  \n",
       "22      0.226592  0.231567  0.227144  0.809743  0.226646  0.819269  0.495064  \n",
       "23      0.226592  0.231567  0.227144  0.236010  0.226646  0.797825  0.966432  \n",
       "24      0.226592  0.231567  0.227144  0.236010  0.226646  0.792789  0.495064  \n",
       "25      0.226592  0.231567  0.227144  0.236010  0.226646  0.790335  0.964672  \n",
       "26      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.964523  \n",
       "27      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.965539  \n",
       "28      0.226592  0.823475  0.227144  0.236010  0.226646  0.792263  0.965273  \n",
       "29      0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "202569  0.226592  0.231567  0.227144  0.236010  0.226646  0.787956  0.495064  \n",
       "202570  0.864441  0.231567  0.227144  0.236010  0.226646  0.762974  0.966189  \n",
       "202571  0.226592  0.830474  0.227144  0.236010  0.226646  0.290901  0.963870  \n",
       "202572  0.226592  0.825827  0.227144  0.819722  0.226646  0.290901  0.962915  \n",
       "202573  0.226592  0.231567  0.227144  0.236010  0.226646  0.790335  0.964672  \n",
       "202574  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.965324  \n",
       "202575  0.226592  0.231567  0.227144  0.236010  0.226646  0.793271  0.964494  \n",
       "202576  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.965082  \n",
       "202577  0.226592  0.231567  0.227144  0.818499  0.226646  0.793806  0.965360  \n",
       "202578  0.226592  0.231567  0.227144  0.236010  0.226646  0.806960  0.964611  \n",
       "202579  0.226592  0.231567  0.227144  0.236010  0.226646  0.788476  0.964522  \n",
       "202580  0.226592  0.231567  0.859558  0.236010  0.226646  0.290901  0.495064  \n",
       "202581  0.226592  0.231567  0.227144  0.810389  0.226646  0.290901  0.965646  \n",
       "202582  0.226592  0.231567  0.227144  0.236010  0.226646  0.790484  0.965396  \n",
       "202583  0.226592  0.231567  0.227144  0.812143  0.226646  0.290901  0.963014  \n",
       "202584  0.226592  0.231567  0.227144  0.236010  0.226646  0.792789  0.495064  \n",
       "202585  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "202586  0.226592  0.837767  0.227144  0.819524  0.226646  0.290901  0.963668  \n",
       "202587  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "202588  0.226592  0.231567  0.227144  0.236010  0.226646  0.789156  0.495064  \n",
       "202589  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "202590  0.226592  0.231567  0.227144  0.236010  0.226646  0.797561  0.965888  \n",
       "202591  0.226592  0.231567  0.227144  0.823509  0.226646  0.790358  0.965263  \n",
       "202592  0.226592  0.828619  0.227144  0.818340  0.226646  0.290901  0.964970  \n",
       "202593  0.226592  0.830843  0.227144  0.236010  0.226646  0.290901  0.964984  \n",
       "202594  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.964351  \n",
       "202595  0.226592  0.231567  0.227144  0.815174  0.226646  0.799841  0.495064  \n",
       "202596  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901  0.495064  \n",
       "202597  0.226592  0.231567  0.227144  0.236010  0.226646  0.792245  0.965147  \n",
       "202598  0.875538  0.830110  0.227144  0.236010  0.226646  0.799619  0.967261  \n",
       "\n",
       "[202599 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr=pd.DataFrame(y_prob)\n",
    "# attr.to_csv('celeba-dataset/attr.csv',index=False)\n",
    "attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.847598</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818762</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797713</td>\n",
       "      <td>0.964245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>0.854284</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.296929</td>\n",
       "      <td>0.963263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893830</td>\n",
       "      <td>0.857029</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797451</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848516</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.828885</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.962808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792245</td>\n",
       "      <td>0.965147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000006.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.880379</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.844832</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.789205</td>\n",
       "      <td>0.964984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000007.jpg</td>\n",
       "      <td>0.843310</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.876754</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.838772</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000008.jpg</td>\n",
       "      <td>0.853705</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.851993</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.827412</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.796232</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000009.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.793946</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.794794</td>\n",
       "      <td>0.964835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000010.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797354</td>\n",
       "      <td>0.963577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000011.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848233</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000012.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.851965</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.880994</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.852404</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000013.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000014.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818295</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000015.jpg</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890676</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000016.jpg</td>\n",
       "      <td>0.854084</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000017.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.841212</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.795435</td>\n",
       "      <td>0.965144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000018.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.877505</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875282</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.821901</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000019.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849638</td>\n",
       "      <td>0.843485</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000020.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.238068</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.847361</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.875345</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000021.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.841702</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000022.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.883911</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849182</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.799684</td>\n",
       "      <td>0.964311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000023.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.878591</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873638</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.819269</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000024.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848564</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797825</td>\n",
       "      <td>0.966432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000025.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792789</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000026.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848584</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790335</td>\n",
       "      <td>0.964672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000027.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.855844</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000028.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.865686</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000029.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848988</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.823475</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>0.965273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000030.jpg</td>\n",
       "      <td>0.854084</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202569</th>\n",
       "      <td>202570.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.868697</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.846318</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.787956</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202570</th>\n",
       "      <td>202571.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.873830</td>\n",
       "      <td>0.886399</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.330819</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.864441</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.762974</td>\n",
       "      <td>0.966189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202571</th>\n",
       "      <td>202572.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.845949</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.830474</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202572</th>\n",
       "      <td>202573.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904575</td>\n",
       "      <td>0.854878</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.825827</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.819722</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.962915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202573</th>\n",
       "      <td>202574.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848584</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790335</td>\n",
       "      <td>0.964672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202574</th>\n",
       "      <td>202575.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849005</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202575</th>\n",
       "      <td>202576.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.793271</td>\n",
       "      <td>0.964494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202576</th>\n",
       "      <td>202577.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848959</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202577</th>\n",
       "      <td>202578.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.868594</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.844060</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.793806</td>\n",
       "      <td>0.965360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202578</th>\n",
       "      <td>202579.jpg</td>\n",
       "      <td>0.859691</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.850327</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.806960</td>\n",
       "      <td>0.964611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202579</th>\n",
       "      <td>202580.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.794916</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.870359</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.842945</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.788476</td>\n",
       "      <td>0.964522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202580</th>\n",
       "      <td>202581.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.247887</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.814552</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.859558</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202581</th>\n",
       "      <td>202582.jpg</td>\n",
       "      <td>0.855618</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887981</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.810389</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.965646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202582</th>\n",
       "      <td>202583.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.838017</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790484</td>\n",
       "      <td>0.965396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202583</th>\n",
       "      <td>202584.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.874206</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202584</th>\n",
       "      <td>202585.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792789</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202585</th>\n",
       "      <td>202586.jpg</td>\n",
       "      <td>0.857652</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848269</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202586</th>\n",
       "      <td>202587.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.848493</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.819524</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.963668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202587</th>\n",
       "      <td>202588.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.857552</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.842099</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202588</th>\n",
       "      <td>202589.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.840531</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.789156</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202589</th>\n",
       "      <td>202590.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.895807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202590</th>\n",
       "      <td>202591.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.852762</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849177</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.797561</td>\n",
       "      <td>0.965888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202591</th>\n",
       "      <td>202592.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.882705</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.846669</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.823509</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.790358</td>\n",
       "      <td>0.965263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202592</th>\n",
       "      <td>202593.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.800968</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.828619</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.818340</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202593</th>\n",
       "      <td>202594.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.830843</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202594</th>\n",
       "      <td>202595.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.879823</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.964351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595</th>\n",
       "      <td>202596.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.815174</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.799841</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596</th>\n",
       "      <td>202597.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.847356</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.874454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.290901</td>\n",
       "      <td>0.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597</th>\n",
       "      <td>202598.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.226592</td>\n",
       "      <td>0.231567</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.792245</td>\n",
       "      <td>0.965147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598</th>\n",
       "      <td>202599.jpg</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.226421</td>\n",
       "      <td>0.228619</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.230029</td>\n",
       "      <td>0.228527</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>0.326709</td>\n",
       "      <td>0.231347</td>\n",
       "      <td>0.875538</td>\n",
       "      <td>0.830110</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.226646</td>\n",
       "      <td>0.799619</td>\n",
       "      <td>0.967261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id         0         1         2         3         4  \\\n",
       "0       000001.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "1       000002.jpg  0.854284  0.226421  0.228619  0.230902  0.229227   \n",
       "2       000003.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "3       000004.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "4       000005.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "5       000006.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "6       000007.jpg  0.843310  0.226421  0.228619  0.856332  0.229227   \n",
       "7       000008.jpg  0.853705  0.226421  0.228619  0.851993  0.229227   \n",
       "8       000009.jpg  0.230243  0.226421  0.793946  0.230902  0.229227   \n",
       "9       000010.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "10      000011.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "11      000012.jpg  0.230243  0.226421  0.228619  0.851965  0.229227   \n",
       "12      000013.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "13      000014.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "14      000015.jpg  0.853583  0.226421  0.228619  0.230902  0.229227   \n",
       "15      000016.jpg  0.854084  0.226421  0.228619  0.230902  0.229227   \n",
       "16      000017.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "17      000018.jpg  0.230243  0.226421  0.228619  0.230902  0.877505   \n",
       "18      000019.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "19      000020.jpg  0.230243  0.226421  0.238068  0.230902  0.229227   \n",
       "20      000021.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "21      000022.jpg  0.230243  0.226421  0.228619  0.230902  0.883911   \n",
       "22      000023.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "23      000024.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "24      000025.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "25      000026.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "26      000027.jpg  0.230243  0.226421  0.228619  0.855844  0.229227   \n",
       "27      000028.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "28      000029.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "29      000030.jpg  0.854084  0.226421  0.228619  0.230902  0.229227   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "202569  202570.jpg  0.230243  0.226421  0.228619  0.868697  0.229227   \n",
       "202570  202571.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202571  202572.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202572  202573.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202573  202574.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202574  202575.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202575  202576.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202576  202577.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202577  202578.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202578  202579.jpg  0.859691  0.226421  0.228619  0.230902  0.229227   \n",
       "202579  202580.jpg  0.230243  0.226421  0.794916  0.230902  0.229227   \n",
       "202580  202581.jpg  0.230243  0.226421  0.228619  0.230902  0.247887   \n",
       "202581  202582.jpg  0.855618  0.226421  0.228619  0.230902  0.229227   \n",
       "202582  202583.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202583  202584.jpg  0.230243  0.226421  0.228619  0.230902  0.874206   \n",
       "202584  202585.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202585  202586.jpg  0.857652  0.226421  0.228619  0.230902  0.229227   \n",
       "202586  202587.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202587  202588.jpg  0.230243  0.226421  0.228619  0.857552  0.229227   \n",
       "202588  202589.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202589  202590.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202590  202591.jpg  0.230243  0.226421  0.228619  0.852762  0.229227   \n",
       "202591  202592.jpg  0.230243  0.226421  0.228619  0.230902  0.882705   \n",
       "202592  202593.jpg  0.230243  0.226421  0.800968  0.230902  0.229227   \n",
       "202593  202594.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202594  202595.jpg  0.230243  0.226421  0.228619  0.230902  0.879823   \n",
       "202595  202596.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202596  202597.jpg  0.230243  0.226421  0.228619  0.847356  0.229227   \n",
       "202597  202598.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "202598  202599.jpg  0.230243  0.226421  0.228619  0.230902  0.229227   \n",
       "\n",
       "               5         6         7         8    ...           15        16  \\\n",
       "0       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.847598   \n",
       "1       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "2       0.230029  0.228527  0.227724  0.227509    ...     0.893830  0.857029   \n",
       "3       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848516   \n",
       "4       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "5       0.880379  0.228527  0.227724  0.227509    ...     0.228122  0.844832   \n",
       "6       0.230029  0.876754  0.227724  0.227509    ...     0.228122  0.838772   \n",
       "7       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "8       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "9       0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.845152   \n",
       "10      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848233   \n",
       "11      0.230029  0.880994  0.227724  0.227509    ...     0.228122  0.852404   \n",
       "12      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "13      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "14      0.230029  0.228527  0.227724  0.227509    ...     0.890676  0.326709   \n",
       "15      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "16      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "17      0.230029  0.228527  0.227724  0.227509    ...     0.875282  0.326709   \n",
       "18      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.849638   \n",
       "19      0.230029  0.228527  0.847361  0.227509    ...     0.228122  0.326709   \n",
       "20      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.841702   \n",
       "21      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.849182   \n",
       "22      0.878591  0.228527  0.227724  0.227509    ...     0.873638  0.326709   \n",
       "23      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848564   \n",
       "24      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "25      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848584   \n",
       "26      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "27      0.865686  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "28      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848988   \n",
       "29      0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "...          ...       ...       ...       ...    ...          ...       ...   \n",
       "202569  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202570  0.873830  0.886399  0.227724  0.227509    ...     0.228122  0.330819   \n",
       "202571  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.845949   \n",
       "202572  0.230029  0.228527  0.227724  0.227509    ...     0.904575  0.854878   \n",
       "202573  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848584   \n",
       "202574  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.849005   \n",
       "202575  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202576  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848959   \n",
       "202577  0.868594  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202578  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.850327   \n",
       "202579  0.870359  0.228527  0.227724  0.227509    ...     0.228122  0.842945   \n",
       "202580  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202581  0.230029  0.228527  0.227724  0.227509    ...     0.887981  0.326709   \n",
       "202582  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202583  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.847879   \n",
       "202584  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202585  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848269   \n",
       "202586  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.848493   \n",
       "202587  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202588  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202589  0.230029  0.228527  0.227724  0.895807    ...     0.228122  0.326709   \n",
       "202590  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.849177   \n",
       "202591  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.846669   \n",
       "202592  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.849057   \n",
       "202593  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202594  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.850510   \n",
       "202595  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202596  0.230029  0.228527  0.227724  0.874454    ...     0.228122  0.850123   \n",
       "202597  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "202598  0.230029  0.228527  0.227724  0.227509    ...     0.228122  0.326709   \n",
       "\n",
       "              17        18        19        20        21        22        23  \\\n",
       "0       0.231347  0.226592  0.231567  0.227144  0.818762  0.226646  0.797713   \n",
       "1       0.231347  0.226592  0.231567  0.227144  0.813673  0.226646  0.296929   \n",
       "2       0.231347  0.226592  0.827042  0.227144  0.236010  0.226646  0.797451   \n",
       "3       0.231347  0.226592  0.828885  0.227144  0.236010  0.226646  0.290901   \n",
       "4       0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.792245   \n",
       "5       0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.789205   \n",
       "6       0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "7       0.231347  0.226592  0.827412  0.227144  0.236010  0.226646  0.796232   \n",
       "8       0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.794794   \n",
       "9       0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.797354   \n",
       "10      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "11      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "12      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "13      0.231347  0.226592  0.231567  0.227144  0.818295  0.226646  0.290901   \n",
       "14      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "15      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "16      0.841212  0.226592  0.231567  0.227144  0.810045  0.226646  0.795435   \n",
       "17      0.231347  0.226592  0.231567  0.227144  0.821901  0.226646  0.290901   \n",
       "18      0.843485  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "19      0.231347  0.226592  0.231567  0.875345  0.236010  0.226646  0.290901   \n",
       "20      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "21      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.799684   \n",
       "22      0.231347  0.226592  0.231567  0.227144  0.809743  0.226646  0.819269   \n",
       "23      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.797825   \n",
       "24      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.792789   \n",
       "25      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.790335   \n",
       "26      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "27      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "28      0.231347  0.226592  0.823475  0.227144  0.236010  0.226646  0.792263   \n",
       "29      0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "202569  0.846318  0.226592  0.231567  0.227144  0.236010  0.226646  0.787956   \n",
       "202570  0.231347  0.864441  0.231567  0.227144  0.236010  0.226646  0.762974   \n",
       "202571  0.231347  0.226592  0.830474  0.227144  0.236010  0.226646  0.290901   \n",
       "202572  0.231347  0.226592  0.825827  0.227144  0.819722  0.226646  0.290901   \n",
       "202573  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.790335   \n",
       "202574  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202575  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.793271   \n",
       "202576  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202577  0.844060  0.226592  0.231567  0.227144  0.818499  0.226646  0.793806   \n",
       "202578  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.806960   \n",
       "202579  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.788476   \n",
       "202580  0.814552  0.226592  0.231567  0.859558  0.236010  0.226646  0.290901   \n",
       "202581  0.231347  0.226592  0.231567  0.227144  0.810389  0.226646  0.290901   \n",
       "202582  0.838017  0.226592  0.231567  0.227144  0.236010  0.226646  0.790484   \n",
       "202583  0.231347  0.226592  0.231567  0.227144  0.812143  0.226646  0.290901   \n",
       "202584  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.792789   \n",
       "202585  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202586  0.231347  0.226592  0.837767  0.227144  0.819524  0.226646  0.290901   \n",
       "202587  0.842099  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202588  0.840531  0.226592  0.231567  0.227144  0.236010  0.226646  0.789156   \n",
       "202589  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202590  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.797561   \n",
       "202591  0.231347  0.226592  0.231567  0.227144  0.823509  0.226646  0.790358   \n",
       "202592  0.231347  0.226592  0.828619  0.227144  0.818340  0.226646  0.290901   \n",
       "202593  0.231347  0.226592  0.830843  0.227144  0.236010  0.226646  0.290901   \n",
       "202594  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202595  0.231347  0.226592  0.231567  0.227144  0.815174  0.226646  0.799841   \n",
       "202596  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.290901   \n",
       "202597  0.231347  0.226592  0.231567  0.227144  0.236010  0.226646  0.792245   \n",
       "202598  0.231347  0.875538  0.830110  0.227144  0.236010  0.226646  0.799619   \n",
       "\n",
       "              24  \n",
       "0       0.964245  \n",
       "1       0.963263  \n",
       "2       0.495064  \n",
       "3       0.962808  \n",
       "4       0.965147  \n",
       "5       0.964984  \n",
       "6       0.495064  \n",
       "7       0.495064  \n",
       "8       0.964835  \n",
       "9       0.963577  \n",
       "10      0.964488  \n",
       "11      0.495064  \n",
       "12      0.495064  \n",
       "13      0.964319  \n",
       "14      0.495064  \n",
       "15      0.495064  \n",
       "16      0.965144  \n",
       "17      0.963936  \n",
       "18      0.965751  \n",
       "19      0.495064  \n",
       "20      0.495064  \n",
       "21      0.964311  \n",
       "22      0.495064  \n",
       "23      0.966432  \n",
       "24      0.495064  \n",
       "25      0.964672  \n",
       "26      0.964523  \n",
       "27      0.965539  \n",
       "28      0.965273  \n",
       "29      0.495064  \n",
       "...          ...  \n",
       "202569  0.495064  \n",
       "202570  0.966189  \n",
       "202571  0.963870  \n",
       "202572  0.962915  \n",
       "202573  0.964672  \n",
       "202574  0.965324  \n",
       "202575  0.964494  \n",
       "202576  0.965082  \n",
       "202577  0.965360  \n",
       "202578  0.964611  \n",
       "202579  0.964522  \n",
       "202580  0.495064  \n",
       "202581  0.965646  \n",
       "202582  0.965396  \n",
       "202583  0.963014  \n",
       "202584  0.495064  \n",
       "202585  0.495064  \n",
       "202586  0.963668  \n",
       "202587  0.495064  \n",
       "202588  0.495064  \n",
       "202589  0.495064  \n",
       "202590  0.965888  \n",
       "202591  0.965263  \n",
       "202592  0.964970  \n",
       "202593  0.964984  \n",
       "202594  0.964351  \n",
       "202595  0.495064  \n",
       "202596  0.495064  \n",
       "202597  0.965147  \n",
       "202598  0.967261  \n",
       "\n",
       "[202599 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idnum=pd.DataFrame(list(data['image_id']),columns=['image_id'])\n",
    "newdataset=pd.concat([idnum,attr],axis=1)\n",
    "newdataset.to_csv('celeba-dataset/attr.csv',index=False)\n",
    "newdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "# x_train = np.array(x_train)\n",
    "# x_test = np.array(x_test)\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "# print(x_test)\n",
    "# print(x_test.shape)\n",
    "# print(y_test)\n",
    "# vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "    \n",
    "# x_transform_train = vocab_processor.fit_transform(x_train) # 둘의 차이는?\n",
    "# x_transform_test = vocab_processor.transform(x_test)\n",
    "# x_train = np.array(list(x_transform_train))\n",
    "# x_test = np.array(list(x_transform_test))\n",
    "# print(x_test)\n",
    "# print(x_test.shape)\n",
    "# print(y_test)\n",
    "\n",
    "# x_transform = vocab_processor.transform(x)\n",
    "# x1 = np.array(list(x_transform))\n",
    "# y1 = np.array(y)\n",
    "# print(x1)\n",
    "# print(x1.shape)\n",
    "# print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global n_words\n",
    "# global vocab_processor\n",
    "# global classifier\n",
    "    \n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "# x_train = np.array(x_train)\n",
    "# x_test = np.array(x_test)\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test) # tensorflow input으로 사용될 수 있는 자료형으로 변환시켜줘야 한다.\n",
    "# # 단어들을 우리가 원하는 sequence length로 맞추어 준다.(embedding 해주기 전 단계) 위의 사진 참고\n",
    "# vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "    \n",
    "# x_transform_train = vocab_processor.fit_transform(x_train) # 둘의 차이는?\n",
    "# x_transform_test = vocab_processor.transform(x_test)\n",
    "# x_train = np.array(list(x_transform_train))\n",
    "# x_test = np.array(list(x_transform_test))\n",
    "    \n",
    "    \n",
    "# n_words = len(vocab_processor.vocabulary_)\n",
    "# print('Total words : %d', n_words)\n",
    "    \n",
    "# # 모델을 만들어준다.(여기서는 위에서 정의한 rnn_model을 사용한다.)\n",
    "# model_fn = rnn_model\n",
    "# classifier = tf.estimator.Estimator(model_fn=model_fn)\n",
    "    \n",
    "    \n",
    "# # Train\n",
    "# train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#     x = {WORDS_FEATURE : x_train},\n",
    "#     y = y_train,\n",
    "#     batch_size = 256,\n",
    "#     num_epochs = 1,\n",
    "#     shuffle = True) # shuffle = True : \n",
    "    \n",
    "    \n",
    "    \n",
    "# tensors_to_log = {\"prob\": 'prob', 'labels': 'labels', 'predicted_classes': 'predicted_classes', 'acc': 'acc', 'acc_row': 'acc_row'}\n",
    "# logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "    \n",
    "# classifier.train(input_fn = train_input_fn, hooks=[logging_hook])\n",
    "\n",
    "#     # Predict\n",
    "# test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#     x = {WORDS_FEATURE : x_test},\n",
    "#     y = y_test,\n",
    "#     num_epochs = 1,\n",
    "#     shuffle = False)\n",
    "# predictions = classifier.predict(input_fn = test_input_fn)\n",
    "# y_predicted = np.array(list(p['prob'] for p in predictions))\n",
    "    \n",
    "    \n",
    "# # Score using tensorflow\n",
    "# score = classifier.evaluate(input_fn = test_input_fn)\n",
    "# print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor.vocabulary_.reverse(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train data set, test data set을 나눠준다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test) # tensorflow input으로 사용될 수 있는 자료형으로 변환시켜줘야 한다.\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "# 단어들을 우리가 원하는 sequence length로 맞추어 준다.(embedding 해주기 전 단계) 위의 사진 참고\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "\n",
    "x_transform_train = vocab_processor.fit_transform(x_train) # 둘의 차이는?\n",
    "x_transform_test = vocab_processor.transform(x_test)\n",
    "x_train = np.array(list(x_transform_train))\n",
    "x_test = np.array(list(x_transform_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {WORDS_FEATURE : x_test},\n",
    "    y = y_test,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "# Score using tensorflow\n",
    "score = classifier.evaluate(input_fn = test_input_fn)\n",
    "print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predictions:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
